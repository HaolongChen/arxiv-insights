[
  {
    "arxiv_id": "2512.14693",
    "title": "Universal Reasoning Model",
    "authors": [
      "Zitian Gao",
      "Lynx Chen",
      "Yihao Xiao",
      "He Xing",
      "Ran Tao",
      "Haoming Luo",
      "Joey Zhou",
      "Bryan Dai"
    ],
    "date": "2025-12-16",
    "field": "cs-ai",
    "tags": [
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.14693",
    "abstract": "Universal transformers (UTs) have been widely used for complex reasoning tasks such as ARC-AGI and Sudoku, yet the specific sources of their performance gains remain underexplored. In this work, we systematically analyze UTs variants and show that improvements on ARC-AGI primarily arise from the rec",
    "file": "cs/ai/2512.14693-universal-reasoning-model.md"
  },
  {
    "arxiv_id": "2512.14681",
    "title": "Fast and Accurate Causal Parallel Decoding using Jacobi Forcing",
    "authors": [
      "Lanxiang Hu",
      "Siqi Kou",
      "Yichao Fu",
      "Samyam Rajbhandari",
      "Tajana Rosing",
      "Yuxiong He",
      "Zhijie Deng",
      "Hao Zhang"
    ],
    "date": "2025-12-16",
    "field": "cs-ai",
    "tags": [
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.14681",
    "abstract": "Multi-token generation has emerged as a promising paradigm for accelerating transformer-based large model inference. Recent efforts primarily explore diffusion Large Language Models (dLLMs) for parallel decoding to reduce inference latency. To achieve AR-level generation quality, many techniques ada",
    "file": "cs/ai/2512.14681-fast-and-accurate-causal-parallel-decoding-using-j.md"
  },
  {
    "arxiv_id": "2512.14691",
    "title": "MMGR: Multi-Modal Generative Reasoning",
    "authors": [
      "Zefan Cai",
      "Haoyi Qiu",
      "Tianyi Ma",
      "Haozhe Zhao",
      "Gengze Zhou",
      "Kung-Hsiang Huang",
      "Parisa Kordjamshidi",
      "Minjia Zhang",
      "Xiao Wen",
      "Jiuxiang Gu",
      "Nanyun Peng",
      "Junjie Hu"
    ],
    "date": "2025-12-16",
    "field": "cs-ai",
    "tags": [
      "cs.CL",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.14691",
    "abstract": "Video foundation models generate visually realistic and temporally coherent content, but their reliability as world simulators depends on whether they capture physical, logical, and spatial constraints. Existing metrics such as Frechet Video Distance (FVD) emphasize perceptual quality and overlook r",
    "file": "cs/ai/2512.14691-mmgr-multi-modal-generative-reasoning.md"
  },
  {
    "arxiv_id": "2512.14696",
    "title": "CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives",
    "authors": [
      "Zihan Wang",
      "Jiashun Wang",
      "Jeff Tan",
      "Yiwen Zhao",
      "Jessica Hodgins",
      "Shubham Tulsiani",
      "Deva Ramanan"
    ],
    "date": "2025-12-16",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.GR",
      "cs.RO"
    ],
    "url": "https://arxiv.org/abs/2512.14696",
    "abstract": "We introduce CRISP, a method that recovers simulatable human motion and scene geometry from monocular video. Prior work on joint human-scene reconstruction relies on data-driven priors and joint optimization with no physics in the loop, or recovers noisy geometry with artifacts that cause motion tra",
    "file": "cs/cv/2512.14696-crisp-contact-guided-real2sim-from-monocular-vide.md"
  },
  {
    "arxiv_id": "2512.14640",
    "title": "A Multicenter Benchmark of Multiple Instance Learning Models for Lymphoma Subtyping from HE-stained Whole Slide Images",
    "authors": [
      "Rao Muhammad Umer",
      "Daniel Sens",
      "Jonathan Noll",
      "Christian Matek",
      "Lukas Wolfseher",
      "Rainer Spang",
      "Ralf Huss",
      "Johannes Raffler",
      "Sarah Reinke",
      "Wolfram Klapper",
      "Katja Steiger",
      "Kristina Schwamborn",
      "Carsten Marr"
    ],
    "date": "2025-12-16",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.14640",
    "abstract": "Timely and accurate lymphoma diagnosis is essential for guiding cancer treatment. Standard diagnostic practice combines hematoxylin and eosin (HE)-stained whole slide images with immunohistochemistry, flow cytometry, and molecular genetic tests to determine lymphoma subtypes, a process requiring cos",
    "file": "cs/cv/2512.14640-a-multicenter-benchmark-of-multiple-instance-learn.md"
  },
  {
    "arxiv_id": "2512.14698",
    "title": "TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs",
    "authors": [
      "Jun Zhang",
      "Teng Wang",
      "Yuying Ge",
      "Yixiao Ge",
      "Xinhao Li",
      "Ying Shan",
      "Limin Wang"
    ],
    "date": "2025-12-16",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "url": "https://arxiv.org/abs/2512.14698",
    "abstract": "This paper does not introduce a novel method but instead establishes a straightforward, incremental, yet essential baseline for video temporal grounding (VTG), a core capability in video understanding. While multimodal large language models (MLLMs) excel at various video understanding tasks, the rec",
    "file": "cs/cv/2512.14698-timelens-rethinking-video-temporal-grounding-with.md"
  },
  {
    "arxiv_id": "2512.14639",
    "title": "AMD-HookNet++: Evolution of AMD-HookNet with Hybrid CNN-Transformer Feature Enhancement for Glacier Calving Front Segmentation",
    "authors": [
      "Fei Wu",
      "Marcel Dreier",
      "Nora Gourmelon",
      "Sebastian Wind",
      "Jianlin Zhang",
      "Thorsten Seehaus",
      "Matthias Braun",
      "Andreas Maier",
      "Vincent Christlein"
    ],
    "date": "2025-12-16",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.14639",
    "abstract": "The dynamics of glaciers and ice shelf fronts significantly impact the mass balance of ice sheets and coastal sea levels. To effectively monitor glacier conditions, it is crucial to consistently estimate positional shifts of glacier calving fronts. AMD-HookNet firstly introduces a pure two-branch co",
    "file": "cs/cv/2512.14639-amd-hooknet-evolution-of-amd-hooknet-with-hybri.md"
  },
  {
    "arxiv_id": "2512.14671",
    "title": "ART: Articulated Reconstruction Transformer",
    "authors": [
      "Zizhang Li",
      "Cheng Zhang",
      "Zhengqin Li",
      "Henry Howard-Jenkins",
      "Zhaoyang Lv",
      "Chen Geng",
      "Jiajun Wu",
      "Richard Newcombe",
      "Jakob Engel",
      "Zhao Dong"
    ],
    "date": "2025-12-16",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.14671",
    "abstract": "We introduce ART, Articulated Reconstruction Transformer -- a category-agnostic, feed-forward model that reconstructs complete 3D articulated objects from only sparse, multi-state RGB images. Previous methods for articulated object reconstruction either rely on slow optimization with fragile cross-s",
    "file": "cs/cv/2512.14671-art-articulated-reconstruction-transformer.md"
  },
  {
    "arxiv_id": "2512.14666",
    "title": "EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models",
    "authors": [
      "Zechen Bai",
      "Chen Gao",
      "Mike Zheng Shou"
    ],
    "date": "2025-12-16",
    "field": "other",
    "tags": [
      "cs.RO",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.14666",
    "abstract": "Achieving truly adaptive embodied intelligence requires agents that learn not just by imitating static demonstrations, but by continuously improving through environmental interaction, which is akin to how humans master skills through practice. Vision-Language-Action (VLA) models have advanced roboti",
    "file": "other/2512.14666-evolve-vla-test-time-training-from-environment-fe.md"
  },
  {
    "arxiv_id": "2512.14656",
    "title": "WaveSim: A Wavelet-based Multi-scale Similarity Metric for Weather and Climate Fields",
    "authors": [
      "Gabriele Accarino",
      "Viviana Acquaviva",
      "Sara Shamekh",
      "Duncan Watson-Parris",
      "David Lawrence"
    ],
    "date": "2025-12-16",
    "field": "other",
    "tags": [
      "physics.ao-ph",
      "cs.CV",
      "physics.data-an"
    ],
    "url": "https://arxiv.org/abs/2512.14656",
    "abstract": "We introduce WaveSim, a multi-scale similarity metric for the evaluation of spatial fields in weather and climate applications. WaveSim exploits wavelet transforms to decompose input fields into scale-specific wavelet coefficients. The metric is built by multiplying three orthogonal components deriv",
    "file": "other/2512.14656-wavesim-a-wavelet-based-multi-scale-similarity-me.md"
  },
  {
    "arxiv_id": "2512.13685",
    "title": "Beyond surface form: A pipeline for semantic analysis in Alzheimer's Disease detection from spontaneous speech",
    "authors": [
      "Dylan Phelps",
      "Rodrigo Wilkens",
      "Edward Gow-Smith",
      "Lilian Hubner",
      "B\u00e1rbara Malcorra",
      "C\u00e9sar Renn\u00f3-Costa",
      "Marco Idiart",
      "Maria-Cruz Villa-Uriol",
      "Aline Villavicencio"
    ],
    "date": "2025-12-15",
    "field": "cs-ai",
    "tags": [
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.13685",
    "abstract": "Alzheimer's Disease (AD) is a progressive neurodegenerative condition that adversely affects cognitive abilities. Language-related changes can be automatically identified through the analysis of outputs from linguistic assessment tasks, such as picture description. Language models show promise as a ",
    "file": "cs/ai/2512.13685-beyond-surface-form-a-pipeline-for-semantic-analy.md"
  },
  {
    "arxiv_id": "2512.13672",
    "title": "Directional Textual Inversion for Personalized Text-to-Image Generation",
    "authors": [
      "Kunhee Kim",
      "NaHyeon Park",
      "Kibeom Hong",
      "Hyunjung Shim"
    ],
    "date": "2025-12-15",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.13672",
    "abstract": "Textual Inversion (TI) is an efficient approach to text-to-image personalization but often fails on complex prompts. We trace these failures to embedding norm inflation: learned tokens drift to out-of-distribution magnitudes, degrading prompt conditioning in pre-norm Transformers. Empirically, we sh",
    "file": "cs/lg/2512.13672-directional-textual-inversion-for-personalized-tex.md"
  },
  {
    "arxiv_id": "2512.13668",
    "title": "A Scientific Reasoning Model for Organic Synthesis Procedure Generation",
    "authors": [
      "Guoqing Liu",
      "Junren Li",
      "Zihan Zhao",
      "Eray Inanc",
      "Krzysztof Maziarz",
      "Jose Garrido Torres",
      "Victor Garcia Satorras",
      "Shoko Ueda",
      "Christopher M. Bishop",
      "Marwin Segler"
    ],
    "date": "2025-12-15",
    "field": "cs-lg",
    "tags": [
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.13668",
    "abstract": "Solving computer-aided synthesis planning is essential for enabling fully automated, robot-assisted synthesis workflows and improving the efficiency of drug discovery. A key challenge, however, is bridging the gap between computational route design and practical laboratory execution, particularly th",
    "file": "cs/lg/2512.13668-a-scientific-reasoning-model-for-organic-synthesis.md"
  },
  {
    "arxiv_id": "2512.13690",
    "title": "DiffusionBrowser: Interactive Diffusion Previews via Multi-Branch Decoders",
    "authors": [
      "Susung Hong",
      "Chongjian Ge",
      "Zhifei Zhang",
      "Jui-Hsien Wang"
    ],
    "date": "2025-12-15",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.13690",
    "abstract": "Video diffusion models have revolutionized generative video synthesis, but they are imprecise, slow, and can be opaque during generation -- keeping users in the dark for a prolonged period. In this work, we propose DiffusionBrowser, a model-agnostic, lightweight decoder framework that allows users t",
    "file": "cs/cv/2512.13690-diffusionbrowser-interactive-diffusion-previews-v.md"
  },
  {
    "arxiv_id": "2512.13665",
    "title": "Grab-3D: Detecting AI-Generated Videos from 3D Geometric Temporal Consistency",
    "authors": [
      "Wenhan Chen",
      "Sezer Karaoglu",
      "Theo Gevers"
    ],
    "date": "2025-12-15",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.13665",
    "abstract": "Recent advances in diffusion-based generation techniques enable AI models to produce highly realistic videos, heightening the need for reliable detection mechanisms. However, existing detection methods provide only limited exploration of the 3D geometric patterns present in generated videos. In this",
    "file": "cs/cv/2512.13665-grab-3d-detecting-ai-generated-videos-from-3d-geo.md"
  },
  {
    "arxiv_id": "2512.13680",
    "title": "LASER: Layer-wise Scale Alignment for Training-Free Streaming 4D Reconstruction",
    "authors": [
      "Tianye Ding",
      "Yiming Xie",
      "Yiqing Liang",
      "Moitreya Chatterjee",
      "Pedro Miraldo",
      "Huaizu Jiang"
    ],
    "date": "2025-12-15",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.13680",
    "abstract": "Recent feed-forward reconstruction models like VGGT and $\u03c0^3$ achieve impressive reconstruction quality but cannot process streaming videos due to quadratic memory complexity, limiting their practical deployment. While existing streaming methods address this through learned memory mechanisms or caus",
    "file": "cs/cv/2512.13680-laser-layer-wise-scale-alignment-for-training-fre.md"
  },
  {
    "arxiv_id": "2512.13671",
    "title": "AgentIAD: Tool-Augmented Single-Agent for Industrial Anomaly Detection",
    "authors": [
      "Junwen Miao",
      "Penghui Du",
      "Yi Liu",
      "Yu Wang",
      "Yan Wang"
    ],
    "date": "2025-12-15",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.13671",
    "abstract": "Industrial anomaly detection (IAD) is difficult due to the scarcity of normal reference samples and the subtle, localized nature of many defects. Single-pass vision-language models (VLMs) often overlook small abnormalities and lack explicit mechanisms to compare against canonical normal patterns. We",
    "file": "cs/cv/2512.13671-agentiad-tool-augmented-single-agent-for-industri.md"
  },
  {
    "arxiv_id": "2512.13689",
    "title": "LitePT: Lighter Yet Stronger Point Transformer",
    "authors": [
      "Yuanwen Yue",
      "Damien Robert",
      "Jianyuan Wang",
      "Sunghwan Hong",
      "Jan Dirk Wegner",
      "Christian Rupprecht",
      "Konrad Schindler"
    ],
    "date": "2025-12-15",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.13689",
    "abstract": "Modern neural architectures for 3D point cloud processing contain both convolutional layers and attention blocks, but the best way to assemble them remains unclear. We analyse the role of different computational blocks in 3D point cloud networks and find an intuitive behaviour: convolution is adequa",
    "file": "cs/cv/2512.13689-litept-lighter-yet-stronger-point-transformer.md"
  },
  {
    "arxiv_id": "2512.13677",
    "title": "JoVA: Unified Multimodal Learning for Joint Video-Audio Generation",
    "authors": [
      "Xiaohu Huang",
      "Hao Zhou",
      "Qiangpeng Yang",
      "Shilei Wen",
      "Kai Han"
    ],
    "date": "2025-12-15",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.13677",
    "abstract": "In this paper, we present JoVA, a unified framework for joint video-audio generation. Despite recent encouraging advances, existing methods face two critical limitations. First, most existing approaches can only generate ambient sounds and lack the capability to produce human speech synchronized wit",
    "file": "cs/cv/2512.13677-jova-unified-multimodal-learning-for-joint-video.md"
  },
  {
    "arxiv_id": "2512.13684",
    "title": "Recurrent Video Masked Autoencoders",
    "authors": [
      "Daniel Zoran",
      "Nikhil Parthasarathy",
      "Yi Yang",
      "Drew A Hudson",
      "Joao Carreira",
      "Andrew Zisserman"
    ],
    "date": "2025-12-15",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.13684",
    "abstract": "We present Recurrent Video Masked-Autoencoders (RVM): a novel video representation learning approach that uses a transformer-based recurrent neural network to aggregate dense image features over time, effectively capturing the spatio-temporal structure of natural video data. RVM learns via an asymme",
    "file": "cs/cv/2512.13684-recurrent-video-masked-autoencoders.md"
  },
  {
    "arxiv_id": "2512.12777",
    "title": "State over Tokens: Characterizing the Role of Reasoning Tokens",
    "authors": [
      "Mosh Levy",
      "Zohar Elyoseph",
      "Shauli Ravfogel",
      "Yoav Goldberg"
    ],
    "date": "2025-12-14",
    "field": "cs-ai",
    "tags": [
      "cs.CL",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.12777",
    "abstract": "Large Language Models (LLMs) can generate reasoning tokens before their final answer to boost performance on complex tasks. While these sequences seem like human thought processes, empirical evidence reveals that they are not a faithful explanation of the model's actual reasoning process. To address",
    "file": "cs/ai/2512.12777-state-over-tokens-characterizing-the-role-of-reas.md"
  },
  {
    "arxiv_id": "2512.12775",
    "title": "Persistent Personas? Role-Playing, Instruction Following, and Safety in Extended Interactions",
    "authors": [
      "Pedro Henrique Luz de Araujo",
      "Michael A. Hedderich",
      "Ali Modarressi",
      "Hinrich Schuetze",
      "Benjamin Roth"
    ],
    "date": "2025-12-14",
    "field": "cs-ai",
    "tags": [
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.12775",
    "abstract": "Persona-assigned large language models (LLMs) are used in domains such as education, healthcare, and sociodemographic simulation. Yet, they are typically evaluated only in short, single-round settings that do not reflect real-world usage. We introduce an evaluation protocol that combines long person",
    "file": "cs/ai/2512.12775-persistent-personas-role-playing-instruction-fol.md"
  },
  {
    "arxiv_id": "2512.12756",
    "title": "FysicsWorld: A Unified Full-Modality Benchmark for Any-to-Any Understanding, Generation, and Reasoning",
    "authors": [
      "Yue Jiang",
      "Dingkang Yang",
      "Minghao Han",
      "Jinghang Han",
      "Zizhi Chen",
      "Yizhou Liu",
      "Mingcheng Li",
      "Peng Zhai",
      "Lihua Zhang"
    ],
    "date": "2025-12-14",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.12756",
    "abstract": "Despite rapid progress in multimodal large language models (MLLMs) and emerging omni-modal architectures, current benchmarks remain limited in scope and integration, suffering from incomplete modality coverage, restricted interaction to text-centric outputs, and weak interdependence and complementar",
    "file": "cs/cv/2512.12756-fysicsworld-a-unified-full-modality-benchmark-for.md"
  },
  {
    "arxiv_id": "2512.12772",
    "title": "JointAVBench: A Benchmark for Joint Audio-Visual Reasoning Evaluation",
    "authors": [
      "Jianghan Chao",
      "Jianzhang Gao",
      "Wenhui Tan",
      "Yuchong Sun",
      "Ruihua Song",
      "Liyun Ru"
    ],
    "date": "2025-12-14",
    "field": "other",
    "tags": [
      "cs.MM",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.12772",
    "abstract": "Understanding videos inherently requires reasoning over both visual and auditory information. To properly evaluate Omni-Large Language Models (Omni-LLMs), which are capable of processing multi-modal information including vision and audio, an effective benchmark must comprehensively cover three key a",
    "file": "other/2512.12772-jointavbench-a-benchmark-for-joint-audio-visual-r.md"
  },
  {
    "arxiv_id": "2512.12769",
    "title": "Adaptive Edge-Cloud Inference for Speech-to-Action Systems Using ASR and Large Language Models (ASTA)",
    "authors": [
      "Mohammad Jalili Torkamani",
      "Israt Zarin"
    ],
    "date": "2025-12-14",
    "field": "other",
    "tags": [
      "cs.SD",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.12769",
    "abstract": "Voice-based interaction has emerged as a natural and intuitive modality for controlling IoT devices. However, speech-driven edge devices face a fundamental trade-off between cloud-based solutions, which offer stronger language understanding capabilities at the cost of latency, connectivity dependenc",
    "file": "other/2512.12769-adaptive-edge-cloud-inference-for-speech-to-action.md"
  },
  {
    "arxiv_id": "2512.10807",
    "title": "HAROOD: A Benchmark for Out-of-distribution Generalization in Sensor-based Human Activity Recognition",
    "authors": [
      "Wang Lu",
      "Yao Zhu",
      "Jindong Wang"
    ],
    "date": "2025-12-11",
    "field": "cs-ai",
    "tags": [
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10807",
    "abstract": "Sensor-based human activity recognition (HAR) mines activity patterns from the time-series sensory data. In realistic scenarios, variations across individuals, devices, environments, and time introduce significant distributional shifts for the same activities. Recent efforts attempt to solve this ch",
    "file": "cs/ai/2512.10807-harood-a-benchmark-for-out-of-distribution-genera.md"
  },
  {
    "arxiv_id": "2512.10895",
    "title": "LLMs Can Assist with Proposal Selection at Large User Facilities",
    "authors": [
      "Lijie Ding",
      "Janell Thomson",
      "Jon Taylor",
      "Changwoo Do"
    ],
    "date": "2025-12-11",
    "field": "cs-ai",
    "tags": [
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10895",
    "abstract": "We explore how large language models (LLMs) can enhance the proposal selection process at large user facilities, offering a scalable, consistent, and cost-effective alternative to traditional human review. Proposal selection depends on assessing the relative strength among submitted proposals; howev",
    "file": "cs/ai/2512.10895-llms-can-assist-with-proposal-selection-at-large-u.md"
  },
  {
    "arxiv_id": "2512.10903",
    "title": "Multi-Granular Node Pruning for Circuit Discovery",
    "authors": [
      "Muhammad Umair Haider",
      "Hammad Rizwan",
      "Hassan Sajjad",
      "A. B. Siddique"
    ],
    "date": "2025-12-11",
    "field": "cs-ai",
    "tags": [
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10903",
    "abstract": "Circuit discovery aims to identify minimal subnetworks that are responsible for specific behaviors in large language models (LLMs). Existing approaches primarily rely on iterative edge pruning, which is computationally expensive and limited to coarse-grained units such as attention heads or MLP bloc",
    "file": "cs/ai/2512.10903-multi-granular-node-pruning-for-circuit-discovery.md"
  },
  {
    "arxiv_id": "2512.10882",
    "title": "Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity",
    "authors": [
      "Hauke Licht"
    ],
    "date": "2025-12-11",
    "field": "cs-ai",
    "tags": [
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.10882",
    "abstract": "Emotions are central to politics and analyzing their role in political communication has a long tradition. As research increasingly leverages audio-visual materials to analyze the display of emotions, the emergence of multimodal generative AI promises great advances. However, we lack evidence about ",
    "file": "cs/ai/2512.10882-computational-emotion-analysis-with-multimodal-llm.md"
  },
  {
    "arxiv_id": "2512.10922",
    "title": "SparseSwaps: Tractable LLM Pruning Mask Refinement at Scale",
    "authors": [
      "Max Zimmer",
      "Christophe Roux",
      "Moritz Wagner",
      "Deborah Hendrych",
      "Sebastian Pokutta"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10922",
    "abstract": "The resource requirements of Neural Networks can be significantly reduced through pruning -- the removal of seemingly less important parameters. However, with the rise of Large Language Models (LLMs), full retraining to recover pruning-induced performance degradation is often prohibitive and classic",
    "file": "cs/lg/2512.10922-sparseswaps-tractable-llm-pruning-mask-refinement.md"
  },
  {
    "arxiv_id": "2512.10936",
    "title": "Empirical evaluation of the Frank-Wolfe methods for constructing white-box adversarial attacks",
    "authors": [
      "Kristina Korotkova",
      "Aleksandr Katrutsa"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10936",
    "abstract": "The construction of adversarial attacks for neural networks appears to be a crucial challenge for their deployment in various services. To estimate the adversarial robustness of a neural network, a fast and efficient approach is needed to construct adversarial attacks. Since the formalization of adv",
    "file": "cs/lg/2512.10936-empirical-evaluation-of-the-frank-wolfe-methods-fo.md"
  },
  {
    "arxiv_id": "2512.10953",
    "title": "Bidirectional Normalizing Flow: From Data to Noise and Back",
    "authors": [
      "Yiyang Lu",
      "Qiao Sun",
      "Xianbang Wang",
      "Zhicheng Jiang",
      "Hanhong Zhao",
      "Kaiming He"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10953",
    "abstract": "Normalizing Flows (NFs) have been established as a principled framework for generative modeling. Standard NFs consist of a forward process and a reverse process: the forward process maps data to noise, while the reverse process generates samples by inverting it. Typical NF forward transformations ar",
    "file": "cs/lg/2512.10953-bidirectional-normalizing-flow-from-data-to-noise.md"
  },
  {
    "arxiv_id": "2512.10817",
    "title": "Extrapolation of Periodic Functions Using Binary Encoding of Continuous Numerical Values",
    "authors": [
      "Brian P. Powell",
      "Jordan A. Caraballo-Vega",
      "Mark L. Carroll",
      "Thomas Maxwell",
      "Andrew Ptak",
      "Greg Olmschenk",
      "Jorge Martinez-Palomera"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "url": "https://arxiv.org/abs/2512.10817",
    "abstract": "We report the discovery that binary encoding allows neural networks to extrapolate periodic functions beyond their training bounds. We introduce Normalized Base-2 Encoding (NB2E) as a method for encoding continuous numerical values and demonstrate that, using this input encoding, vanilla multi-layer",
    "file": "cs/lg/2512.10817-extrapolation-of-periodic-functions-using-binary-e.md"
  },
  {
    "arxiv_id": "2512.10877",
    "title": "Guided Transfer Learning for Discrete Diffusion Models",
    "authors": [
      "Julian Kleutgens",
      "Claudio Battiloro",
      "Lingkai Kong",
      "Benjamin Grewe",
      "Francesca Dominici",
      "Mauricio Tec"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.10877",
    "abstract": "Discrete diffusion models achieve strong performance across language and other discrete domains, providing a powerful alternative to autoregressive models. However, their strong performance relies on large training datasets, which are costly or risky to obtain, especially when adapting to new domain",
    "file": "cs/lg/2512.10877-guided-transfer-learning-for-discrete-diffusion-mo.md"
  },
  {
    "arxiv_id": "2512.10866",
    "title": "UrbanAI 2025 Challenge: Linear vs Transformer Models for Long-Horizon Exogenous Temperature Forecasting",
    "authors": [
      "Ruslan Gokhman"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10866",
    "abstract": "We study long-horizon exogenous-only temperature forecasting - a challenging univariate setting where only the past values of the indoor temperature are used for prediction - using linear and Transformer-family models. We evaluate Linear, NLinear, DLinear, Transformer, Informer, and Autoformer under",
    "file": "cs/lg/2512.10866-urbanai-2025-challenge-linear-vs-transformer-mode.md"
  },
  {
    "arxiv_id": "2512.10858",
    "title": "Scaling Behavior of Discrete Diffusion Language Models",
    "authors": [
      "Dimitri von R\u00fctte",
      "Janis Fluri",
      "Omead Pooladzandi",
      "Bernhard Sch\u00f6lkopf",
      "Thomas Hofmann",
      "Antonio Orvieto"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.10858",
    "abstract": "Modern LLM pre-training consumes vast amounts of compute and training data, making the scaling behavior, or scaling laws, of different models a key distinguishing factor. Discrete diffusion language models (DLMs) have been proposed as an alternative to autoregressive language models (ALMs). However,",
    "file": "cs/lg/2512.10858-scaling-behavior-of-discrete-diffusion-language-mo.md"
  },
  {
    "arxiv_id": "2512.10938",
    "title": "Stronger Normalization-Free Transformers",
    "authors": [
      "Mingzhi Chen",
      "Taiming Lu",
      "Jiachen Zhu",
      "Mingjie Sun",
      "Zhuang Liu"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10938",
    "abstract": "Although normalization layers have long been viewed as indispensable components of deep learning architectures, the recent introduction of Dynamic Tanh (DyT) has demonstrated that alternatives are possible. The point-wise function DyT constrains extreme values for stable convergence and reaches norm",
    "file": "cs/lg/2512.10938-stronger-normalization-free-transformers.md"
  },
  {
    "arxiv_id": "2512.10925",
    "title": "Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation",
    "authors": [
      "Zamirddine Mari",
      "Mohamad Motasem Nawaf",
      "Pierre Drap"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.RO"
    ],
    "url": "https://arxiv.org/abs/2512.10925",
    "abstract": "Autonomous navigation in underwater environments remains a major challenge due to the absence of GPS, degraded visibility, and the presence of submerged obstacles. This article investigates these issues through the case of the BlueROV2, an open platform widely used for scientific experimentation. We",
    "file": "cs/lg/2512.10925-digital-twin-supervised-reinforcement-learning-fra.md"
  },
  {
    "arxiv_id": "2512.10835",
    "title": "Learning Controllable and Diverse Player Behaviors in Multi-Agent Environments",
    "authors": [
      "Atahan Cilan",
      "Atay \u00d6zg\u00f6vde"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.10835",
    "abstract": "This paper introduces a reinforcement learning framework that enables controllable and diverse player behaviors without relying on human gameplay data. Existing approaches often require large-scale player trajectories, train separate models for different player types, or provide no direct mapping be",
    "file": "cs/lg/2512.10835-learning-controllable-and-diverse-player-behaviors.md"
  },
  {
    "arxiv_id": "2512.10949",
    "title": "Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation",
    "authors": [
      "Yiwen Tang",
      "Zoey Guo",
      "Kaixin Zhu",
      "Ray Zhang",
      "Qizhi Chen",
      "Dongzhi Jiang",
      "Junli Liu",
      "Bohan Zeng",
      "Haoming Song",
      "Delin Qu",
      "Tianyi Bai",
      "Dan Xu",
      "Wentao Zhang",
      "Bin Zhao"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.10949",
    "abstract": "Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which req",
    "file": "cs/cv/2512.10949-are-we-ready-for-rl-in-text-to-3d-generation-a-pr.md"
  },
  {
    "arxiv_id": "2512.10943",
    "title": "AlcheMinT: Fine-grained Temporal Control for Multi-Reference Consistent Video Generation",
    "authors": [
      "Sharath Girish",
      "Viacheslav Ivanov",
      "Tsai-Shien Chen",
      "Hao Chen",
      "Aliaksandr Siarohin",
      "Sergey Tulyakov"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10943",
    "abstract": "Recent advances in subject-driven video generation with large diffusion models have enabled personalized content synthesis conditioned on user-provided subjects. However, existing methods lack fine-grained temporal control over subject appearance and disappearance, which are essential for applicatio",
    "file": "cs/cv/2512.10943-alchemint-fine-grained-temporal-control-for-multi.md"
  },
  {
    "arxiv_id": "2512.10947",
    "title": "Towards Efficient and Effective Multi-Camera Encoding for End-to-End Driving",
    "authors": [
      "Jiawei Yang",
      "Ziyu Chen",
      "Yurong You",
      "Yan Wang",
      "Yiming Li",
      "Yuxiao Chen",
      "Boyi Li",
      "Boris Ivanovic",
      "Marco Pavone",
      "Yue Wang"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10947",
    "abstract": "We present Flex, an efficient and effective scene encoder that addresses the computational bottleneck of processing high-volume multi-camera data in end-to-end autonomous driving. Flex employs a small set of learnable scene tokens to jointly encode information from all image tokens across different ",
    "file": "cs/cv/2512.10947-towards-efficient-and-effective-multi-camera-encod.md"
  },
  {
    "arxiv_id": "2512.10954",
    "title": "Group Diffusion: Enhancing Image Generation by Unlocking Cross-Sample Collaboration",
    "authors": [
      "Sicheng Mo",
      "Thao Nguyen",
      "Richard Zhang",
      "Nick Kolkin",
      "Siddharth Srinivasan Iyer",
      "Eli Shechtman",
      "Krishna Kumar Singh",
      "Yong Jae Lee",
      "Bolei Zhou",
      "Yuheng Li"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10954",
    "abstract": "In this work, we explore an untapped signal in diffusion model inference. While all previous methods generate images independently at inference, we instead ask if samples can be generated collaboratively. We propose Group Diffusion, unlocking the attention mechanism to be shared across images, rathe",
    "file": "cs/cv/2512.10954-group-diffusion-enhancing-image-generation-by-unl.md"
  },
  {
    "arxiv_id": "2512.10867",
    "title": "From Macro to Micro: Benchmarking Microscopic Spatial Intelligence on Molecules via Vision-Language Models",
    "authors": [
      "Zongzhao Li",
      "Xiangzhe Kong",
      "Jiahui Su",
      "Zongyang Ma",
      "Mingze Li",
      "Songyou Li",
      "Yuelin Zhang",
      "Yu Rong",
      "Tingyang Xu",
      "Deli Zhao",
      "Wenbing Huang"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10867",
    "abstract": "This paper introduces the concept of Microscopic Spatial Intelligence (MiSI), the capability to perceive and reason about the spatial relationships of invisible microscopic entities, which is fundamental to scientific discovery. To assess the potential of Vision-Language Models (VLMs) in this domain",
    "file": "cs/cv/2512.10867-from-macro-to-micro-benchmarking-microscopic-spat.md"
  },
  {
    "arxiv_id": "2512.10860",
    "title": "SWiT-4D: Sliding-Window Transformer for Lossless and Parameter-Free Temporal 4D Generation",
    "authors": [
      "Kehong Gong",
      "Zhengyu Wen",
      "Mingxi Xu",
      "Weixia He",
      "Qi Wang",
      "Ning Zhang",
      "Zhengyu Li",
      "Chenbin Li",
      "Dongze Lian",
      "Wei Zhao",
      "Xiaoyu He",
      "Mingyuan Zhang"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10860",
    "abstract": "Despite significant progress in 4D content generation, the conversion of monocular videos into high-quality animated 3D assets with explicit 4D meshes remains considerably challenging. The scarcity of large-scale, naturally captured 4D mesh datasets further limits the ability to train generalizable ",
    "file": "cs/cv/2512.10860-swit-4d-sliding-window-transformer-for-lossless-a.md"
  },
  {
    "arxiv_id": "2512.10935",
    "title": "Any4D: Unified Feed-Forward Metric 4D Reconstruction",
    "authors": [
      "Jay Karhade",
      "Nikhil Keetha",
      "Yuchen Zhang",
      "Tanisha Gupta",
      "Akash Sharma",
      "Sebastian Scherer",
      "Deva Ramanan"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "url": "https://arxiv.org/abs/2512.10935",
    "abstract": "We present Any4D, a scalable multi-view transformer for metric-scale, dense feed-forward 4D reconstruction. Any4D directly generates per-pixel motion and geometry predictions for N frames, in contrast to prior work that typically focuses on either 2-view dense scene flow or sparse 3D point tracking.",
    "file": "cs/cv/2512.10935-any4d-unified-feed-forward-metric-4d-reconstructi.md"
  },
  {
    "arxiv_id": "2512.10939",
    "title": "GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting",
    "authors": [
      "Madhav Agarwal",
      "Mingtian Zhang",
      "Laura Sevilla-Lara",
      "Steven McDonagh"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10939",
    "abstract": "Speech-driven talking heads have recently emerged and enable interactive avatars. However, real-world applications are limited, as current methods achieve high visual fidelity but slow or fast yet temporally unstable. Diffusion methods provide realistic image generation, yet struggle with oneshot se",
    "file": "cs/cv/2512.10939-gaussianheadtalk-wobble-free-3d-talking-heads-wit.md"
  },
  {
    "arxiv_id": "2512.10927",
    "title": "FoundationMotion: Auto-Labeling and Reasoning about Spatial Movement in Videos",
    "authors": [
      "Yulu Gan",
      "Ligeng Zhu",
      "Dandan Shan",
      "Baifeng Shi",
      "Hongxu Yin",
      "Boris Ivanovic",
      "Song Han",
      "Trevor Darrell",
      "Jitendra Malik",
      "Marco Pavone",
      "Boyi Li"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10927",
    "abstract": "Motion understanding is fundamental to physical reasoning, enabling models to infer dynamics and predict future states. However, state-of-the-art models still struggle on recent motion benchmarks, primarily due to the scarcity of large-scale, fine-grained motion datasets. Existing motion datasets ar",
    "file": "cs/cv/2512.10927-foundationmotion-auto-labeling-and-reasoning-abou.md"
  },
  {
    "arxiv_id": "2512.10940",
    "title": "OmniView: An All-Seeing Diffusion Model for 3D and 4D View Synthesis",
    "authors": [
      "Xiang Fan",
      "Sharath Girish",
      "Vivek Ramanujan",
      "Chaoyang Wang",
      "Ashkan Mirzaei",
      "Petr Sushko",
      "Aliaksandr Siarohin",
      "Sergey Tulyakov",
      "Ranjay Krishna"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10940",
    "abstract": "Prior approaches injecting camera control into diffusion models have focused on specific subsets of 4D consistency tasks: novel view synthesis, text-to-video with camera control, image-to-video, amongst others. Therefore, these fragmented approaches are trained on disjoint slices of available 3D/4D ",
    "file": "cs/cv/2512.10940-omniview-an-all-seeing-diffusion-model-for-3d-and.md"
  },
  {
    "arxiv_id": "2512.10808",
    "title": "Graph Laplacian Transformer with Progressive Sampling for Prostate Cancer Grading",
    "authors": [
      "Masum Shah Junayed",
      "John Derek Van Vessem",
      "Qian Wan",
      "Gahie Nam",
      "Sheida Nabavi"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10808",
    "abstract": "Prostate cancer grading from whole-slide images (WSIs) remains a challenging task due to the large-scale nature of WSIs, the presence of heterogeneous tissue structures, and difficulty of selecting diagnostically relevant regions. Existing approaches often rely on random or static patch selection, l",
    "file": "cs/cv/2512.10808-graph-laplacian-transformer-with-progressive-sampl.md"
  },
  {
    "arxiv_id": "2512.10932",
    "title": "BabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models",
    "authors": [
      "Shengao Wang",
      "Wenqi Wang",
      "Zecheng Wang",
      "Max Whitton",
      "Michael Wakeham",
      "Arjun Chandra",
      "Joey Huang",
      "Pengyue Zhu",
      "Helen Chen",
      "David Li",
      "Jeffrey Li",
      "Shawn Li",
      "Andrew Zagula",
      "Amy Zhao",
      "Andrew Zhu",
      "Sayaka Nakamura",
      "Yuki Yamamoto",
      "Jerry Jun Yokono",
      "Aaron Mueller",
      "Bryan A. Plummer",
      "Kate Saenko",
      "Venkatesh Saligrama",
      "Boqing Gong"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10932",
    "abstract": "Early children's developmental trajectories set up a natural goal for sample-efficient pretraining of vision foundation models. We introduce BabyVLM-V2, a developmentally grounded framework for infant-inspired vision-language modeling that extensively improves upon BabyVLM-V1 through a longitudinal,",
    "file": "cs/cv/2512.10932-babyvlm-v2-toward-developmentally-grounded-pretra.md"
  },
  {
    "arxiv_id": "2512.10840",
    "title": "PoseGAM: Robust Unseen Object Pose Estimation via Geometry-Aware Multi-View Reasoning",
    "authors": [
      "Jianqi Chen",
      "Biao Zhang",
      "Xiangjun Tang",
      "Peter Wonka"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10840",
    "abstract": "6D object pose estimation, which predicts the transformation of an object relative to the camera, remains challenging for unseen objects. Existing approaches typically rely on explicitly constructing feature correspondences between the query image and either the object model or template images. In t",
    "file": "cs/cv/2512.10840-posegam-robust-unseen-object-pose-estimation-via.md"
  },
  {
    "arxiv_id": "2512.10888",
    "title": "PubTables-v2: A new large-scale dataset for full-page and multi-page table extraction",
    "authors": [
      "Brandon Smock",
      "Valerie Faucon-Morin",
      "Max Sokolov",
      "Libin Liang",
      "Tayyibah Khanam",
      "Maury Courtland"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10888",
    "abstract": "Table extraction (TE) is a key challenge in visual document understanding. Traditional approaches detect tables first, then recognize their structure. Recently, interest has surged in developing methods, such as vision-language models (VLMs), that can extract tables directly in their full page or do",
    "file": "cs/cv/2512.10888-pubtables-v2-a-new-large-scale-dataset-for-full-p.md"
  },
  {
    "arxiv_id": "2512.10934",
    "title": "Curriculum-Based Reinforcement Learning for Autonomous UAV Navigation in Unknown Curved Tubular Conduit",
    "authors": [
      "Zamirddine Mari",
      "J\u00e9r\u00f4me Pasquet",
      "Julien Seinturier"
    ],
    "date": "2025-12-11",
    "field": "other",
    "tags": [
      "cs.RO",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.10934",
    "abstract": "Autonomous drone navigation in confined tubular environments remains a major challenge due to the constraining geometry of the conduits, the proximity of the walls, and the perceptual limitations inherent to such scenarios. We propose a reinforcement learning approach enabling a drone to navigate un",
    "file": "other/2512.10934-curriculum-based-reinforcement-learning-for-autono.md"
  },
  {
    "arxiv_id": "2512.10891",
    "title": "Iterative Compositional Data Generation for Robot Control",
    "authors": [
      "Anh-Quan Pham",
      "Marcel Hussing",
      "Shubhankar P. Patankar",
      "Dani S. Bassett",
      "Jorge Mendez-Mendez",
      "Eric Eaton"
    ],
    "date": "2025-12-11",
    "field": "other",
    "tags": [
      "cs.RO",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.10891",
    "abstract": "Collecting robotic manipulation data is expensive, making it impractical to acquire demonstrations for the combinatorially large space of tasks that arise in multi-object, multi-robot, and multi-environment settings. While recent generative models can synthesize useful data for individual tasks, the",
    "file": "other/2512.10891-iterative-compositional-data-generation-for-robot.md"
  }
]