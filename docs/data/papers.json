[
  {
    "arxiv_id": "2512.23684",
    "title": "Multilingual Hidden Prompt Injection Attacks on LLM-Based Academic Reviewing",
    "authors": [
      "Panagiotis Theocharopoulos",
      "Ajinkya Kulkarni",
      "Mathew Magimai. -Doss"
    ],
    "date": "2025-12-29",
    "field": "cs-ai",
    "tags": [
      "cs.CL",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.23684",
    "abstract": "Large language models (LLMs) are increasingly considered for use in high-impact workflows, including academic peer review. However, LLMs are vulnerable to document-level hidden prompt injection attacks. In this work, we construct a dataset of approximately 500 real academic papers accepted to ICML a",
    "file": "cs/ai/2512.23684-multilingual-hidden-prompt-injection-attacks-on-ll.md"
  },
  {
    "arxiv_id": "2512.23328",
    "title": "CubeBench: Diagnosing Interactive, Long-Horizon Spatial Reasoning Under Partial Observations",
    "authors": [
      "Huan-ang Gao",
      "Zikang Zhang",
      "Tianwei Luo",
      "Kaisen Yang",
      "Xinzhe Juan",
      "Jiahao Qiu",
      "Tianxing Chen",
      "Bingxiang He",
      "Hao Zhao",
      "Hao Zhou",
      "Shilong Liu",
      "Mengdi Wang"
    ],
    "date": "2025-12-29",
    "field": "cs-ai",
    "tags": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.23328",
    "abstract": "Large Language Model (LLM) agents, while proficient in the digital realm, face a significant gap in physical-world deployment due to the challenge of forming and maintaining a robust spatial mental model. We identify three core cognitive challenges hindering this transition: spatial reasoning, long-",
    "file": "cs/ai/2512.23328-cubebench-diagnosing-interactive-long-horizon-sp.md"
  },
  {
    "arxiv_id": "2512.23676",
    "title": "Web World Models",
    "authors": [
      "Jichen Feng",
      "Yifan Zhang",
      "Chenggong Zhang",
      "Yifu Lu",
      "Shilong Liu",
      "Mengdi Wang"
    ],
    "date": "2025-12-29",
    "field": "cs-ai",
    "tags": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.23676",
    "abstract": "Language agents increasingly require persistent worlds in which they can act, remember, and learn. Existing approaches sit at two extremes: conventional web frameworks provide reliable but fixed contexts backed by databases, while fully generative world models aim for unlimited environments at the e",
    "file": "cs/ai/2512.23676-web-world-models.md"
  },
  {
    "arxiv_id": "2512.23624",
    "title": "Physics-Informed Neural Networks for Device and Circuit Modeling: A Case Study of NeuroSPICE",
    "authors": [
      "Chien-Ting Tung",
      "Chenming Hu"
    ],
    "date": "2025-12-29",
    "field": "cs-ai",
    "tags": [
      "cs.AI",
      "physics.app-ph"
    ],
    "url": "https://arxiv.org/abs/2512.23624",
    "abstract": "We present NeuroSPICE, a physics-informed neural network (PINN) framework for device and circuit simulation. Unlike conventional SPICE, which relies on time-discretized numerical solvers, NeuroSPICE leverages PINNs to solve circuit differential-algebraic equations (DAEs) by minimizing the residual o",
    "file": "cs/ai/2512.23624-physics-informed-neural-networks-for-device-and-ci.md"
  },
  {
    "arxiv_id": "2512.23701",
    "title": "Eliciting Behaviors in Multi-Turn Conversations",
    "authors": [
      "Jing Huang",
      "Shujian Zhang",
      "Lun Wang",
      "Andrew Hard",
      "Rajiv Mathews",
      "John Lambert"
    ],
    "date": "2025-12-29",
    "field": "cs-ai",
    "tags": [
      "cs.CL",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.23701",
    "abstract": "Identifying specific and often complex behaviors from large language models (LLMs) in conversational settings is crucial for their evaluation. Recent work proposes novel techniques to find natural language prompts that induce specific behaviors from a target model, yet they are mainly studied in sin",
    "file": "cs/ai/2512.23701-eliciting-behaviors-in-multi-turn-conversations.md"
  },
  {
    "arxiv_id": "2512.23675",
    "title": "End-to-End Test-Time Training for Long Context",
    "authors": [
      "Arnuv Tandon",
      "Karan Dalal",
      "Xinhao Li",
      "Daniel Koceja",
      "Marcel R\u00f8d",
      "Sam Buchanan",
      "Xiaolong Wang",
      "Jure Leskovec",
      "Sanmi Koyejo",
      "Tatsunori Hashimoto",
      "Carlos Guestrin",
      "Jed McCaleb",
      "Yejin Choi",
      "Yu Sun"
    ],
    "date": "2025-12-29",
    "field": "cs-lg",
    "tags": [
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.23675",
    "abstract": "We formulate long-context language modeling as a problem in continual learning rather than architecture design. Under this formulation, we only use a standard architecture -- a Transformer with sliding-window attention. However, our model continues learning at test time via next-token prediction on ",
    "file": "cs/lg/2512.23675-end-to-end-test-time-training-for-long-context.md"
  },
  {
    "arxiv_id": "2512.23617",
    "title": "Le Cam Distortion: A Decision-Theoretic Framework for Robust Transfer Learning",
    "authors": [
      "Deniz Akdemir"
    ],
    "date": "2025-12-29",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ME",
      "stat.ML"
    ],
    "url": "https://arxiv.org/abs/2512.23617",
    "abstract": "Distribution shift is the defining challenge of real-world machine learning. The dominant paradigm--Unsupervised Domain Adaptation (UDA)--enforces feature invariance, aligning source and target representations via symmetric divergence minimization [Ganin et al., 2016]. We demonstrate that this appro",
    "file": "cs/lg/2512.23617-le-cam-distortion-a-decision-theoretic-framework.md"
  },
  {
    "arxiv_id": "2512.23329",
    "title": "Deep learning for pedestrians: backpropagation in Transformers",
    "authors": [
      "Laurent Bou\u00e9"
    ],
    "date": "2025-12-29",
    "field": "cs-lg",
    "tags": [
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.23329",
    "abstract": "This document is a follow-up to our previous paper dedicated to a vectorized derivation of backpropagation in CNNs. Following the same principles and notations already put in place there, we now focus on transformer-based next-token-prediction architectures. To this end, we apply our lightweight ind",
    "file": "cs/lg/2512.23329-deep-learning-for-pedestrians-backpropagation-in.md"
  },
  {
    "arxiv_id": "2512.23707",
    "title": "Training AI Co-Scientists Using Rubric Rewards",
    "authors": [
      "Shashwat Goel",
      "Rishi Hazra",
      "Dulhan Jayalath",
      "Timon Willi",
      "Parag Jain",
      "William F. Shen",
      "Ilias Leontiadis",
      "Francesco Barbieri",
      "Yoram Bachrach",
      "Jonas Geiping",
      "Chenxi Whitehouse"
    ],
    "date": "2025-12-29",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.CL",
      "cs.HC"
    ],
    "url": "https://arxiv.org/abs/2512.23707",
    "abstract": "AI co-scientists are emerging as a tool to assist human researchers in achieving their research goals. A crucial feature of these AI co-scientists is the ability to generate a research plan given a set of aims and constraints. The plan may be used by researchers for brainstorming, or may even be imp",
    "file": "cs/lg/2512.23707-training-ai-co-scientists-using-rubric-rewards.md"
  },
  {
    "arxiv_id": "2512.23631",
    "title": "BOAD: Discovering Hierarchical Software Engineering Agents via Bandit Optimization",
    "authors": [
      "Iris Xu",
      "Guangtao Zeng",
      "Zexue He",
      "Charles Jin",
      "Aldo Pareja",
      "Dan Gutfreund",
      "Chuang Gan",
      "Zhang-Wei Hong"
    ],
    "date": "2025-12-29",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.23631",
    "abstract": "Large language models (LLMs) have shown strong reasoning and coding capabilities, yet they struggle to generalize to real-world software engineering (SWE) problems that are long-horizon and out of distribution. Existing systems often rely on a single agent to handle the entire workflow-interpreting ",
    "file": "cs/lg/2512.23631-boad-discovering-hierarchical-software-engineerin.md"
  },
  {
    "arxiv_id": "2512.23628",
    "title": "Memorization in 3D Shape Generation: An Empirical Study",
    "authors": [
      "Shu Pu",
      "Boya Zeng",
      "Kaichen Zhou",
      "Mengyu Wang",
      "Zhuang Liu"
    ],
    "date": "2025-12-29",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.23628",
    "abstract": "Generative models are increasingly used in 3D vision to synthesize novel shapes, yet it remains unclear whether their generation relies on memorizing training shapes. Understanding their memorization could help prevent training data leakage and improve the diversity of generated results. In this pap",
    "file": "cs/cv/2512.23628-memorization-in-3d-shape-generation-an-empirical.md"
  },
  {
    "arxiv_id": "2512.23705",
    "title": "Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation",
    "authors": [
      "Shaocong Xu",
      "Songlin Wei",
      "Qizhe Wei",
      "Zheng Geng",
      "Hong Li",
      "Licheng Shen",
      "Qianpu Sun",
      "Shu Han",
      "Bin Ma",
      "Bohan Li",
      "Chongjie Ye",
      "Yuhang Zheng",
      "Nan Wang",
      "Saining Zhang",
      "Hao Zhao"
    ],
    "date": "2025-12-29",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.23705",
    "abstract": "Transparent objects remain notoriously hard for perception systems: refraction, reflection and transmission break the assumptions behind stereo, ToF and purely discriminative monocular depth, causing holes and temporally unstable estimates. Our key observation is that modern video diffusion models a",
    "file": "cs/cv/2512.23705-diffusion-knows-transparency-repurposing-video-di.md"
  },
  {
    "arxiv_id": "2512.23333",
    "title": "CME-CAD: Heterogeneous Collaborative Multi-Expert Reinforcement Learning for CAD Code Generation",
    "authors": [
      "Ke Niu",
      "Haiyang Yu",
      "Zhuofan Chen",
      "Zhengtao Yao",
      "Weitao Jia",
      "Xiaodong Ge",
      "Jingqun Tang",
      "Benlei Cui",
      "Bin Li",
      "Xiangyang Xue"
    ],
    "date": "2025-12-29",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.23333",
    "abstract": "Computer-Aided Design (CAD) is essential in industrial design, but the complexity of traditional CAD modeling and workflows presents significant challenges for automating the generation of high-precision, editable CAD models. Existing methods that reconstruct 3D models from sketches often produce no",
    "file": "cs/cv/2512.23333-cme-cad-heterogeneous-collaborative-multi-expert.md"
  },
  {
    "arxiv_id": "2512.23646",
    "title": "OmniAgent: Audio-Guided Active Perception Agent for Omnimodal Audio-Video Understanding",
    "authors": [
      "Keda Tao",
      "Wenjie Du",
      "Bohan Yu",
      "Weiqiang Wang",
      "Jian Liu",
      "Huan Wang"
    ],
    "date": "2025-12-29",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.23646",
    "abstract": "Omnimodal large language models have made significant strides in unifying audio and visual modalities; however, they often lack the fine-grained cross-modal understanding and have difficulty with multimodal alignment. To address these limitations, we introduce OmniAgent, a fully audio-guided active ",
    "file": "cs/cv/2512.23646-omniagent-audio-guided-active-perception-agent-fo.md"
  },
  {
    "arxiv_id": "2512.23667",
    "title": "IDT: A Physically Grounded Transformer for Feed-Forward Multi-View Intrinsic Decomposition",
    "authors": [
      "Kang Du",
      "Yirui Guan",
      "Zeyu Wang"
    ],
    "date": "2025-12-29",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.23667",
    "abstract": "Intrinsic image decomposition is fundamental for visual understanding, as RGB images entangle material properties, illumination, and view-dependent effects. Recent diffusion-based methods have achieved strong results for single-view intrinsic decomposition; however, extending these approaches to mul",
    "file": "cs/cv/2512.23667-idt-a-physically-grounded-transformer-for-feed-fo.md"
  },
  {
    "arxiv_id": "2512.23643",
    "title": "Simultaneous Approximation of the Score Function and Its Derivatives by Deep Neural Networks",
    "authors": [
      "Konstantin Yakovlev",
      "Nikita Puchkin"
    ],
    "date": "2025-12-29",
    "field": "other",
    "tags": [
      "math.NA",
      "cs.LG",
      "math.ST",
      "stat.ML"
    ],
    "url": "https://arxiv.org/abs/2512.23643",
    "abstract": "We present a theory for simultaneous approximation of the score function and its derivatives, enabling the handling of data distributions with low-dimensional structure and unbounded support. Our approximation error bounds match those in the literature while relying on assumptions that relax the usu",
    "file": "other/2512.23643-simultaneous-approximation-of-the-score-function-a.md"
  },
  {
    "arxiv_id": "2512.23694",
    "title": "Bellman Calibration for V-Learning in Offline Reinforcement Learning",
    "authors": [
      "Lars van der Laan",
      "Nathan Kallus"
    ],
    "date": "2025-12-29",
    "field": "other",
    "tags": [
      "stat.ML",
      "cs.LG",
      "econ.EM"
    ],
    "url": "https://arxiv.org/abs/2512.23694",
    "abstract": "We introduce Iterated Bellman Calibration, a simple, model-agnostic, post-hoc procedure for calibrating off-policy value predictions in infinite-horizon Markov decision processes. Bellman calibration requires that states with similar predicted long-term returns exhibit one-step returns consistent wi",
    "file": "other/2512.23694-bellman-calibration-for-v-learning-in-offline-rein.md"
  },
  {
    "arxiv_id": "2512.23312",
    "title": "Explainable Neural Inverse Kinematics for Obstacle-Aware Robotic Manipulation: A Comparative Analysis of IKNet Variants",
    "authors": [
      "Sheng-Kai Chen",
      "Yi-Ling Tsai",
      "Chun-Chih Chang",
      "Yan-Chen Chen",
      "Po-Chiang Lin"
    ],
    "date": "2025-12-29",
    "field": "other",
    "tags": [
      "cs.RO",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.23312",
    "abstract": "Deep neural networks have accelerated inverse-kinematics (IK) inference to the point where low cost manipulators can execute complex trajectories in real time, yet the opaque nature of these models contradicts the transparency and safety requirements emerging in responsible AI regulation. This study",
    "file": "other/2512.23312-explainable-neural-inverse-kinematics-for-obstacle.md"
  },
  {
    "arxiv_id": "2512.23633",
    "title": "AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms",
    "authors": [
      "LearnLM Team",
      "Eedi",
      ":",
      "Albert Wang",
      "Aliya Rysbek",
      "Andrea Huber",
      "Anjali Nambiar",
      "Anna Kenolty",
      "Ben Caulfield",
      "Beth Lilley-Draper",
      "Bibi Groot",
      "Brian Veprek",
      "Chelsea Burdett",
      "Claire Willis",
      "Craig Barton",
      "Digory Smith",
      "George Mu",
      "Harriet Walters",
      "Irina Jurenka",
      "Iris Hulls",
      "James Stalley-Moores",
      "Jonathan Caton",
      "Julia Wilkowski",
      "Kaiz Alarakyia",
      "Kevin R. McKee",
      "Liam McCafferty",
      "Lucy Dalton",
      "Markus Kunesch",
      "Pauline Malubay",
      "Rachel Kidson",
      "Rich Wells",
      "Sam Wheeler",
      "Sara Wiltberger",
      "Shakir Mohamed",
      "Simon Woodhead",
      "Vasco Braz\u00e3o"
    ],
    "date": "2025-12-29",
    "field": "other",
    "tags": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.23633",
    "abstract": "One-to-one tutoring is widely considered the gold standard for personalized education, yet it remains prohibitively expensive to scale. To evaluate whether generative AI might help expand access to this resource, we conducted an exploratory randomized controlled trial (RCT) with $N = 165$ students a",
    "file": "other/2512.23633-ai-tutoring-can-safely-and-effectively-support-stu.md"
  },
  {
    "arxiv_id": "2512.23318",
    "title": "PCR-ORB: Enhanced ORB-SLAM3 with Point Cloud Refinement Using Deep Learning-Based Dynamic Object Filtering",
    "authors": [
      "Sheng-Kai Chen",
      "Jie-Yu Chao",
      "Jr-Yu Chang",
      "Po-Lien Wu",
      "Po-Chiang Lin"
    ],
    "date": "2025-12-29",
    "field": "other",
    "tags": [
      "cs.RO",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.23318",
    "abstract": "Visual Simultaneous Localization and Mapping (vSLAM) systems encounter substantial challenges in dynamic environments where moving objects compromise tracking accuracy and map consistency. This paper introduces PCR-ORB (Point Cloud Refinement ORB), an enhanced ORB-SLAM3 framework that integrates dee",
    "file": "other/2512.23318-pcr-orb-enhanced-orb-slam3-with-point-cloud-refin.md"
  },
  {
    "arxiv_id": "2512.21280",
    "title": "SMART SLM: Structured Memory and Reasoning Transformer, A Small Language Model for Accurate Document Assistance",
    "authors": [
      "Divij Dudeja",
      "Mayukha Pal"
    ],
    "date": "2025-12-24",
    "field": "cs-ai",
    "tags": [
      "cs.CL",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.21280",
    "abstract": "The user of Engineering Manuals (EM) finds it difficult to read EM s because they are long, have a dense format which includes written documents, step by step procedures, and standard parameter lists for engineering equipment. Off the shelf transformers, especially compact ones, treat this material ",
    "file": "cs/ai/2512.21280-smart-slm-structured-memory-and-reasoning-transfo.md"
  },
  {
    "arxiv_id": "2512.21336",
    "title": "Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty",
    "authors": [
      "Ziyu Chen",
      "Xinbei Jiang",
      "Peng Sun",
      "Tao Lin"
    ],
    "date": "2025-12-24",
    "field": "cs-ai",
    "tags": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.21336",
    "abstract": "Masked Diffusion Models (MDMs) offer flexible, non-autoregressive generation, but this freedom introduces a challenge: final output quality is highly sensitive to the decoding order. We are the first to formalize this issue, attributing the variability in output quality to the cumulative predictive ",
    "file": "cs/ai/2512.21336-optimizing-decoding-paths-in-masked-diffusion-mode.md"
  },
  {
    "arxiv_id": "2512.21323",
    "title": "Parallel Token Prediction for Language Models",
    "authors": [
      "Felix Draxler",
      "Justus Will",
      "Farrin Marouf Sofian",
      "Theofanis Karaletsos",
      "Sameer Singh",
      "Stephan Mandt"
    ],
    "date": "2025-12-24",
    "field": "cs-ai",
    "tags": [
      "cs.CL",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.21323",
    "abstract": "We propose Parallel Token Prediction (PTP), a universal framework for parallel sequence generation in language models. PTP jointly predicts multiple dependent tokens in a single transformer call by incorporating the sampling procedure into the model. This reduces the latency bottleneck of autoregres",
    "file": "cs/ai/2512.21323-parallel-token-prediction-for-language-models.md"
  },
  {
    "arxiv_id": "2512.21332",
    "title": "C2LLM Technical Report: A New Frontier in Code Retrieval via Adaptive Cross-Attention Pooling",
    "authors": [
      "Jin Qin",
      "Zihan Liao",
      "Ziyin Zhang",
      "Hang Yu",
      "Peng Di",
      "Rui Wang"
    ],
    "date": "2025-12-24",
    "field": "cs-ai",
    "tags": [
      "cs.CL",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.21332",
    "abstract": "We present C2LLM - Contrastive Code Large Language Models, a family of code embedding models in both 0.5B and 7B sizes. Building upon Qwen-2.5-Coder backbones, C2LLM adopts a Pooling by Multihead Attention (PMA) module for generating sequence embedding from token embeddings, effectively 1) utilizing",
    "file": "cs/ai/2512.21332-c2llm-technical-report-a-new-frontier-in-code-ret.md"
  },
  {
    "arxiv_id": "2512.21315",
    "title": "Does the Data Processing Inequality Reflect Practice? On the Utility of Low-Level Tasks",
    "authors": [
      "Roy Turgeman",
      "Tom Tirer"
    ],
    "date": "2025-12-24",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ],
    "url": "https://arxiv.org/abs/2512.21315",
    "abstract": "The data processing inequality is an information-theoretic principle stating that the information content of a signal cannot be increased by processing the observations. In particular, it suggests that there is no benefit in enhancing the signal or encoding it before addressing a classification prob",
    "file": "cs/lg/2512.21315-does-the-data-processing-inequality-reflect-practi.md"
  },
  {
    "arxiv_id": "2512.21331",
    "title": "TICON: A Slide-Level Tile Contextualizer for Histopathology Representation Learning",
    "authors": [
      "Varun Belagali",
      "Saarthak Kapse",
      "Pierre Marza",
      "Srijan Das",
      "Zilinghan Li",
      "Sofi\u00e8ne Boutaj",
      "Pushpak Pati",
      "Srikar Yellapragada",
      "Tarak Nath Nandi",
      "Ravi K Madduri",
      "Joel Saltz",
      "Prateek Prasanna",
      "Stergios Christodoulidis Maria Vakalopoulou",
      "Dimitris Samaras"
    ],
    "date": "2025-12-24",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.21331",
    "abstract": "The interpretation of small tiles in large whole slide images (WSI) often needs a larger image context. We introduce TICON, a transformer-based tile representation contextualizer that produces rich, contextualized embeddings for ''any'' application in computational pathology. Standard tile encoder-b",
    "file": "cs/cv/2512.21331-ticon-a-slide-level-tile-contextualizer-for-histo.md"
  },
  {
    "arxiv_id": "2512.21338",
    "title": "HiStream: Efficient High-Resolution Video Generation via Redundancy-Eliminated Streaming",
    "authors": [
      "Haonan Qiu",
      "Shikun Liu",
      "Zijian Zhou",
      "Zhaochong An",
      "Weiming Ren",
      "Zhiheng Liu",
      "Jonas Schult",
      "Sen He",
      "Shoufa Chen",
      "Yuren Cong",
      "Tao Xiang",
      "Ziwei Liu",
      "Juan-Manuel Perez-Rua"
    ],
    "date": "2025-12-24",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.21338",
    "abstract": "High-resolution video generation, while crucial for digital media and film, is computationally bottlenecked by the quadratic complexity of diffusion models, making practical inference infeasible. To address this, we introduce HiStream, an efficient autoregressive framework that systematically reduce",
    "file": "cs/cv/2512.21338-histream-efficient-high-resolution-video-generati.md"
  },
  {
    "arxiv_id": "2512.21333",
    "title": "Fast SAM2 with Text-Driven Token Pruning",
    "authors": [
      "Avilasha Mandal",
      "Chaoning Zhang",
      "Fachrina Dewi Puspitasari",
      "Xudong Wang",
      "Jiaquan Zhang",
      "Caiyan Qin",
      "Guoqing Wang",
      "Yang Yang",
      "Heng Tao Shen"
    ],
    "date": "2025-12-24",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.21333",
    "abstract": "Segment Anything Model 2 (SAM2), a vision foundation model has significantly advanced in prompt-driven video object segmentation, yet their practical deployment remains limited by the high computational and memory cost of processing dense visual tokens across time. The SAM2 pipelines typically propa",
    "file": "cs/cv/2512.21333-fast-sam2-with-text-driven-token-pruning.md"
  },
  {
    "arxiv_id": "2512.21276",
    "title": "GriDiT: Factorized Grid-Based Diffusion for Efficient Long Image Sequence Generation",
    "authors": [
      "Snehal Singh Tomar",
      "Alexandros Graikos",
      "Arjun Krishna",
      "Dimitris Samaras",
      "Klaus Mueller"
    ],
    "date": "2025-12-24",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.21276",
    "abstract": "Modern deep learning methods typically treat image sequences as large tensors of sequentially stacked frames. However, is this straightforward representation ideal given the current state-of-the-art (SoTA)? In this work, we address this question in the context of generative models and aim to devise ",
    "file": "cs/cv/2512.21276-gridit-factorized-grid-based-diffusion-for-effici.md"
  },
  {
    "arxiv_id": "2512.21268",
    "title": "ACD: Direct Conditional Control for Video Diffusion Models via Attention Supervision",
    "authors": [
      "Weiqi Li",
      "Zehao Zhang",
      "Liang Lin",
      "Guangrun Wang"
    ],
    "date": "2025-12-24",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.21268",
    "abstract": "Controllability is a fundamental requirement in video synthesis, where accurate alignment with conditioning signals is essential. Existing classifier-free guidance methods typically achieve conditioning indirectly by modeling the joint distribution of data and conditions, which often results in limi",
    "file": "cs/cv/2512.21268-acd-direct-conditional-control-for-video-diffusio.md"
  },
  {
    "arxiv_id": "2512.21284",
    "title": "Surgical Scene Segmentation using a Spike-Driven Video Transformer with Real-Time Potential",
    "authors": [
      "Shihao Zou",
      "Jingjing Li",
      "Wei Ji",
      "Jincai Huang",
      "Kai Wang",
      "Guo Dan",
      "Weixin Si",
      "Yi Pan"
    ],
    "date": "2025-12-24",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.21284",
    "abstract": "Modern surgical systems increasingly rely on intelligent scene understanding to provide timely situational awareness for enhanced intra-operative safety. Within this pipeline, surgical scene segmentation plays a central role in accurately perceiving operative events. Although recent deep learning mo",
    "file": "cs/cv/2512.21284-surgical-scene-segmentation-using-a-spike-driven-v.md"
  },
  {
    "arxiv_id": "2512.21287",
    "title": "Post-Processing Mask-Based Table Segmentation for Structural Coordinate Extraction",
    "authors": [
      "Suren Bandara"
    ],
    "date": "2025-12-24",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.21287",
    "abstract": "Structured data extraction from tables plays a crucial role in document image analysis for scanned documents and digital archives. Although many methods have been proposed to detect table structures and extract cell contents, accurately identifying table segment boundaries (rows and columns) remains",
    "file": "cs/cv/2512.21287-post-processing-mask-based-table-segmentation-for.md"
  },
  {
    "arxiv_id": "2512.21252",
    "title": "DreaMontage: Arbitrary Frame-Guided One-Shot Video Generation",
    "authors": [
      "Jiawei Liu",
      "Junqiao Li",
      "Jiangfan Deng",
      "Gen Li",
      "Siyu Zhou",
      "Zetao Fang",
      "Shanshan Lao",
      "Zengde Deng",
      "Jianing Zhu",
      "Tingting Ma",
      "Jiayi Li",
      "Yunqiu Wang",
      "Qian He",
      "Xinglong Wu"
    ],
    "date": "2025-12-24",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.21252",
    "abstract": "The \"one-shot\" technique represents a distinct and sophisticated aesthetic in filmmaking. However, its practical realization is often hindered by prohibitive costs and complex real-world constraints. Although emerging video generation models offer a virtual alternative, existing approaches typically",
    "file": "cs/cv/2512.21252-dreamontage-arbitrary-frame-guided-one-shot-video.md"
  },
  {
    "arxiv_id": "2512.21316",
    "title": "Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Consulting, Data Analyst, and Management Tasks",
    "authors": [
      "Ali Merali"
    ],
    "date": "2025-12-24",
    "field": "other",
    "tags": [
      "econ.GN",
      "cs.AI",
      "cs.HC"
    ],
    "url": "https://arxiv.org/abs/2512.21316",
    "abstract": "This paper derives `Scaling Laws for Economic Impacts' -- empirical relationships between the training compute of Large Language Models (LLMs) and professional productivity. In a preregistered experiment, over 500 consultants, data analysts, and managers completed professional tasks using one of 13 ",
    "file": "other/2512.21316-scaling-laws-for-economic-productivity-experiment.md"
  },
  {
    "arxiv_id": "2512.21238",
    "title": "Assessing the Software Security Comprehension of Large Language Models",
    "authors": [
      "Mohammed Latif Siddiq",
      "Natalie Sekerak",
      "Antonio Karam",
      "Maria Leal",
      "Arvin Islam-Gomes",
      "Joanna C. S. Santos"
    ],
    "date": "2025-12-24",
    "field": "other",
    "tags": [
      "cs.SE",
      "cs.CR",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.21238",
    "abstract": "Large language models (LLMs) are increasingly used in software development, but their level of software security expertise remains unclear. This work systematically evaluates the security comprehension of five leading LLMs: GPT-4o-Mini, GPT-5-Mini, Gemini-2.5-Flash, Llama-3.1, and Qwen-2.5, using Bl",
    "file": "other/2512.21238-assessing-the-software-security-comprehension-of-l.md"
  },
  {
    "arxiv_id": "2512.21243",
    "title": "LookPlanGraph: Embodied Instruction Following Method with VLM Graph Augmentation",
    "authors": [
      "Anatoly O. Onishchenko",
      "Alexey K. Kovalev",
      "Aleksandr I. Panov"
    ],
    "date": "2025-12-24",
    "field": "other",
    "tags": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.21243",
    "abstract": "Methods that use Large Language Models (LLM) as planners for embodied instruction following tasks have become widespread. To successfully complete tasks, the LLM must be grounded in the environment in which the robot operates. One solution is to use a scene graph that contains all the necessary info",
    "file": "other/2512.21243-lookplangraph-embodied-instruction-following-meth.md"
  },
  {
    "arxiv_id": "2512.21236",
    "title": "Casting a SPELL: Sentence Pairing Exploration for LLM Limitation-breaking",
    "authors": [
      "Yifan Huang",
      "Xiaojun Jia",
      "Wenbo Guo",
      "Yuqiang Sun",
      "Yihao Huang",
      "Chong Wang",
      "Yang Liu"
    ],
    "date": "2025-12-24",
    "field": "other",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "url": "https://arxiv.org/abs/2512.21236",
    "abstract": "Large language models (LLMs) have revolutionized software development through AI-assisted coding tools, enabling developers with limited programming expertise to create sophisticated applications. However, this accessibility extends to malicious actors who may exploit these powerful tools to generat",
    "file": "other/2512.21236-casting-a-spell-sentence-pairing-exploration-for.md"
  },
  {
    "arxiv_id": "2512.21257",
    "title": "ReaSeq: Unleashing World Knowledge via Reasoning for Sequential Modeling",
    "authors": [
      "Chuan Wang",
      "Gaoming Yang",
      "Han Wu",
      "Jiakai Tang",
      "Jiahao Yu",
      "Jian Wu",
      "Jianwu Hu",
      "Junjun Zheng",
      "Shuwen Xiao",
      "Yeqiu Yang",
      "Yuning Jiang",
      "Ahjol Nurlanbek",
      "Binbin Cao",
      "Bo Zheng",
      "Fangmei Zhu",
      "Gaoming Zhou",
      "Huimin Yi",
      "Huiping Chu",
      "Jin Huang",
      "Jinzhe Shan",
      "Kenan Cui",
      "Longbin Li",
      "Silu Zhou",
      "Wen Chen",
      "Xia Ming",
      "Xiang Gao",
      "Xin Yao",
      "Xingyu Wen",
      "Yan Zhang",
      "Yiwen Hu",
      "Yulin Wang",
      "Ziheng Bao",
      "Zongyuan Wu"
    ],
    "date": "2025-12-24",
    "field": "other",
    "tags": [
      "cs.IR",
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.21257",
    "abstract": "Industrial recommender systems face two fundamental limitations under the log-driven paradigm: (1) knowledge poverty in ID-based item representations that causes brittle interest modeling under data sparsity, and (2) systemic blindness to beyond-log user interests that constrains model performance w",
    "file": "other/2512.21257-reaseq-unleashing-world-knowledge-via-reasoning-f.md"
  },
  {
    "arxiv_id": "2512.21319",
    "title": "Variationally correct operator learning: Reduced basis neural operator with a posteriori error estimation",
    "authors": [
      "Yuan Qiu",
      "Wolfgang Dahmen",
      "Peng Chen"
    ],
    "date": "2025-12-24",
    "field": "other",
    "tags": [
      "math.NA",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.21319",
    "abstract": "Minimizing PDE-residual losses is a common strategy to promote physical consistency in neural operators. However, standard formulations often lack variational correctness, meaning that small residuals do not guarantee small solution errors due to the use of non-compliant norms or ad hoc penalty term",
    "file": "other/2512.21319-variationally-correct-operator-learning-reduced-b.md"
  },
  {
    "arxiv_id": "2512.21335",
    "title": "Autonomous Uncertainty Quantification for Computational Point-of-care Sensors",
    "authors": [
      "Artem Goncharov",
      "Rajesh Ghosh",
      "Hyou-Arm Joung",
      "Dino Di Carlo",
      "Aydogan Ozcan"
    ],
    "date": "2025-12-24",
    "field": "other",
    "tags": [
      "physics.med-ph",
      "cs.LG",
      "physics.app-ph",
      "physics.bio-ph"
    ],
    "url": "https://arxiv.org/abs/2512.21335",
    "abstract": "Computational point-of-care (POC) sensors enable rapid, low-cost, and accessible diagnostics in emergency, remote and resource-limited areas that lack access to centralized medical facilities. These systems can utilize neural network-based algorithms to accurately infer a diagnosis from the signals ",
    "file": "other/2512.21335-autonomous-uncertainty-quantification-for-computat.md"
  },
  {
    "arxiv_id": "2512.20586",
    "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent",
    "authors": [
      "Humza Nusrat",
      "Luke Francisco",
      "Bing Luo",
      "Hassan Bagher-Ebadian",
      "Joshua Kim",
      "Karen Chin-Snyder",
      "Salim Siddiqui",
      "Mira Shah",
      "Eric Mellon",
      "Mohammad Ghassemi",
      "Anthony Doemer",
      "Benjamin Movsas",
      "Kundan Thind"
    ],
    "date": "2025-12-23",
    "field": "cs-ai",
    "tags": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "url": "https://arxiv.org/abs/2512.20586",
    "abstract": "Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns. We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metasta",
    "file": "cs/ai/2512.20586-automated-stereotactic-radiosurgery-planning-using.md"
  },
  {
    "arxiv_id": "2512.20569",
    "title": "Distilling to Hybrid Attention Models via KL-Guided Layer Selection",
    "authors": [
      "Yanhong Li",
      "Songlin Yang",
      "Shawn Tan",
      "Mayank Mishra",
      "Rameswar Panda",
      "Jiawei Zhou",
      "Yoon Kim"
    ],
    "date": "2025-12-23",
    "field": "cs-ai",
    "tags": [
      "cs.CL",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.20569",
    "abstract": "Distilling pretrained softmax attention Transformers into more efficient hybrid architectures that interleave softmax and linear attention layers is a promising approach for improving the inference efficiency of LLMs without requiring expensive pretraining from scratch. A critical factor in the conv",
    "file": "cs/ai/2512.20569-distilling-to-hybrid-attention-models-via-kl-guide.md"
  },
  {
    "arxiv_id": "2512.20578",
    "title": "Can LLMs Predict Their Own Failures? Self-Awareness via Internal Circuits",
    "authors": [
      "Amirhosein Ghasemabadi",
      "Di Niu"
    ],
    "date": "2025-12-23",
    "field": "cs-ai",
    "tags": [
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.20578",
    "abstract": "Large language models (LLMs) generate fluent and complex outputs but often fail to recognize their own mistakes and hallucinations. Existing approaches typically rely on external judges, multi-sample consistency, or text-based self-critique, which incur additional compute or correlate weakly with tr",
    "file": "cs/ai/2512.20578-can-llms-predict-their-own-failures-self-awarenes.md"
  },
  {
    "arxiv_id": "2512.20595",
    "title": "Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs",
    "authors": [
      "Dhruv Anand",
      "Ehsan Shareghi"
    ],
    "date": "2025-12-23",
    "field": "cs-ai",
    "tags": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.20595",
    "abstract": "We introduce Cube Bench, a Rubik's-cube benchmark for evaluating spatial and sequential reasoning in multimodal large language models (MLLMs). The benchmark decomposes performance into five skills: (i) reconstructing cube faces from images and text, (ii) choosing the optimal next move, (iii) predict",
    "file": "cs/ai/2512.20595-cube-bench-a-benchmark-for-spatial-visual-reasoni.md"
  },
  {
    "arxiv_id": "2512.20618",
    "title": "LongVideoAgent: Multi-Agent Reasoning with Long Videos",
    "authors": [
      "Runtao Liu",
      "Ziyi Liu",
      "Jiaqi Tang",
      "Yue Ma",
      "Renjie Pi",
      "Jipeng Zhang",
      "Qifeng Chen"
    ],
    "date": "2025-12-23",
    "field": "cs-ai",
    "tags": [
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MA"
    ],
    "url": "https://arxiv.org/abs/2512.20618",
    "abstract": "Recent advances in multimodal LLMs and systems that use tools for long-video QA point to the promise of reasoning over hour-long episodes. However, many methods still compress content into lossy summaries or rely on limited toolsets, weakening temporal grounding and missing fine-grained cues. We pro",
    "file": "cs/ai/2512.20618-longvideoagent-multi-agent-reasoning-with-long-vi.md"
  },
  {
    "arxiv_id": "2512.20604",
    "title": "MoE-DiffuSeq: Enhancing Long-Document Diffusion Models with Sparse Attention and Mixture of Experts",
    "authors": [
      "Alexandros Christoforos",
      "Chadbourne Davis"
    ],
    "date": "2025-12-23",
    "field": "cs-ai",
    "tags": [
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.20604",
    "abstract": "We present MoE-DiffuSeq, a mixture of experts based framework for enhancing diffusion models in long document generation. Existing diffusion based text generation models, such as DiffuSeq, suffer from high computational cost and memory overhead when applied to extended sequences. To address these ch",
    "file": "cs/ai/2512.20604-moe-diffuseq-enhancing-long-document-diffusion-mo.md"
  },
  {
    "arxiv_id": "2512.20607",
    "title": "Saddle-to-Saddle Dynamics Explains A Simplicity Bias Across Neural Network Architectures",
    "authors": [
      "Yedi Zhang",
      "Andrew Saxe",
      "Peter E. Latham"
    ],
    "date": "2025-12-23",
    "field": "cs-lg",
    "tags": [
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.20607",
    "abstract": "Neural networks trained with gradient descent often learn solutions of increasing complexity over time, a phenomenon known as simplicity bias. Despite being widely observed across architectures, existing theoretical treatments lack a unifying framework. We present a theoretical framework that explai",
    "file": "cs/lg/2512.20607-saddle-to-saddle-dynamics-explains-a-simplicity-bi.md"
  },
  {
    "arxiv_id": "2512.20573",
    "title": "Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs",
    "authors": [
      "Rui Pan",
      "Zhuofu Chen",
      "Ravi Netravali"
    ],
    "date": "2025-12-23",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "url": "https://arxiv.org/abs/2512.20573",
    "abstract": "Diffusion Large Language Models (dLLMs) offer fast, parallel token generation, but their standalone use is plagued by an inherent efficiency-quality tradeoff. We show that, if carefully applied, the attributes of dLLMs can actually be a strength for drafters in speculative decoding with autoregressi",
    "file": "cs/lg/2512.20573-fail-fast-win-big-rethinking-the-drafting-strate.md"
  },
  {
    "arxiv_id": "2512.20605",
    "title": "Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning",
    "authors": [
      "Seijin Kobayashi",
      "Yanick Schimpf",
      "Maximilian Schlegel",
      "Angelika Steger",
      "Maciej Wolczyk",
      "Johannes von Oswald",
      "Nino Scherre",
      "Kaitlin Maile",
      "Guillaume Lajoie",
      "Blake A. Richards",
      "Rif A. Saurous",
      "James Manyika",
      "Blaise Ag\u00fcera y Arcas",
      "Alexander Meulemans",
      "Jo\u00e3o Sacramento"
    ],
    "date": "2025-12-23",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.20605",
    "abstract": "Large-scale autoregressive models pretrained on next-token prediction and finetuned with reinforcement learning (RL) have achieved unprecedented success on many problem domains. During RL, these models explore by generating new outputs, one token at a time. However, sampling actions token-by-token c",
    "file": "cs/lg/2512.20605-emergent-temporal-abstractions-in-autoregressive-m.md"
  },
  {
    "arxiv_id": "2512.20582",
    "title": "Relu and softplus neural nets as zero-sum turn-based games",
    "authors": [
      "Stephane Gaubert",
      "Yiannis Vlassopoulos"
    ],
    "date": "2025-12-23",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.GT",
      "math.OC"
    ],
    "url": "https://arxiv.org/abs/2512.20582",
    "abstract": "We show that the output of a ReLU neural network can be interpreted as the value of a zero-sum, turn-based, stopping game, which we call the ReLU net game. The game runs in the direction opposite to that of the network, and the input of the network serves as the terminal reward of the game. In fact,",
    "file": "cs/lg/2512.20582-relu-and-softplus-neural-nets-as-zero-sum-turn-bas.md"
  },
  {
    "arxiv_id": "2512.20576",
    "title": "Performative Policy Gradient: Optimality in Performative Reinforcement Learning",
    "authors": [
      "Debabrota Basu",
      "Udvas Das",
      "Brahim Driss",
      "Uddalak Mukherjee"
    ],
    "date": "2025-12-23",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "url": "https://arxiv.org/abs/2512.20576",
    "abstract": "Post-deployment machine learning algorithms often influence the environments they act in, and thus shift the underlying dynamics that the standard reinforcement learning (RL) methods ignore. While designing optimal algorithms in this performative setting has recently been studied in supervised learn",
    "file": "cs/lg/2512.20576-performative-policy-gradient-optimality-in-perfor.md"
  },
  {
    "arxiv_id": "2512.20606",
    "title": "Repurposing Video Diffusion Transformers for Robust Point Tracking",
    "authors": [
      "Soowon Son",
      "Honggyu An",
      "Chaehyun Kim",
      "Hyunah Ko",
      "Jisu Nam",
      "Dahyun Chung",
      "Siyoon Jin",
      "Jung Yi",
      "Jaewon Min",
      "Junhwa Hur",
      "Seungryong Kim"
    ],
    "date": "2025-12-23",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.20606",
    "abstract": "Point tracking aims to localize corresponding points across video frames, serving as a fundamental task for 4D reconstruction, robotics, and video editing. Existing methods commonly rely on shallow convolutional backbones such as ResNet that process frames independently, lacking temporal coherence a",
    "file": "cs/cv/2512.20606-repurposing-video-diffusion-transformers-for-robus.md"
  },
  {
    "arxiv_id": "2512.20619",
    "title": "SemanticGen: Video Generation in Semantic Space",
    "authors": [
      "Jianhong Bai",
      "Xiaoshi Wu",
      "Xintao Wang",
      "Fu Xiao",
      "Yuanxing Zhang",
      "Qinghe Wang",
      "Xiaoyu Shi",
      "Menghan Xia",
      "Zuozhu Liu",
      "Haoji Hu",
      "Pengfei Wan",
      "Kun Gai"
    ],
    "date": "2025-12-23",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.20619",
    "abstract": "State-of-the-art video generative models typically learn the distribution of video latents in the VAE space and map them to pixels using a VAE decoder. While this approach can generate high-quality videos, it suffers from slow convergence and is computationally expensive when generating long videos.",
    "file": "cs/cv/2512.20619-semanticgen-video-generation-in-semantic-space.md"
  },
  {
    "arxiv_id": "2512.20589",
    "title": "Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information",
    "authors": [
      "\u0130brahim O\u011fuz \u00c7etinkaya",
      "Sajad Khodadadian",
      "Taylan G. Top\u00e7u"
    ],
    "date": "2025-12-23",
    "field": "other",
    "tags": [
      "cs.CY",
      "cs.AI",
      "eess.SY",
      "math.OC"
    ],
    "url": "https://arxiv.org/abs/2512.20589",
    "abstract": "As systems engineering (SE) objectives evolve from design and operation of monolithic systems to complex System of Systems (SoS), the discipline of Mission Engineering (ME) has emerged which is increasingly being accepted as a new line of thinking for the SE community. Moreover, mission environments",
    "file": "other/2512.20589-leveraging-high-fidelity-digital-models-and-reinfo.md"
  },
  {
    "arxiv_id": "2512.20612",
    "title": "Making Large Language Models Efficient Dense Retrievers",
    "authors": [
      "Yibin Lei",
      "Shwai He",
      "Ang Li",
      "Andrew Yates"
    ],
    "date": "2025-12-23",
    "field": "other",
    "tags": [
      "cs.IR",
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.20612",
    "abstract": "Recent work has shown that directly fine-tuning large language models (LLMs) for dense retrieval yields strong performance, but their substantial parameter counts make them computationally inefficient. While prior studies have revealed significant layer redundancy in LLMs for generative tasks, it re",
    "file": "other/2512.20612-making-large-language-models-efficient-dense-retri.md"
  },
  {
    "arxiv_id": "2512.19691",
    "title": "Scalably Enhancing the Clinical Validity of a Task Benchmark with Physician Oversight",
    "authors": [
      "Junze Ye",
      "Daniel Tawfik",
      "Alex J. Goodell",
      "Nikhil V. Kotha",
      "Mark K. Buyyounouski",
      "Mohsen Bayati"
    ],
    "date": "2025-12-22",
    "field": "cs-ai",
    "tags": [
      "cs.AI",
      "stat.AP"
    ],
    "url": "https://arxiv.org/abs/2512.19691",
    "abstract": "Automating the calculation of clinical risk scores offers a significant opportunity to reduce physician administrative burden and enhance patient care. The current standard for evaluating this capability is MedCalc-Bench, a large-scale dataset constructed using LLM-based feature extraction and rule-",
    "file": "cs/ai/2512.19691-scalably-enhancing-the-clinical-validity-of-a-task.md"
  },
  {
    "arxiv_id": "2512.19651",
    "title": "Exploring Zero-Shot ACSA with Unified Meaning Representation in Chain-of-Thought Prompting",
    "authors": [
      "Filippos Ventirozos",
      "Peter Appleby",
      "Matthew Shardlow"
    ],
    "date": "2025-12-22",
    "field": "cs-ai",
    "tags": [
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.19651",
    "abstract": "Aspect-Category Sentiment Analysis (ACSA) provides granular insights by identifying specific themes within reviews and their associated sentiment. While supervised learning approaches dominate this field, the scarcity and high cost of annotated data for new domains present significant barriers. We a",
    "file": "cs/ai/2512.19651-exploring-zero-shot-acsa-with-unified-meaning-repr.md"
  },
  {
    "arxiv_id": "2512.19682",
    "title": "GenEnv: Difficulty-Aligned Co-Evolution Between LLM Agents and Environment Simulators",
    "authors": [
      "Jiacheng Guo",
      "Ling Yang",
      "Peter Chen",
      "Qixin Xiao",
      "Yinjie Wang",
      "Xinzhe Juan",
      "Jiahao Qiu",
      "Ke Shen",
      "Mengdi Wang"
    ],
    "date": "2025-12-22",
    "field": "cs-ai",
    "tags": [
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.19682",
    "abstract": "Training capable Large Language Model (LLM) agents is critically bottlenecked by the high cost and static nature of real-world interaction data. We address this by introducing GenEnv, a framework that establishes a difficulty-aligned co-evolutionary game between an agent and a scalable, generative e",
    "file": "cs/ai/2512.19682-genenv-difficulty-aligned-co-evolution-between-ll.md"
  },
  {
    "arxiv_id": "2512.18940",
    "title": "FASTRIC: Prompt Specification Language for Verifiable LLM Interactions",
    "authors": [
      "Wen-Long Jin"
    ],
    "date": "2025-12-22",
    "field": "cs-ai",
    "tags": [
      "cs.CL",
      "cs.SE"
    ],
    "url": "https://arxiv.org/abs/2512.18940",
    "abstract": "Large Language Models (LLMs) execute complex multi-turn interaction protocols but lack formal specifications to verify execution against designer intent. We introduce FASTRIC, a Prompt Specification Language that makes implicit Finite State Machines (FSMs) explicit in natural language prompts, enabl",
    "file": "cs/ai/2512.18940-fastric-prompt-specification-language-for-verifia.md"
  },
  {
    "arxiv_id": "2512.19673",
    "title": "Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies",
    "authors": [
      "Yuqiao Tan",
      "Minzheng Wang",
      "Shizhu He",
      "Huanxuan Liao",
      "Chengfeng Zhao",
      "Qiunan Lu",
      "Tian Liang",
      "Jun Zhao",
      "Kang Liu"
    ],
    "date": "2025-12-22",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.19673",
    "abstract": "Existing reinforcement learning (RL) approaches treat large language models (LLMs) as a single unified policy, overlooking their internal mechanisms. Understanding how policy evolves across layers and modules is therefore crucial for enabling more targeted optimization and raveling out complex reaso",
    "file": "cs/lg/2512.19673-bottom-up-policy-optimization-your-language-model.md"
  },
  {
    "arxiv_id": "2512.18934",
    "title": "When Less is More: 8-bit Quantization Improves Continual Learning in Large Language Models",
    "authors": [
      "Michael S. Zhang",
      "Rishi A. Ruia",
      "Arnav Kewalram",
      "Saathvik Dharmapuram",
      "Utkarsh Sharma",
      "Kevin Zhu"
    ],
    "date": "2025-12-22",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.18934",
    "abstract": "Catastrophic forgetting poses a fundamental challenge in continual learning, particularly when models are quantized for deployment efficiency. We systematically investigate the interplay between quantization precision (FP16, INT8, INT4) and replay buffer strategies in large language models, revealin",
    "file": "cs/lg/2512.18934-when-less-is-more-8-bit-quantization-improves-con.md"
  },
  {
    "arxiv_id": "2512.19649",
    "title": "Deep Legendre Transform",
    "authors": [
      "Aleksey Minabutdinov",
      "Patrick Cheridito"
    ],
    "date": "2025-12-22",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "math.OC"
    ],
    "url": "https://arxiv.org/abs/2512.19649",
    "abstract": "We introduce a novel deep learning algorithm for computing convex conjugates of differentiable convex functions, a fundamental operation in convex analysis with various applications in different fields such as optimization, control theory, physics and economics. While traditional numerical methods s",
    "file": "cs/lg/2512.19649-deep-legendre-transform.md"
  },
  {
    "arxiv_id": "2512.19692",
    "title": "Interact2Ar: Full-Body Human-Human Interaction Generation via Autoregressive Diffusion Models",
    "authors": [
      "Pablo Ruiz-Ponce",
      "Sergio Escalera",
      "Jos\u00e9 Garc\u00eda-Rodr\u00edguez",
      "Jiankang Deng",
      "Rolandos Alexandros Potamias"
    ],
    "date": "2025-12-22",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.19692",
    "abstract": "Generating realistic human-human interactions is a challenging task that requires not only high-quality individual body and hand motions, but also coherent coordination among all interactants. Due to limitations in available data and increased learning complexity, previous methods tend to ignore han",
    "file": "cs/cv/2512.19692-interact2ar-full-body-human-human-interaction-gen.md"
  },
  {
    "arxiv_id": "2512.19683",
    "title": "From Indoor to Open World: Revealing the Spatial Reasoning Gap in MLLMs",
    "authors": [
      "Mingrui Wu",
      "Zhaozhi Wang",
      "Fangjinhua Wang",
      "Jiaolong Yang",
      "Marc Pollefeys",
      "Tong Zhang"
    ],
    "date": "2025-12-22",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.19683",
    "abstract": "While Multimodal Large Language Models (MLLMs) have achieved impressive performance on semantic tasks, their spatial intelligence--crucial for robust and grounded AI systems--remains underdeveloped. Existing benchmarks fall short of diagnosing this limitation: they either focus on overly simplified ",
    "file": "cs/cv/2512.19683-from-indoor-to-open-world-revealing-the-spatial-r.md"
  },
  {
    "arxiv_id": "2512.19663",
    "title": "Beyond CLIP: Knowledge-Enhanced Multimodal Transformers for Cross-Modal Alignment in Diabetic Retinopathy Diagnosis",
    "authors": [
      "Argha Kamal Samanta",
      "Harshika Goyal",
      "Vasudha Joshi",
      "Tushar Mungle",
      "Pabitra Mitra"
    ],
    "date": "2025-12-22",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.19663",
    "abstract": "Diabetic retinopathy (DR) is a leading cause of preventable blindness worldwide, demanding accurate automated diagnostic systems. While general-domain vision-language models like Contrastive Language-Image Pre-Training (CLIP) perform well on natural image tasks, they struggle in medical domain appli",
    "file": "cs/cv/2512.19663-beyond-clip-knowledge-enhanced-multimodal-transfo.md"
  },
  {
    "arxiv_id": "2512.19676",
    "title": "Efficient Vision Mamba for MRI Super-Resolution via Hybrid Selective Scanning",
    "authors": [
      "Mojtaba Safari",
      "Shansong Wang",
      "Vanessa L Wildman",
      "Mingzhe Hu",
      "Zach Eidex",
      "Chih-Wei Chang",
      "Erik H Middlebrooks",
      "Richard L. J Qiu",
      "Pretesh Patel",
      "Ashesh B. Jania",
      "Hui Mao",
      "Zhen Tian",
      "Xiaofeng Yang"
    ],
    "date": "2025-12-22",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "physics.med-ph"
    ],
    "url": "https://arxiv.org/abs/2512.19676",
    "abstract": "Background: High-resolution MRI is critical for diagnosis, but long acquisition times limit clinical use. Super-resolution (SR) can enhance resolution post-scan, yet existing deep learning methods face fidelity-efficiency trade-offs. Purpose: To develop a computationally efficient and accurate deep ",
    "file": "cs/cv/2512.19676-efficient-vision-mamba-for-mri-super-resolution-vi.md"
  },
  {
    "arxiv_id": "2512.19675",
    "title": "Multimodal LLMs for Historical Dataset Construction from Archival Image Scans: German Patents (1877-1918)",
    "authors": [
      "Niclas Griesshaber",
      "Jochen Streb"
    ],
    "date": "2025-12-22",
    "field": "other",
    "tags": [
      "econ.GN",
      "cs.CV",
      "cs.DL"
    ],
    "url": "https://arxiv.org/abs/2512.19675",
    "abstract": "We leverage multimodal large language models (LLMs) to construct a dataset of 306,070 German patents (1877-1918) from 9,562 archival image scans using our LLM-based pipeline powered by Gemini-2.5-Pro and Gemini-2.5-Flash-Lite. Our benchmarking exercise provides tentative evidence that multimodal LLM",
    "file": "other/2512.19675-multimodal-llms-for-historical-dataset-constructio.md"
  },
  {
    "arxiv_id": "2512.18906",
    "title": "Remedy-R: Generative Reasoning for Machine Translation Evaluation without Error Annotations",
    "authors": [
      "Shaomu Tan",
      "Ryosuke Mitani",
      "Ritvik Choudhary",
      "Qiyu Wu",
      "Toshiyuki Sekiya",
      "Christof Monz"
    ],
    "date": "2025-12-21",
    "field": "cs-ai",
    "tags": [
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.18906",
    "abstract": "Over the years, automatic MT metrics have hillclimbed benchmarks and presented strong and sometimes human-level agreement with human ratings. Yet they remain black-box, offering little insight into their decision-making and often failing under real-world out-of-distribution (OOD) inputs. We introduc",
    "file": "cs/ai/2512.18906-remedy-r-generative-reasoning-for-machine-transla.md"
  },
  {
    "arxiv_id": "2512.18910",
    "title": "Delta-LLaVA: Base-then-Specialize Alignment for Token-Efficient Vision-Language Models",
    "authors": [
      "Mohamad Zamini",
      "Diksha Shukla"
    ],
    "date": "2025-12-21",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.18910",
    "abstract": "Multimodal Large Language Models (MLLMs) combine visual and textual representations to enable rich reasoning capabilities. However, the high computational cost of processing dense visual tokens remains a major bottleneck. A critical component in this pipeline is the visual projector, which bridges t",
    "file": "cs/cv/2512.18910-delta-llava-base-then-specialize-alignment-for-to.md"
  },
  {
    "arxiv_id": "2512.18925",
    "title": "An Empirical Study of Developer-Provided Context for AI Coding Assistants in Open-Source Projects",
    "authors": [
      "Shaokang Jiang",
      "Daye Nam"
    ],
    "date": "2025-12-21",
    "field": "other",
    "tags": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "url": "https://arxiv.org/abs/2512.18925",
    "abstract": "While Large Language Models (LLMs) have demonstrated remarkable capabilities, research shows that their effectiveness depends not only on explicit prompts but also on the broader context provided. This requirement is especially pronounced in software engineering, where the goals, architecture, and c",
    "file": "other/2512.18925-an-empirical-study-of-developer-provided-context-f.md"
  },
  {
    "arxiv_id": "2512.16872",
    "title": "On the Universal Representation Property of Spiking Neural Networks",
    "authors": [
      "Shayan Hundrieser",
      "Philipp Tuchel",
      "Insung Kong",
      "Johannes Schmidt-Hieber"
    ],
    "date": "2025-12-18",
    "field": "cs-ai",
    "tags": [
      "cs.NE",
      "cs.LG",
      "stat.ML"
    ],
    "url": "https://arxiv.org/abs/2512.16872",
    "abstract": "Inspired by biology, spiking neural networks (SNNs) process information via discrete spikes over time, offering an energy-efficient alternative to the classical computing paradigm and classical artificial neural networks (ANNs). In this work, we analyze the representational power of SNNs by viewing ",
    "file": "cs/ai/2512.16872-on-the-universal-representation-property-of-spikin.md"
  },
  {
    "arxiv_id": "2512.16902",
    "title": "In-Context Algebra",
    "authors": [
      "Eric Todd",
      "Jannik Brinkmann",
      "Rohit Gandikota",
      "David Bau"
    ],
    "date": "2025-12-18",
    "field": "cs-ai",
    "tags": [
      "cs.CL",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.16902",
    "abstract": "We investigate the mechanisms that arise when transformers are trained to solve arithmetic on sequences where tokens are variables whose meaning is determined only through their interactions. While prior work has found that transformers develop geometric embeddings that mirror algebraic structure, t",
    "file": "cs/ai/2512.16902-in-context-algebra.md"
  },
  {
    "arxiv_id": "2512.16802",
    "title": "Exploration of Augmentation Strategies in Multi-modal Retrieval-Augmented Generation for the Biomedical Domain: A Case Study Evaluating Question Answering in Glycobiology",
    "authors": [
      "Primo\u017e Kocbek",
      "Azra Frkatovi\u0107-Hod\u017ei\u0107",
      "Dora Lali\u0107",
      "Vivian Hui",
      "Gordan Lauc",
      "Gregor \u0160tiglic"
    ],
    "date": "2025-12-18",
    "field": "cs-ai",
    "tags": [
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.16802",
    "abstract": "Multi-modal retrieval-augmented generation (MM-RAG) promises grounded biomedical QA, but it is unclear when to (i) convert figures/tables into text versus (ii) use optical character recognition (OCR)-free visual retrieval that returns page images and leaves interpretation to the generator. We study ",
    "file": "cs/ai/2512.16802-exploration-of-augmentation-strategies-in-multi-mo.md"
  },
  {
    "arxiv_id": "2512.16843",
    "title": "LLMCache: Layer-Wise Caching Strategies for Accelerated Reuse in Transformer Inference",
    "authors": [
      "Harsh Vardhan Bansal"
    ],
    "date": "2025-12-18",
    "field": "cs-ai",
    "tags": [
      "cs.CL",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.16843",
    "abstract": "Transformer-based language models have achieved remarkable performance across a wide range of tasks, yet their high inference latency poses a significant challenge for real-timeand large-scale deployment. While existing caching mechanisms,such as token-level key-value caches, offer speedups in autor",
    "file": "cs/ai/2512.16843-llmcache-layer-wise-caching-strategies-for-accele.md"
  },
  {
    "arxiv_id": "2512.16855",
    "title": "TOGGLE: Temporal Logic-Guided Large Language Model Compression for Edge",
    "authors": [
      "Khurram Khalil",
      "Khaza Anuarul Hoque"
    ],
    "date": "2025-12-18",
    "field": "cs-ai",
    "tags": [
      "cs.AI",
      "cs.LO"
    ],
    "url": "https://arxiv.org/abs/2512.16855",
    "abstract": "Large Language Models (LLMs) deliver exceptional performance across natural language tasks but demand substantial computational resources, limiting their deployment on resource-constrained edge devices. Existing compression techniques, such as quantization and pruning, often degrade critical linguis",
    "file": "cs/ai/2512.16855-toggle-temporal-logic-guided-large-language-model.md"
  },
  {
    "arxiv_id": "2512.16899",
    "title": "Multimodal RewardBench 2: Evaluating Omni Reward Models for Interleaved Text and Image",
    "authors": [
      "Yushi Hu",
      "Reyhane Askari-Hemmat",
      "Melissa Hall",
      "Emily Dinan",
      "Luke Zettlemoyer",
      "Marjan Ghazvininejad"
    ],
    "date": "2025-12-18",
    "field": "cs-ai",
    "tags": [
      "cs.CL",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.16899",
    "abstract": "Reward models (RMs) are essential for training large language models (LLMs), but remain underexplored for omni models that handle interleaved image and text sequences. We introduce Multimodal RewardBench 2 (MMRB2), the first comprehensive benchmark for reward models on multimodal understanding and (",
    "file": "cs/ai/2512.16899-multimodal-rewardbench-2-evaluating-omni-reward-m.md"
  },
  {
    "arxiv_id": "2512.16917",
    "title": "Generative Adversarial Reasoner: Enhancing LLM Reasoning with Adversarial Reinforcement Learning",
    "authors": [
      "Qihao Liu",
      "Luoxin Ye",
      "Wufei Ma",
      "Yu-Cheng Chou",
      "Alan Yuille"
    ],
    "date": "2025-12-18",
    "field": "cs-ai",
    "tags": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.16917",
    "abstract": "Large language models (LLMs) with explicit reasoning capabilities excel at mathematical reasoning yet still commit process errors, such as incorrect calculations, brittle logic, and superficially plausible but invalid steps. In this paper, we introduce Generative Adversarial Reasoner, an on-policy j",
    "file": "cs/ai/2512.16917-generative-adversarial-reasoner-enhancing-llm-rea.md"
  },
  {
    "arxiv_id": "2512.16795",
    "title": "From Facts to Conclusions : Integrating Deductive Reasoning in Retrieval-Augmented LLMs",
    "authors": [
      "Shubham Mishra",
      "Samyek Jain",
      "Gorang Mehrishi",
      "Shiv Tiwari",
      "Harsh Sharma",
      "Pratik Narang",
      "Dhruv Kumar"
    ],
    "date": "2025-12-18",
    "field": "cs-ai",
    "tags": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.IR"
    ],
    "url": "https://arxiv.org/abs/2512.16795",
    "abstract": "Retrieval-Augmented Generation (RAG) grounds large language models (LLMs) in external evidence, but fails when retrieved sources conflict or contain outdated or subjective information. Prior work address these issues independently but lack unified reasoning supervision. We propose a reasoning-trace-",
    "file": "cs/ai/2512.16795-from-facts-to-conclusions-integrating-deductive.md"
  },
  {
    "arxiv_id": "2512.16883",
    "title": "AdaSearch: Balancing Parametric Knowledge and Search in Large Language Models via Reinforcement Learning",
    "authors": [
      "Tzu-Han Lin",
      "Wei-Lin Chen",
      "Chen-An Li",
      "Hung-yi Lee",
      "Yun-Nung Chen",
      "Yu Meng"
    ],
    "date": "2025-12-18",
    "field": "cs-ai",
    "tags": [
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.16883",
    "abstract": "Equipping large language models (LLMs) with search engines via reinforcement learning (RL) has emerged as an effective approach for building search agents. However, overreliance on search introduces unnecessary cost and risks exposure to noisy or malicious content, while relying solely on parametric",
    "file": "cs/ai/2512.16883-adasearch-balancing-parametric-knowledge-and-sear.md"
  },
  {
    "arxiv_id": "2512.16848",
    "title": "Meta-RL Induces Exploration in Language Agents",
    "authors": [
      "Yulun Jiang",
      "Liangze Jiang",
      "Damien Teney",
      "Michael Moor",
      "Maria Brbic"
    ],
    "date": "2025-12-18",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.16848",
    "abstract": "Reinforcement learning (RL) has enabled the training of large language model (LLM) agents to interact with the environment and to solve multi-turn long-horizon tasks. However, the RL-trained agents often struggle in tasks that require active exploration and fail to efficiently adapt from trial-and-e",
    "file": "cs/lg/2512.16848-meta-rl-induces-exploration-in-language-agents.md"
  },
  {
    "arxiv_id": "2512.16912",
    "title": "Exploration v.s. Exploitation: Rethinking RLVR through Clipping, Entropy, and Spurious Reward",
    "authors": [
      "Peter Chen",
      "Xiaopeng Li",
      "Ziniu Li",
      "Wotao Yin",
      "Xi Chen",
      "Tianyi Lin"
    ],
    "date": "2025-12-18",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.16912",
    "abstract": "This paper examines the exploration-exploitation trade-off in reinforcement learning with verifiable rewards (RLVR), a framework for improving the reasoning of Large Language Models (LLMs). Recent studies suggest that RLVR can elicit strong mathematical reasoning in LLMs through two seemingly parado",
    "file": "cs/lg/2512.16912-exploration-vs-exploitation-rethinking-rlvr-thr.md"
  },
  {
    "arxiv_id": "2512.16901",
    "title": "Impacts of Racial Bias in Historical Training Data for News AI",
    "authors": [
      "Rahul Bhargava",
      "Malene Hornstrup Jespersen",
      "Emily Boardman Ndulue",
      "Vivica Dsouza"
    ],
    "date": "2025-12-18",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "url": "https://arxiv.org/abs/2512.16901",
    "abstract": "AI technologies have rapidly moved into business and research applications that involve large text corpora, including computational journalism research and newsroom settings. These models, trained on extant data from various sources, can be conceptualized as historical artifacts that encode decades-",
    "file": "cs/lg/2512.16901-impacts-of-racial-bias-in-historical-training-data.md"
  },
  {
    "arxiv_id": "2512.16762",
    "title": "NRGPT: An Energy-based Alternative for GPT",
    "authors": [
      "Nima Dehmamy",
      "Benjamin Hoover",
      "Bishwajit Saha",
      "Leo Kozachkov",
      "Jean-Jacques Slotine",
      "Dmitry Krotov"
    ],
    "date": "2025-12-18",
    "field": "cs-lg",
    "tags": [
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.16762",
    "abstract": "Generative Pre-trained Transformer (GPT) architectures are the most popular design for language modeling. Energy-based modeling is a different paradigm that views inference as a dynamical process operating on an energy landscape. We propose a minimal modification of the GPT setting to unify it with ",
    "file": "cs/lg/2512.16762-nrgpt-an-energy-based-alternative-for-gpt.md"
  },
  {
    "arxiv_id": "2512.16866",
    "title": "Semi-Supervised Online Learning on the Edge by Transforming Knowledge from Teacher Models",
    "authors": [
      "Jiabin Xue"
    ],
    "date": "2025-12-18",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.16866",
    "abstract": "Edge machine learning (Edge ML) enables training ML models using the vast data distributed across network edges. However, many existing approaches assume static models trained centrally and then deployed, making them ineffective against unseen data. To address this, Online Edge ML allows models to b",
    "file": "cs/lg/2512.16866-semi-supervised-online-learning-on-the-edge-by-tra.md"
  },
  {
    "arxiv_id": "2512.16911",
    "title": "Posterior Behavioral Cloning: Pretraining BC Policies for Efficient RL Finetuning",
    "authors": [
      "Andrew Wagenmaker",
      "Perry Dong",
      "Raymond Tsao",
      "Chelsea Finn",
      "Sergey Levine"
    ],
    "date": "2025-12-18",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "url": "https://arxiv.org/abs/2512.16911",
    "abstract": "Standard practice across domains from robotics to language is to first pretrain a policy on a large-scale demonstration dataset, and then finetune this policy, typically with reinforcement learning (RL), in order to improve performance on deployment domains. This finetuning step has proved critical ",
    "file": "cs/lg/2512.16911-posterior-behavioral-cloning-pretraining-bc-polic.md"
  },
  {
    "arxiv_id": "2512.16900",
    "title": "FlashPortrait: 6x Faster Infinite Portrait Animation with Adaptive Latent Prediction",
    "authors": [
      "Shuyuan Tu",
      "Yueming Pan",
      "Yinming Huang",
      "Xintong Han",
      "Zhen Xing",
      "Qi Dai",
      "Kai Qiu",
      "Chong Luo",
      "Zuxuan Wu"
    ],
    "date": "2025-12-18",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.16900",
    "abstract": "Current diffusion-based acceleration methods for long-portrait animation struggle to ensure identity (ID) consistency. This paper presents FlashPortrait, an end-to-end video diffusion transformer capable of synthesizing ID-preserving, infinite-length videos while achieving up to 6x acceleration in i",
    "file": "cs/cv/2512.16900-flashportrait-6x-faster-infinite-portrait-animati.md"
  },
  {
    "arxiv_id": "2512.16893",
    "title": "Instant Expressive Gaussian Head Avatar via 3D-Aware Expression Distillation",
    "authors": [
      "Kaiwen Jiang",
      "Xueting Li",
      "Seonwook Park",
      "Ravi Ramamoorthi",
      "Shalini De Mello",
      "Koki Nagano"
    ],
    "date": "2025-12-18",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.16893",
    "abstract": "Portrait animation has witnessed tremendous quality improvements thanks to recent advances in video diffusion models. However, these 2D methods often compromise 3D consistency and speed, limiting their applicability in real-world scenarios, such as digital twins or telepresence. In contrast, 3D-awar",
    "file": "cs/cv/2512.16893-instant-expressive-gaussian-head-avatar-via-3d-awa.md"
  },
  {
    "arxiv_id": "2512.16919",
    "title": "DVGT: Driving Visual Geometry Transformer",
    "authors": [
      "Sicheng Zuo",
      "Zixun Xie",
      "Wenzhao Zheng",
      "Shaoqing Xu",
      "Fang Li",
      "Shengyin Jiang",
      "Long Chen",
      "Zhi-Xin Yang",
      "Jiwen Lu"
    ],
    "date": "2025-12-18",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "url": "https://arxiv.org/abs/2512.16919",
    "abstract": "Perceiving and reconstructing 3D scene geometry from visual inputs is crucial for autonomous driving. However, there still lacks a driving-targeted dense geometry perception model that can adapt to different scenarios and camera configurations. To bridge this gap, we propose a Driving Visual Geometr",
    "file": "cs/cv/2512.16919-dvgt-driving-visual-geometry-transformer.md"
  },
  {
    "arxiv_id": "2512.16906",
    "title": "VIVA: VLM-Guided Instruction-Based Video Editing with Reward Optimization",
    "authors": [
      "Xiaoyan Cong",
      "Haotian Yang",
      "Angtian Wang",
      "Yizhi Wang",
      "Yiding Yang",
      "Canyu Zhang",
      "Chongyang Ma"
    ],
    "date": "2025-12-18",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.16906",
    "abstract": "Instruction-based video editing aims to modify an input video according to a natural-language instruction while preserving content fidelity and temporal coherence. However, existing diffusion-based approaches are often trained on paired data of simple editing operations, which fundamentally limits t",
    "file": "cs/cv/2512.16906-viva-vlm-guided-instruction-based-video-editing-w.md"
  },
  {
    "arxiv_id": "2512.16921",
    "title": "Differences That Matter: Auditing Models for Capability Gap Discovery and Rectification",
    "authors": [
      "Qihao Liu",
      "Chengzhi Mao",
      "Yaojie Liu",
      "Alan Yuille",
      "Wen-Sheng Chu"
    ],
    "date": "2025-12-18",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.16921",
    "abstract": "Conventional evaluation methods for multimodal LLMs (MLLMs) lack interpretability and are often insufficient to fully disclose significant capability gaps across models. To address this, we introduce AuditDM, an automated framework that actively discovers and rectifies MLLM failure modes by auditing",
    "file": "cs/cv/2512.16921-differences-that-matter-auditing-models-for-capab.md"
  },
  {
    "arxiv_id": "2512.16909",
    "title": "MomaGraph: State-Aware Unified Scene Graphs with Vision-Language Model for Embodied Task Planning",
    "authors": [
      "Yuanchen Ju",
      "Yongyuan Liang",
      "Yen-Jen Wang",
      "Nandiraju Gireesh",
      "Yuanliang Ju",
      "Seungjae Lee",
      "Qiao Gu",
      "Elvis Hsieh",
      "Furong Huang",
      "Koushil Sreenath"
    ],
    "date": "2025-12-18",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.RO"
    ],
    "url": "https://arxiv.org/abs/2512.16909",
    "abstract": "Mobile manipulators in households must both navigate and manipulate. This requires a compact, semantically rich scene representation that captures where objects are, how they function, and which parts are actionable. Scene graphs are a natural choice, yet prior work often separates spatial and funct",
    "file": "cs/cv/2512.16909-momagraph-state-aware-unified-scene-graphs-with-v.md"
  },
  {
    "arxiv_id": "2512.16864",
    "title": "RePlan: Reasoning-guided Region Planning for Complex Instruction-based Image Editing",
    "authors": [
      "Tianyuan Qu",
      "Lei Ke",
      "Xiaohang Zhan",
      "Longxiang Tang",
      "Yuqi Liu",
      "Bohao Peng",
      "Bei Yu",
      "Dong Yu",
      "Jiaya Jia"
    ],
    "date": "2025-12-18",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.16864",
    "abstract": "Instruction-based image editing enables natural-language control over visual modifications, yet existing models falter under Instruction-Visual Complexity (IV-Complexity), where intricate instructions meet cluttered or ambiguous scenes. We introduce RePlan (Region-aligned Planning), a plan-then-exec",
    "file": "cs/cv/2512.16864-replan-reasoning-guided-region-planning-for-compl.md"
  },
  {
    "arxiv_id": "2512.16891",
    "title": "LinkedOut: Linking World Knowledge Representation Out of Video LLM for Next-Generation Video Recommendation",
    "authors": [
      "Haichao Zhang",
      "Yao Lu",
      "Lichen Wang",
      "Yunzhe Li",
      "Daiwei Chen",
      "Yunpeng Xu",
      "Yun Fu"
    ],
    "date": "2025-12-18",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "cs.MM"
    ],
    "url": "https://arxiv.org/abs/2512.16891",
    "abstract": "Video Large Language Models (VLLMs) unlock world-knowledge-aware video understanding through pretraining on internet-scale data and have already shown promise on tasks such as movie analysis and video question answering. However, deploying VLLMs for downstream tasks such as video recommendation rema",
    "file": "cs/cv/2512.16891-linkedout-linking-world-knowledge-representation.md"
  },
  {
    "arxiv_id": "2512.16922",
    "title": "Next-Embedding Prediction Makes Strong Vision Learners",
    "authors": [
      "Sihan Xu",
      "Ziqiao Ma",
      "Wenhao Chai",
      "Xuweiyi Chen",
      "Weiyang Jin",
      "Joyce Chai",
      "Saining Xie",
      "Stella X. Yu"
    ],
    "date": "2025-12-18",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.16922",
    "abstract": "Inspired by the success of generative pretraining in natural language, we ask whether the same principles can yield strong self-supervised visual learners. Instead of training models to output features for downstream use, we train them to generate embeddings to perform predictive tasks directly. Thi",
    "file": "cs/cv/2512.16922-next-embedding-prediction-makes-strong-vision-lear.md"
  },
  {
    "arxiv_id": "2512.16767",
    "title": "Make-It-Poseable: Feed-forward Latent Posing Model for 3D Humanoid Character Animation",
    "authors": [
      "Zhiyang Guo",
      "Ori Zhang",
      "Jax Xiang",
      "Alan Zhao",
      "Wengang Zhou",
      "Houqiang Li"
    ],
    "date": "2025-12-18",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.16767",
    "abstract": "Posing 3D characters is a fundamental task in computer graphics and vision. However, existing methods like auto-rigging and pose-conditioned generation often struggle with challenges such as inaccurate skinning weight prediction, topological imperfections, and poor pose conformance, limiting their r",
    "file": "cs/cv/2512.16767-make-it-poseable-feed-forward-latent-posing-model.md"
  },
  {
    "arxiv_id": "2512.16918",
    "title": "AdaTooler-V: Adaptive Tool-Use for Images and Videos",
    "authors": [
      "Chaoyang Wang",
      "Kaituo Feng",
      "Dongyang Chen",
      "Zhongyu Wang",
      "Zhixun Li",
      "Sicheng Gao",
      "Meng Meng",
      "Xu Zhou",
      "Manyuan Zhang",
      "Yuzhang Shang",
      "Xiangyu Yue"
    ],
    "date": "2025-12-18",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.16918",
    "abstract": "Recent advances have shown that multimodal large language models (MLLMs) benefit from multimodal interleaved chain-of-thought (CoT) with vision tool interactions. However, existing open-source models often exhibit blind tool-use reasoning patterns, invoking vision tools even when they are unnecessar",
    "file": "cs/cv/2512.16918-adatooler-v-adaptive-tool-use-for-images-and-vide.md"
  },
  {
    "arxiv_id": "2512.16874",
    "title": "Pixel Seal: Adversarial-only training for invisible image and video watermarking",
    "authors": [
      "Tom\u00e1\u0161 Sou\u010dek",
      "Pierre Fernandez",
      "Hady Elsahar",
      "Sylvestre-Alvise Rebuffi",
      "Valeriu Lacatusu",
      "Tuan Tran",
      "Tom Sander",
      "Alexandre Mourachko"
    ],
    "date": "2025-12-18",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.16874",
    "abstract": "Invisible watermarking is essential for tracing the provenance of digital content. However, training state-of-the-art models remains notoriously difficult, with current approaches often struggling to balance robustness against true imperceptibility. This work introduces Pixel Seal, which sets a new ",
    "file": "cs/cv/2512.16874-pixel-seal-adversarial-only-training-for-invisibl.md"
  },
  {
    "arxiv_id": "2512.16861",
    "title": "ReinforceGen: Hybrid Skill Policies with Automated Data Generation and Reinforcement Learning",
    "authors": [
      "Zihan Zhou",
      "Animesh Garg",
      "Ajay Mandlekar",
      "Caelan Garrett"
    ],
    "date": "2025-12-18",
    "field": "other",
    "tags": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.16861",
    "abstract": "Long-horizon manipulation has been a long-standing challenge in the robotics community. We propose ReinforceGen, a system that combines task decomposition, data generation, imitation learning, and motion planning to form an initial solution, and improves each component through reinforcement-learning",
    "file": "other/2512.16861-reinforcegen-hybrid-skill-policies-with-automated.md"
  },
  {
    "arxiv_id": "2512.16851",
    "title": "PrivateXR: Defending Privacy Attacks in Extended Reality Through Explainable AI-Guided Differential Privacy",
    "authors": [
      "Ripan Kumar Kundu",
      "Istiak Ahmed",
      "Khaza Anuarul Hoque"
    ],
    "date": "2025-12-18",
    "field": "other",
    "tags": [
      "cs.CR",
      "cs.AI",
      "cs.HC"
    ],
    "url": "https://arxiv.org/abs/2512.16851",
    "abstract": "The convergence of artificial AI and XR technologies (AI XR) promises innovative applications across many domains. However, the sensitive nature of data (e.g., eye-tracking) used in these systems raises significant privacy concerns, as adversaries can exploit these data and models to infer and leak ",
    "file": "other/2512.16851-privatexr-defending-privacy-attacks-in-extended-r.md"
  },
  {
    "arxiv_id": "2512.16786",
    "title": "Few-Shot Specific Emitter Identification via Integrated Complex Variational Mode Decomposition and Spatial Attention Transfer",
    "authors": [
      "Chenyu Zhu",
      "Zeyang Li",
      "Ziyi Xie",
      "Jie Zhang"
    ],
    "date": "2025-12-18",
    "field": "other",
    "tags": [
      "eess.SP",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.16786",
    "abstract": "Specific emitter identification (SEI) utilizes passive hardware characteristics to authenticate transmitters, providing a robust physical-layer security solution. However, most deep-learning-based methods rely on extensive data or require prior information, which poses challenges in real-world scena",
    "file": "other/2512.16786-few-shot-specific-emitter-identification-via-integ.md"
  },
  {
    "arxiv_id": "2512.15712",
    "title": "Predictive Concept Decoders: Training Scalable End-to-End Interpretability Assistants",
    "authors": [
      "Vincent Huang",
      "Dami Choi",
      "Daniel D. Johnson",
      "Sarah Schwettmann",
      "Jacob Steinhardt"
    ],
    "date": "2025-12-17",
    "field": "cs-ai",
    "tags": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.15712",
    "abstract": "Interpreting the internal activations of neural networks can produce more faithful explanations of their behavior, but is difficult due to the complex structure of activation space. Existing approaches to scalable interpretability use hand-designed agents that make and test hypotheses about how inte",
    "file": "cs/ai/2512.15712-predictive-concept-decoders-training-scalable-end.md"
  },
  {
    "arxiv_id": "2512.15710",
    "title": "Artism: AI-Driven Dual-Engine System for Art Generation and Critique",
    "authors": [
      "Shuai Liu",
      "Yiqing Tian",
      "Yang Chen",
      "Mar Canet Sola"
    ],
    "date": "2025-12-17",
    "field": "cs-ai",
    "tags": [
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.15710",
    "abstract": "This paper proposes a dual-engine AI architectural method designed to address the complex problem of exploring potential trajectories in the evolution of art. We present two interconnected components: AIDA (an artificial artist social network) and the Ismism Machine, a system for critical analysis. ",
    "file": "cs/ai/2512.15710-artism-ai-driven-dual-engine-system-for-art-gener.md"
  },
  {
    "arxiv_id": "2512.15706",
    "title": "Learning Model Parameter Dynamics in a Combination Therapy for Bladder Cancer from Sparse Biological Data",
    "authors": [
      "Kayode Olumoyin",
      "Lamees El Naqa",
      "Katarzyna Rejniak"
    ],
    "date": "2025-12-17",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "q-bio.CB"
    ],
    "url": "https://arxiv.org/abs/2512.15706",
    "abstract": "In a mathematical model of interacting biological organisms, where external interventions may alter behavior over time, traditional models that assume fixed parameters usually do not capture the evolving dynamics. In oncology, this is further exacerbated by the fact that experimental data are often ",
    "file": "cs/lg/2512.15706-learning-model-parameter-dynamics-in-a-combination.md"
  },
  {
    "arxiv_id": "2512.15711",
    "title": "Gaussian Pixel Codec Avatars: A Hybrid Representation for Efficient Rendering",
    "authors": [
      "Divam Gupta",
      "Anuj Pahuja",
      "Nemanja Bartolovic",
      "Tomas Simon",
      "Forrest Iandola",
      "Giljoo Nam"
    ],
    "date": "2025-12-17",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.GR"
    ],
    "url": "https://arxiv.org/abs/2512.15711",
    "abstract": "We present Gaussian Pixel Codec Avatars (GPiCA), photorealistic head avatars that can be generated from multi-view images and efficiently rendered on mobile devices. GPiCA utilizes a unique hybrid representation that combines a triangle mesh and anisotropic 3D Gaussians. This combination maximizes m",
    "file": "cs/cv/2512.15711-gaussian-pixel-codec-avatars-a-hybrid-representat.md"
  },
  {
    "arxiv_id": "2512.15701",
    "title": "VLIC: Vision-Language Models As Perceptual Judges for Human-Aligned Image Compression",
    "authors": [
      "Kyle Sargent",
      "Ruiqi Gao",
      "Philipp Henzler",
      "Charles Herrmann",
      "Aleksander Holynski",
      "Li Fei-Fei",
      "Jiajun Wu",
      "Jason Zhang"
    ],
    "date": "2025-12-17",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.15701",
    "abstract": "Evaluations of image compression performance which include human preferences have generally found that naive distortion functions such as MSE are insufficiently aligned to human perception. In order to align compression models to human perception, prior work has employed differentiable perceptual lo",
    "file": "cs/cv/2512.15701-vlic-vision-language-models-as-perceptual-judges.md"
  },
  {
    "arxiv_id": "2512.15708",
    "title": "Multi-View Foundation Models",
    "authors": [
      "Leo Segre",
      "Or Hirschorn",
      "Shai Avidan"
    ],
    "date": "2025-12-17",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.15708",
    "abstract": "Foundation models are vital tools in various Computer Vision applications. They take as input a single RGB image and output a deep feature representation that is useful for various applications. However, in case we have multiple views of the same 3D scene, they operate on each image independently an",
    "file": "cs/cv/2512.15708-multi-view-foundation-models.md"
  },
  {
    "arxiv_id": "2512.15702",
    "title": "End-to-End Training for Autoregressive Video Diffusion via Self-Resampling",
    "authors": [
      "Yuwei Guo",
      "Ceyuan Yang",
      "Hao He",
      "Yang Zhao",
      "Meng Wei",
      "Zhenheng Yang",
      "Weilin Huang",
      "Dahua Lin"
    ],
    "date": "2025-12-17",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.15702",
    "abstract": "Autoregressive video diffusion models hold promise for world simulation but are vulnerable to exposure bias arising from the train-test mismatch. While recent works address this via post-training, they typically rely on a bidirectional teacher model or online discriminator. To achieve an end-to-end ",
    "file": "cs/cv/2512.15702-end-to-end-training-for-autoregressive-video-diffu.md"
  },
  {
    "arxiv_id": "2512.15707",
    "title": "GateFusion: Hierarchical Gated Cross-Modal Fusion for Active Speaker Detection",
    "authors": [
      "Yu Wang",
      "Juhyung Ha",
      "Frangil M. Ramirez",
      "Yuchen Wang",
      "David J. Crandall"
    ],
    "date": "2025-12-17",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.15707",
    "abstract": "Active Speaker Detection (ASD) aims to identify who is currently speaking in each frame of a video. Most state-of-the-art approaches rely on late fusion to combine visual and audio features, but late fusion often fails to capture fine-grained cross-modal interactions, which can be critical for robus",
    "file": "cs/cv/2512.15707-gatefusion-hierarchical-gated-cross-modal-fusion.md"
  },
  {
    "arxiv_id": "2512.15693",
    "title": "Skyra: AI-Generated Video Detection via Grounded Artifact Reasoning",
    "authors": [
      "Yifei Li",
      "Wenzhao Zheng",
      "Yanran Zhang",
      "Runze Sun",
      "Yu Zheng",
      "Lei Chen",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "date": "2025-12-17",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.15693",
    "abstract": "The misuse of AI-driven video generation technologies has raised serious social concerns, highlighting the urgent need for reliable AI-generated video detectors. However, most existing methods are limited to binary classification and lack the necessary explanations for human interpretation. In this ",
    "file": "cs/cv/2512.15693-skyra-ai-generated-video-detection-via-grounded-a.md"
  },
  {
    "arxiv_id": "2512.15705",
    "title": "Dynamic Rebatching for Efficient Early-Exit Inference with DREX",
    "authors": [
      "Xuting Liu",
      "Daniel Alexander",
      "Siva Kesava Reddy Kakarla",
      "Behnaz Arzani",
      "Vincent Liu"
    ],
    "date": "2025-12-17",
    "field": "other",
    "tags": [
      "cs.DC",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.15705",
    "abstract": "Early-Exit (EE) is a Large Language Model (LLM) architecture that accelerates inference by allowing easier tokens to be generated using only a subset of the model's layers. However, traditional batching frameworks are ill-suited for EE LLMs, as not all requests in a batch may be ready to exit at the",
    "file": "other/2512.15705-dynamic-rebatching-for-efficient-early-exit-infere.md"
  },
  {
    "arxiv_id": "2512.14693",
    "title": "Universal Reasoning Model",
    "authors": [
      "Zitian Gao",
      "Lynx Chen",
      "Yihao Xiao",
      "He Xing",
      "Ran Tao",
      "Haoming Luo",
      "Joey Zhou",
      "Bryan Dai"
    ],
    "date": "2025-12-16",
    "field": "cs-ai",
    "tags": [
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.14693",
    "abstract": "Universal transformers (UTs) have been widely used for complex reasoning tasks such as ARC-AGI and Sudoku, yet the specific sources of their performance gains remain underexplored. In this work, we systematically analyze UTs variants and show that improvements on ARC-AGI primarily arise from the rec",
    "file": "cs/ai/2512.14693-universal-reasoning-model.md"
  },
  {
    "arxiv_id": "2512.14681",
    "title": "Fast and Accurate Causal Parallel Decoding using Jacobi Forcing",
    "authors": [
      "Lanxiang Hu",
      "Siqi Kou",
      "Yichao Fu",
      "Samyam Rajbhandari",
      "Tajana Rosing",
      "Yuxiong He",
      "Zhijie Deng",
      "Hao Zhang"
    ],
    "date": "2025-12-16",
    "field": "cs-ai",
    "tags": [
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.14681",
    "abstract": "Multi-token generation has emerged as a promising paradigm for accelerating transformer-based large model inference. Recent efforts primarily explore diffusion Large Language Models (dLLMs) for parallel decoding to reduce inference latency. To achieve AR-level generation quality, many techniques ada",
    "file": "cs/ai/2512.14681-fast-and-accurate-causal-parallel-decoding-using-j.md"
  },
  {
    "arxiv_id": "2512.14691",
    "title": "MMGR: Multi-Modal Generative Reasoning",
    "authors": [
      "Zefan Cai",
      "Haoyi Qiu",
      "Tianyi Ma",
      "Haozhe Zhao",
      "Gengze Zhou",
      "Kung-Hsiang Huang",
      "Parisa Kordjamshidi",
      "Minjia Zhang",
      "Xiao Wen",
      "Jiuxiang Gu",
      "Nanyun Peng",
      "Junjie Hu"
    ],
    "date": "2025-12-16",
    "field": "cs-ai",
    "tags": [
      "cs.CL",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.14691",
    "abstract": "Video foundation models generate visually realistic and temporally coherent content, but their reliability as world simulators depends on whether they capture physical, logical, and spatial constraints. Existing metrics such as Frechet Video Distance (FVD) emphasize perceptual quality and overlook r",
    "file": "cs/ai/2512.14691-mmgr-multi-modal-generative-reasoning.md"
  },
  {
    "arxiv_id": "2512.14619",
    "title": "ParaFormer: A Generalized PageRank Graph Transformer for Graph Representation Learning",
    "authors": [
      "Chaohao Yuan",
      "Zhenjie Song",
      "Ercan Engin Kuruoglu",
      "Kangfei Zhao",
      "Yang Liu",
      "Deli Zhao",
      "Hong Cheng",
      "Yu Rong"
    ],
    "date": "2025-12-16",
    "field": "cs-lg",
    "tags": [
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.14619",
    "abstract": "Graph Transformers (GTs) have emerged as a promising graph learning tool, leveraging their all-pair connected property to effectively capture global information. To address the over-smoothing problem in deep GNNs, global attention was initially introduced, eliminating the necessity for using deep GN",
    "file": "cs/lg/2512.14619-paraformer-a-generalized-pagerank-graph-transform.md"
  },
  {
    "arxiv_id": "2512.14617",
    "title": "Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes",
    "authors": [
      "Alessandro Trapasso",
      "Luca Iocchi",
      "Fabio Patrizi"
    ],
    "date": "2025-12-16",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.14617",
    "abstract": "Many practical decision-making problems involve tasks whose success depends on the entire system history, rather than on achieving a state with desired properties. Markovian Reinforcement Learning (RL) approaches are not suitable for such tasks, while RL with non-Markovian reward decision processes ",
    "file": "cs/lg/2512.14617-model-based-reinforcement-learning-in-discrete-act.md"
  },
  {
    "arxiv_id": "2512.14696",
    "title": "CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives",
    "authors": [
      "Zihan Wang",
      "Jiashun Wang",
      "Jeff Tan",
      "Yiwen Zhao",
      "Jessica Hodgins",
      "Shubham Tulsiani",
      "Deva Ramanan"
    ],
    "date": "2025-12-16",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.GR",
      "cs.RO"
    ],
    "url": "https://arxiv.org/abs/2512.14696",
    "abstract": "We introduce CRISP, a method that recovers simulatable human motion and scene geometry from monocular video. Prior work on joint human-scene reconstruction relies on data-driven priors and joint optimization with no physics in the loop, or recovers noisy geometry with artifacts that cause motion tra",
    "file": "cs/cv/2512.14696-crisp-contact-guided-real2sim-from-monocular-vide.md"
  },
  {
    "arxiv_id": "2512.14614",
    "title": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling",
    "authors": [
      "Wenqiang Sun",
      "Haiyu Zhang",
      "Haoyuan Wang",
      "Junta Wu",
      "Zehan Wang",
      "Zhenwei Wang",
      "Yunhong Wang",
      "Jun Zhang",
      "Tengfei Wang",
      "Chunchao Guo"
    ],
    "date": "2025-12-16",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.GR"
    ],
    "url": "https://arxiv.org/abs/2512.14614",
    "abstract": "This paper presents WorldPlay, a streaming video diffusion model that enables real-time, interactive world modeling with long-term geometric consistency, resolving the trade-off between speed and memory that limits current methods. WorldPlay draws power from three key innovations. 1) We use a Dual A",
    "file": "cs/cv/2512.14614-worldplay-towards-long-term-geometric-consistency.md"
  },
  {
    "arxiv_id": "2512.14640",
    "title": "A Multicenter Benchmark of Multiple Instance Learning Models for Lymphoma Subtyping from HE-stained Whole Slide Images",
    "authors": [
      "Rao Muhammad Umer",
      "Daniel Sens",
      "Jonathan Noll",
      "Christian Matek",
      "Lukas Wolfseher",
      "Rainer Spang",
      "Ralf Huss",
      "Johannes Raffler",
      "Sarah Reinke",
      "Wolfram Klapper",
      "Katja Steiger",
      "Kristina Schwamborn",
      "Carsten Marr"
    ],
    "date": "2025-12-16",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.14640",
    "abstract": "Timely and accurate lymphoma diagnosis is essential for guiding cancer treatment. Standard diagnostic practice combines hematoxylin and eosin (HE)-stained whole slide images with immunohistochemistry, flow cytometry, and molecular genetic tests to determine lymphoma subtypes, a process requiring cos",
    "file": "cs/cv/2512.14640-a-multicenter-benchmark-of-multiple-instance-learn.md"
  },
  {
    "arxiv_id": "2512.14698",
    "title": "TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs",
    "authors": [
      "Jun Zhang",
      "Teng Wang",
      "Yuying Ge",
      "Yixiao Ge",
      "Xinhao Li",
      "Ying Shan",
      "Limin Wang"
    ],
    "date": "2025-12-16",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "url": "https://arxiv.org/abs/2512.14698",
    "abstract": "This paper does not introduce a novel method but instead establishes a straightforward, incremental, yet essential baseline for video temporal grounding (VTG), a core capability in video understanding. While multimodal large language models (MLLMs) excel at various video understanding tasks, the rec",
    "file": "cs/cv/2512.14698-timelens-rethinking-video-temporal-grounding-with.md"
  },
  {
    "arxiv_id": "2512.14639",
    "title": "AMD-HookNet++: Evolution of AMD-HookNet with Hybrid CNN-Transformer Feature Enhancement for Glacier Calving Front Segmentation",
    "authors": [
      "Fei Wu",
      "Marcel Dreier",
      "Nora Gourmelon",
      "Sebastian Wind",
      "Jianlin Zhang",
      "Thorsten Seehaus",
      "Matthias Braun",
      "Andreas Maier",
      "Vincent Christlein"
    ],
    "date": "2025-12-16",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.14639",
    "abstract": "The dynamics of glaciers and ice shelf fronts significantly impact the mass balance of ice sheets and coastal sea levels. To effectively monitor glacier conditions, it is crucial to consistently estimate positional shifts of glacier calving fronts. AMD-HookNet firstly introduces a pure two-branch co",
    "file": "cs/cv/2512.14639-amd-hooknet-evolution-of-amd-hooknet-with-hybri.md"
  },
  {
    "arxiv_id": "2512.14621",
    "title": "Distill Video Datasets into Images",
    "authors": [
      "Zhenghao Zhao",
      "Haoxuan Wang",
      "Kai Wang",
      "Yuzhang Shang",
      "Yuan Hong",
      "Yan Yan"
    ],
    "date": "2025-12-16",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.14621",
    "abstract": "Dataset distillation aims to synthesize compact yet informative datasets that allow models trained on them to achieve performance comparable to training on the full dataset. While this approach has shown promising results for image data, extending dataset distillation methods to video data has prove",
    "file": "cs/cv/2512.14621-distill-video-datasets-into-images.md"
  },
  {
    "arxiv_id": "2512.14671",
    "title": "ART: Articulated Reconstruction Transformer",
    "authors": [
      "Zizhang Li",
      "Cheng Zhang",
      "Zhengqin Li",
      "Henry Howard-Jenkins",
      "Zhaoyang Lv",
      "Chen Geng",
      "Jiajun Wu",
      "Richard Newcombe",
      "Jakob Engel",
      "Zhao Dong"
    ],
    "date": "2025-12-16",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.14671",
    "abstract": "We introduce ART, Articulated Reconstruction Transformer -- a category-agnostic, feed-forward model that reconstructs complete 3D articulated objects from only sparse, multi-state RGB images. Previous methods for articulated object reconstruction either rely on slow optimization with fragile cross-s",
    "file": "cs/cv/2512.14671-art-articulated-reconstruction-transformer.md"
  },
  {
    "arxiv_id": "2512.14629",
    "title": "MuseCPBench: an Empirical Study of Music Editing Methods through Music Context Preservation",
    "authors": [
      "Yash Vishe",
      "Eric Xue",
      "Xunyi Jiang",
      "Zachary Novack",
      "Junda Wu",
      "Julian McAuley",
      "Xin Xu"
    ],
    "date": "2025-12-16",
    "field": "other",
    "tags": [
      "cs.SD",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.14629",
    "abstract": "Music editing plays a vital role in modern music production, with applications in film, broadcasting, and game development. Recent advances in music generation models have enabled diverse editing tasks such as timbre transfer, instrument substitution, and genre transformation. However, many existing",
    "file": "other/2512.14629-musecpbench-an-empirical-study-of-music-editing-m.md"
  },
  {
    "arxiv_id": "2512.14666",
    "title": "EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models",
    "authors": [
      "Zechen Bai",
      "Chen Gao",
      "Mike Zheng Shou"
    ],
    "date": "2025-12-16",
    "field": "other",
    "tags": [
      "cs.RO",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.14666",
    "abstract": "Achieving truly adaptive embodied intelligence requires agents that learn not just by imitating static demonstrations, but by continuously improving through environmental interaction, which is akin to how humans master skills through practice. Vision-Language-Action (VLA) models have advanced roboti",
    "file": "other/2512.14666-evolve-vla-test-time-training-from-environment-fe.md"
  },
  {
    "arxiv_id": "2512.14656",
    "title": "WaveSim: A Wavelet-based Multi-scale Similarity Metric for Weather and Climate Fields",
    "authors": [
      "Gabriele Accarino",
      "Viviana Acquaviva",
      "Sara Shamekh",
      "Duncan Watson-Parris",
      "David Lawrence"
    ],
    "date": "2025-12-16",
    "field": "other",
    "tags": [
      "physics.ao-ph",
      "cs.CV",
      "physics.data-an"
    ],
    "url": "https://arxiv.org/abs/2512.14656",
    "abstract": "We introduce WaveSim, a multi-scale similarity metric for the evaluation of spatial fields in weather and climate applications. WaveSim exploits wavelet transforms to decompose input fields into scale-specific wavelet coefficients. The metric is built by multiplying three orthogonal components deriv",
    "file": "other/2512.14656-wavesim-a-wavelet-based-multi-scale-similarity-me.md"
  },
  {
    "arxiv_id": "2512.13685",
    "title": "Beyond surface form: A pipeline for semantic analysis in Alzheimer's Disease detection from spontaneous speech",
    "authors": [
      "Dylan Phelps",
      "Rodrigo Wilkens",
      "Edward Gow-Smith",
      "Lilian Hubner",
      "B\u00e1rbara Malcorra",
      "C\u00e9sar Renn\u00f3-Costa",
      "Marco Idiart",
      "Maria-Cruz Villa-Uriol",
      "Aline Villavicencio"
    ],
    "date": "2025-12-15",
    "field": "cs-ai",
    "tags": [
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.13685",
    "abstract": "Alzheimer's Disease (AD) is a progressive neurodegenerative condition that adversely affects cognitive abilities. Language-related changes can be automatically identified through the analysis of outputs from linguistic assessment tasks, such as picture description. Language models show promise as a ",
    "file": "cs/ai/2512.13685-beyond-surface-form-a-pipeline-for-semantic-analy.md"
  },
  {
    "arxiv_id": "2512.13672",
    "title": "Directional Textual Inversion for Personalized Text-to-Image Generation",
    "authors": [
      "Kunhee Kim",
      "NaHyeon Park",
      "Kibeom Hong",
      "Hyunjung Shim"
    ],
    "date": "2025-12-15",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.13672",
    "abstract": "Textual Inversion (TI) is an efficient approach to text-to-image personalization but often fails on complex prompts. We trace these failures to embedding norm inflation: learned tokens drift to out-of-distribution magnitudes, degrading prompt conditioning in pre-norm Transformers. Empirically, we sh",
    "file": "cs/lg/2512.13672-directional-textual-inversion-for-personalized-tex.md"
  },
  {
    "arxiv_id": "2512.13668",
    "title": "A Scientific Reasoning Model for Organic Synthesis Procedure Generation",
    "authors": [
      "Guoqing Liu",
      "Junren Li",
      "Zihan Zhao",
      "Eray Inanc",
      "Krzysztof Maziarz",
      "Jose Garrido Torres",
      "Victor Garcia Satorras",
      "Shoko Ueda",
      "Christopher M. Bishop",
      "Marwin Segler"
    ],
    "date": "2025-12-15",
    "field": "cs-lg",
    "tags": [
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.13668",
    "abstract": "Solving computer-aided synthesis planning is essential for enabling fully automated, robot-assisted synthesis workflows and improving the efficiency of drug discovery. A key challenge, however, is bridging the gap between computational route design and practical laboratory execution, particularly th",
    "file": "cs/lg/2512.13668-a-scientific-reasoning-model-for-organic-synthesis.md"
  },
  {
    "arxiv_id": "2512.13690",
    "title": "DiffusionBrowser: Interactive Diffusion Previews via Multi-Branch Decoders",
    "authors": [
      "Susung Hong",
      "Chongjian Ge",
      "Zhifei Zhang",
      "Jui-Hsien Wang"
    ],
    "date": "2025-12-15",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.13690",
    "abstract": "Video diffusion models have revolutionized generative video synthesis, but they are imprecise, slow, and can be opaque during generation -- keeping users in the dark for a prolonged period. In this work, we propose DiffusionBrowser, a model-agnostic, lightweight decoder framework that allows users t",
    "file": "cs/cv/2512.13690-diffusionbrowser-interactive-diffusion-previews-v.md"
  },
  {
    "arxiv_id": "2512.13665",
    "title": "Grab-3D: Detecting AI-Generated Videos from 3D Geometric Temporal Consistency",
    "authors": [
      "Wenhan Chen",
      "Sezer Karaoglu",
      "Theo Gevers"
    ],
    "date": "2025-12-15",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.13665",
    "abstract": "Recent advances in diffusion-based generation techniques enable AI models to produce highly realistic videos, heightening the need for reliable detection mechanisms. However, existing detection methods provide only limited exploration of the 3D geometric patterns present in generated videos. In this",
    "file": "cs/cv/2512.13665-grab-3d-detecting-ai-generated-videos-from-3d-geo.md"
  },
  {
    "arxiv_id": "2512.13680",
    "title": "LASER: Layer-wise Scale Alignment for Training-Free Streaming 4D Reconstruction",
    "authors": [
      "Tianye Ding",
      "Yiming Xie",
      "Yiqing Liang",
      "Moitreya Chatterjee",
      "Pedro Miraldo",
      "Huaizu Jiang"
    ],
    "date": "2025-12-15",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.13680",
    "abstract": "Recent feed-forward reconstruction models like VGGT and $\u03c0^3$ achieve impressive reconstruction quality but cannot process streaming videos due to quadratic memory complexity, limiting their practical deployment. While existing streaming methods address this through learned memory mechanisms or caus",
    "file": "cs/cv/2512.13680-laser-layer-wise-scale-alignment-for-training-fre.md"
  },
  {
    "arxiv_id": "2512.13671",
    "title": "AgentIAD: Tool-Augmented Single-Agent for Industrial Anomaly Detection",
    "authors": [
      "Junwen Miao",
      "Penghui Du",
      "Yi Liu",
      "Yu Wang",
      "Yan Wang"
    ],
    "date": "2025-12-15",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.13671",
    "abstract": "Industrial anomaly detection (IAD) is difficult due to the scarcity of normal reference samples and the subtle, localized nature of many defects. Single-pass vision-language models (VLMs) often overlook small abnormalities and lack explicit mechanisms to compare against canonical normal patterns. We",
    "file": "cs/cv/2512.13671-agentiad-tool-augmented-single-agent-for-industri.md"
  },
  {
    "arxiv_id": "2512.13689",
    "title": "LitePT: Lighter Yet Stronger Point Transformer",
    "authors": [
      "Yuanwen Yue",
      "Damien Robert",
      "Jianyuan Wang",
      "Sunghwan Hong",
      "Jan Dirk Wegner",
      "Christian Rupprecht",
      "Konrad Schindler"
    ],
    "date": "2025-12-15",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.13689",
    "abstract": "Modern neural architectures for 3D point cloud processing contain both convolutional layers and attention blocks, but the best way to assemble them remains unclear. We analyse the role of different computational blocks in 3D point cloud networks and find an intuitive behaviour: convolution is adequa",
    "file": "cs/cv/2512.13689-litept-lighter-yet-stronger-point-transformer.md"
  },
  {
    "arxiv_id": "2512.13677",
    "title": "JoVA: Unified Multimodal Learning for Joint Video-Audio Generation",
    "authors": [
      "Xiaohu Huang",
      "Hao Zhou",
      "Qiangpeng Yang",
      "Shilei Wen",
      "Kai Han"
    ],
    "date": "2025-12-15",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.13677",
    "abstract": "In this paper, we present JoVA, a unified framework for joint video-audio generation. Despite recent encouraging advances, existing methods face two critical limitations. First, most existing approaches can only generate ambient sounds and lack the capability to produce human speech synchronized wit",
    "file": "cs/cv/2512.13677-jova-unified-multimodal-learning-for-joint-video.md"
  },
  {
    "arxiv_id": "2512.13684",
    "title": "Recurrent Video Masked Autoencoders",
    "authors": [
      "Daniel Zoran",
      "Nikhil Parthasarathy",
      "Yi Yang",
      "Drew A Hudson",
      "Joao Carreira",
      "Andrew Zisserman"
    ],
    "date": "2025-12-15",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.13684",
    "abstract": "We present Recurrent Video Masked-Autoencoders (RVM): a novel video representation learning approach that uses a transformer-based recurrent neural network to aggregate dense image features over time, effectively capturing the spatio-temporal structure of natural video data. RVM learns via an asymme",
    "file": "cs/cv/2512.13684-recurrent-video-masked-autoencoders.md"
  },
  {
    "arxiv_id": "2512.12777",
    "title": "State over Tokens: Characterizing the Role of Reasoning Tokens",
    "authors": [
      "Mosh Levy",
      "Zohar Elyoseph",
      "Shauli Ravfogel",
      "Yoav Goldberg"
    ],
    "date": "2025-12-14",
    "field": "cs-ai",
    "tags": [
      "cs.CL",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.12777",
    "abstract": "Large Language Models (LLMs) can generate reasoning tokens before their final answer to boost performance on complex tasks. While these sequences seem like human thought processes, empirical evidence reveals that they are not a faithful explanation of the model's actual reasoning process. To address",
    "file": "cs/ai/2512.12777-state-over-tokens-characterizing-the-role-of-reas.md"
  },
  {
    "arxiv_id": "2512.12775",
    "title": "Persistent Personas? Role-Playing, Instruction Following, and Safety in Extended Interactions",
    "authors": [
      "Pedro Henrique Luz de Araujo",
      "Michael A. Hedderich",
      "Ali Modarressi",
      "Hinrich Schuetze",
      "Benjamin Roth"
    ],
    "date": "2025-12-14",
    "field": "cs-ai",
    "tags": [
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.12775",
    "abstract": "Persona-assigned large language models (LLMs) are used in domains such as education, healthcare, and sociodemographic simulation. Yet, they are typically evaluated only in short, single-round settings that do not reflect real-world usage. We introduce an evaluation protocol that combines long person",
    "file": "cs/ai/2512.12775-persistent-personas-role-playing-instruction-fol.md"
  },
  {
    "arxiv_id": "2512.12756",
    "title": "FysicsWorld: A Unified Full-Modality Benchmark for Any-to-Any Understanding, Generation, and Reasoning",
    "authors": [
      "Yue Jiang",
      "Dingkang Yang",
      "Minghao Han",
      "Jinghang Han",
      "Zizhi Chen",
      "Yizhou Liu",
      "Mingcheng Li",
      "Peng Zhai",
      "Lihua Zhang"
    ],
    "date": "2025-12-14",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.12756",
    "abstract": "Despite rapid progress in multimodal large language models (MLLMs) and emerging omni-modal architectures, current benchmarks remain limited in scope and integration, suffering from incomplete modality coverage, restricted interaction to text-centric outputs, and weak interdependence and complementar",
    "file": "cs/cv/2512.12756-fysicsworld-a-unified-full-modality-benchmark-for.md"
  },
  {
    "arxiv_id": "2512.12772",
    "title": "JointAVBench: A Benchmark for Joint Audio-Visual Reasoning Evaluation",
    "authors": [
      "Jianghan Chao",
      "Jianzhang Gao",
      "Wenhui Tan",
      "Yuchong Sun",
      "Ruihua Song",
      "Liyun Ru"
    ],
    "date": "2025-12-14",
    "field": "other",
    "tags": [
      "cs.MM",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.12772",
    "abstract": "Understanding videos inherently requires reasoning over both visual and auditory information. To properly evaluate Omni-Large Language Models (Omni-LLMs), which are capable of processing multi-modal information including vision and audio, an effective benchmark must comprehensively cover three key a",
    "file": "other/2512.12772-jointavbench-a-benchmark-for-joint-audio-visual-r.md"
  },
  {
    "arxiv_id": "2512.12769",
    "title": "Adaptive Edge-Cloud Inference for Speech-to-Action Systems Using ASR and Large Language Models (ASTA)",
    "authors": [
      "Mohammad Jalili Torkamani",
      "Israt Zarin"
    ],
    "date": "2025-12-14",
    "field": "other",
    "tags": [
      "cs.SD",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.12769",
    "abstract": "Voice-based interaction has emerged as a natural and intuitive modality for controlling IoT devices. However, speech-driven edge devices face a fundamental trade-off between cloud-based solutions, which offer stronger language understanding capabilities at the cost of latency, connectivity dependenc",
    "file": "other/2512.12769-adaptive-edge-cloud-inference-for-speech-to-action.md"
  },
  {
    "arxiv_id": "2512.10807",
    "title": "HAROOD: A Benchmark for Out-of-distribution Generalization in Sensor-based Human Activity Recognition",
    "authors": [
      "Wang Lu",
      "Yao Zhu",
      "Jindong Wang"
    ],
    "date": "2025-12-11",
    "field": "cs-ai",
    "tags": [
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10807",
    "abstract": "Sensor-based human activity recognition (HAR) mines activity patterns from the time-series sensory data. In realistic scenarios, variations across individuals, devices, environments, and time introduce significant distributional shifts for the same activities. Recent efforts attempt to solve this ch",
    "file": "cs/ai/2512.10807-harood-a-benchmark-for-out-of-distribution-genera.md"
  },
  {
    "arxiv_id": "2512.10895",
    "title": "LLMs Can Assist with Proposal Selection at Large User Facilities",
    "authors": [
      "Lijie Ding",
      "Janell Thomson",
      "Jon Taylor",
      "Changwoo Do"
    ],
    "date": "2025-12-11",
    "field": "cs-ai",
    "tags": [
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10895",
    "abstract": "We explore how large language models (LLMs) can enhance the proposal selection process at large user facilities, offering a scalable, consistent, and cost-effective alternative to traditional human review. Proposal selection depends on assessing the relative strength among submitted proposals; howev",
    "file": "cs/ai/2512.10895-llms-can-assist-with-proposal-selection-at-large-u.md"
  },
  {
    "arxiv_id": "2512.10903",
    "title": "Multi-Granular Node Pruning for Circuit Discovery",
    "authors": [
      "Muhammad Umair Haider",
      "Hammad Rizwan",
      "Hassan Sajjad",
      "A. B. Siddique"
    ],
    "date": "2025-12-11",
    "field": "cs-ai",
    "tags": [
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10903",
    "abstract": "Circuit discovery aims to identify minimal subnetworks that are responsible for specific behaviors in large language models (LLMs). Existing approaches primarily rely on iterative edge pruning, which is computationally expensive and limited to coarse-grained units such as attention heads or MLP bloc",
    "file": "cs/ai/2512.10903-multi-granular-node-pruning-for-circuit-discovery.md"
  },
  {
    "arxiv_id": "2512.10882",
    "title": "Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity",
    "authors": [
      "Hauke Licht"
    ],
    "date": "2025-12-11",
    "field": "cs-ai",
    "tags": [
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.10882",
    "abstract": "Emotions are central to politics and analyzing their role in political communication has a long tradition. As research increasingly leverages audio-visual materials to analyze the display of emotions, the emergence of multimodal generative AI promises great advances. However, we lack evidence about ",
    "file": "cs/ai/2512.10882-computational-emotion-analysis-with-multimodal-llm.md"
  },
  {
    "arxiv_id": "2512.10922",
    "title": "SparseSwaps: Tractable LLM Pruning Mask Refinement at Scale",
    "authors": [
      "Max Zimmer",
      "Christophe Roux",
      "Moritz Wagner",
      "Deborah Hendrych",
      "Sebastian Pokutta"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10922",
    "abstract": "The resource requirements of Neural Networks can be significantly reduced through pruning -- the removal of seemingly less important parameters. However, with the rise of Large Language Models (LLMs), full retraining to recover pruning-induced performance degradation is often prohibitive and classic",
    "file": "cs/lg/2512.10922-sparseswaps-tractable-llm-pruning-mask-refinement.md"
  },
  {
    "arxiv_id": "2512.10936",
    "title": "Empirical evaluation of the Frank-Wolfe methods for constructing white-box adversarial attacks",
    "authors": [
      "Kristina Korotkova",
      "Aleksandr Katrutsa"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10936",
    "abstract": "The construction of adversarial attacks for neural networks appears to be a crucial challenge for their deployment in various services. To estimate the adversarial robustness of a neural network, a fast and efficient approach is needed to construct adversarial attacks. Since the formalization of adv",
    "file": "cs/lg/2512.10936-empirical-evaluation-of-the-frank-wolfe-methods-fo.md"
  },
  {
    "arxiv_id": "2512.10953",
    "title": "Bidirectional Normalizing Flow: From Data to Noise and Back",
    "authors": [
      "Yiyang Lu",
      "Qiao Sun",
      "Xianbang Wang",
      "Zhicheng Jiang",
      "Hanhong Zhao",
      "Kaiming He"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10953",
    "abstract": "Normalizing Flows (NFs) have been established as a principled framework for generative modeling. Standard NFs consist of a forward process and a reverse process: the forward process maps data to noise, while the reverse process generates samples by inverting it. Typical NF forward transformations ar",
    "file": "cs/lg/2512.10953-bidirectional-normalizing-flow-from-data-to-noise.md"
  },
  {
    "arxiv_id": "2512.10817",
    "title": "Extrapolation of Periodic Functions Using Binary Encoding of Continuous Numerical Values",
    "authors": [
      "Brian P. Powell",
      "Jordan A. Caraballo-Vega",
      "Mark L. Carroll",
      "Thomas Maxwell",
      "Andrew Ptak",
      "Greg Olmschenk",
      "Jorge Martinez-Palomera"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "url": "https://arxiv.org/abs/2512.10817",
    "abstract": "We report the discovery that binary encoding allows neural networks to extrapolate periodic functions beyond their training bounds. We introduce Normalized Base-2 Encoding (NB2E) as a method for encoding continuous numerical values and demonstrate that, using this input encoding, vanilla multi-layer",
    "file": "cs/lg/2512.10817-extrapolation-of-periodic-functions-using-binary-e.md"
  },
  {
    "arxiv_id": "2512.10877",
    "title": "Guided Transfer Learning for Discrete Diffusion Models",
    "authors": [
      "Julian Kleutgens",
      "Claudio Battiloro",
      "Lingkai Kong",
      "Benjamin Grewe",
      "Francesca Dominici",
      "Mauricio Tec"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.10877",
    "abstract": "Discrete diffusion models achieve strong performance across language and other discrete domains, providing a powerful alternative to autoregressive models. However, their strong performance relies on large training datasets, which are costly or risky to obtain, especially when adapting to new domain",
    "file": "cs/lg/2512.10877-guided-transfer-learning-for-discrete-diffusion-mo.md"
  },
  {
    "arxiv_id": "2512.10866",
    "title": "UrbanAI 2025 Challenge: Linear vs Transformer Models for Long-Horizon Exogenous Temperature Forecasting",
    "authors": [
      "Ruslan Gokhman"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10866",
    "abstract": "We study long-horizon exogenous-only temperature forecasting - a challenging univariate setting where only the past values of the indoor temperature are used for prediction - using linear and Transformer-family models. We evaluate Linear, NLinear, DLinear, Transformer, Informer, and Autoformer under",
    "file": "cs/lg/2512.10866-urbanai-2025-challenge-linear-vs-transformer-mode.md"
  },
  {
    "arxiv_id": "2512.10858",
    "title": "Scaling Behavior of Discrete Diffusion Language Models",
    "authors": [
      "Dimitri von R\u00fctte",
      "Janis Fluri",
      "Omead Pooladzandi",
      "Bernhard Sch\u00f6lkopf",
      "Thomas Hofmann",
      "Antonio Orvieto"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.10858",
    "abstract": "Modern LLM pre-training consumes vast amounts of compute and training data, making the scaling behavior, or scaling laws, of different models a key distinguishing factor. Discrete diffusion language models (DLMs) have been proposed as an alternative to autoregressive language models (ALMs). However,",
    "file": "cs/lg/2512.10858-scaling-behavior-of-discrete-diffusion-language-mo.md"
  },
  {
    "arxiv_id": "2512.10938",
    "title": "Stronger Normalization-Free Transformers",
    "authors": [
      "Mingzhi Chen",
      "Taiming Lu",
      "Jiachen Zhu",
      "Mingjie Sun",
      "Zhuang Liu"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10938",
    "abstract": "Although normalization layers have long been viewed as indispensable components of deep learning architectures, the recent introduction of Dynamic Tanh (DyT) has demonstrated that alternatives are possible. The point-wise function DyT constrains extreme values for stable convergence and reaches norm",
    "file": "cs/lg/2512.10938-stronger-normalization-free-transformers.md"
  },
  {
    "arxiv_id": "2512.10925",
    "title": "Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation",
    "authors": [
      "Zamirddine Mari",
      "Mohamad Motasem Nawaf",
      "Pierre Drap"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.RO"
    ],
    "url": "https://arxiv.org/abs/2512.10925",
    "abstract": "Autonomous navigation in underwater environments remains a major challenge due to the absence of GPS, degraded visibility, and the presence of submerged obstacles. This article investigates these issues through the case of the BlueROV2, an open platform widely used for scientific experimentation. We",
    "file": "cs/lg/2512.10925-digital-twin-supervised-reinforcement-learning-fra.md"
  },
  {
    "arxiv_id": "2512.10835",
    "title": "Learning Controllable and Diverse Player Behaviors in Multi-Agent Environments",
    "authors": [
      "Atahan Cilan",
      "Atay \u00d6zg\u00f6vde"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.10835",
    "abstract": "This paper introduces a reinforcement learning framework that enables controllable and diverse player behaviors without relying on human gameplay data. Existing approaches often require large-scale player trajectories, train separate models for different player types, or provide no direct mapping be",
    "file": "cs/lg/2512.10835-learning-controllable-and-diverse-player-behaviors.md"
  },
  {
    "arxiv_id": "2512.10949",
    "title": "Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation",
    "authors": [
      "Yiwen Tang",
      "Zoey Guo",
      "Kaixin Zhu",
      "Ray Zhang",
      "Qizhi Chen",
      "Dongzhi Jiang",
      "Junli Liu",
      "Bohan Zeng",
      "Haoming Song",
      "Delin Qu",
      "Tianyi Bai",
      "Dan Xu",
      "Wentao Zhang",
      "Bin Zhao"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.10949",
    "abstract": "Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which req",
    "file": "cs/cv/2512.10949-are-we-ready-for-rl-in-text-to-3d-generation-a-pr.md"
  },
  {
    "arxiv_id": "2512.10943",
    "title": "AlcheMinT: Fine-grained Temporal Control for Multi-Reference Consistent Video Generation",
    "authors": [
      "Sharath Girish",
      "Viacheslav Ivanov",
      "Tsai-Shien Chen",
      "Hao Chen",
      "Aliaksandr Siarohin",
      "Sergey Tulyakov"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10943",
    "abstract": "Recent advances in subject-driven video generation with large diffusion models have enabled personalized content synthesis conditioned on user-provided subjects. However, existing methods lack fine-grained temporal control over subject appearance and disappearance, which are essential for applicatio",
    "file": "cs/cv/2512.10943-alchemint-fine-grained-temporal-control-for-multi.md"
  },
  {
    "arxiv_id": "2512.10947",
    "title": "Towards Efficient and Effective Multi-Camera Encoding for End-to-End Driving",
    "authors": [
      "Jiawei Yang",
      "Ziyu Chen",
      "Yurong You",
      "Yan Wang",
      "Yiming Li",
      "Yuxiao Chen",
      "Boyi Li",
      "Boris Ivanovic",
      "Marco Pavone",
      "Yue Wang"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10947",
    "abstract": "We present Flex, an efficient and effective scene encoder that addresses the computational bottleneck of processing high-volume multi-camera data in end-to-end autonomous driving. Flex employs a small set of learnable scene tokens to jointly encode information from all image tokens across different ",
    "file": "cs/cv/2512.10947-towards-efficient-and-effective-multi-camera-encod.md"
  },
  {
    "arxiv_id": "2512.10954",
    "title": "Group Diffusion: Enhancing Image Generation by Unlocking Cross-Sample Collaboration",
    "authors": [
      "Sicheng Mo",
      "Thao Nguyen",
      "Richard Zhang",
      "Nick Kolkin",
      "Siddharth Srinivasan Iyer",
      "Eli Shechtman",
      "Krishna Kumar Singh",
      "Yong Jae Lee",
      "Bolei Zhou",
      "Yuheng Li"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10954",
    "abstract": "In this work, we explore an untapped signal in diffusion model inference. While all previous methods generate images independently at inference, we instead ask if samples can be generated collaboratively. We propose Group Diffusion, unlocking the attention mechanism to be shared across images, rathe",
    "file": "cs/cv/2512.10954-group-diffusion-enhancing-image-generation-by-unl.md"
  },
  {
    "arxiv_id": "2512.10867",
    "title": "From Macro to Micro: Benchmarking Microscopic Spatial Intelligence on Molecules via Vision-Language Models",
    "authors": [
      "Zongzhao Li",
      "Xiangzhe Kong",
      "Jiahui Su",
      "Zongyang Ma",
      "Mingze Li",
      "Songyou Li",
      "Yuelin Zhang",
      "Yu Rong",
      "Tingyang Xu",
      "Deli Zhao",
      "Wenbing Huang"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10867",
    "abstract": "This paper introduces the concept of Microscopic Spatial Intelligence (MiSI), the capability to perceive and reason about the spatial relationships of invisible microscopic entities, which is fundamental to scientific discovery. To assess the potential of Vision-Language Models (VLMs) in this domain",
    "file": "cs/cv/2512.10867-from-macro-to-micro-benchmarking-microscopic-spat.md"
  },
  {
    "arxiv_id": "2512.10860",
    "title": "SWiT-4D: Sliding-Window Transformer for Lossless and Parameter-Free Temporal 4D Generation",
    "authors": [
      "Kehong Gong",
      "Zhengyu Wen",
      "Mingxi Xu",
      "Weixia He",
      "Qi Wang",
      "Ning Zhang",
      "Zhengyu Li",
      "Chenbin Li",
      "Dongze Lian",
      "Wei Zhao",
      "Xiaoyu He",
      "Mingyuan Zhang"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10860",
    "abstract": "Despite significant progress in 4D content generation, the conversion of monocular videos into high-quality animated 3D assets with explicit 4D meshes remains considerably challenging. The scarcity of large-scale, naturally captured 4D mesh datasets further limits the ability to train generalizable ",
    "file": "cs/cv/2512.10860-swit-4d-sliding-window-transformer-for-lossless-a.md"
  },
  {
    "arxiv_id": "2512.10935",
    "title": "Any4D: Unified Feed-Forward Metric 4D Reconstruction",
    "authors": [
      "Jay Karhade",
      "Nikhil Keetha",
      "Yuchen Zhang",
      "Tanisha Gupta",
      "Akash Sharma",
      "Sebastian Scherer",
      "Deva Ramanan"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "url": "https://arxiv.org/abs/2512.10935",
    "abstract": "We present Any4D, a scalable multi-view transformer for metric-scale, dense feed-forward 4D reconstruction. Any4D directly generates per-pixel motion and geometry predictions for N frames, in contrast to prior work that typically focuses on either 2-view dense scene flow or sparse 3D point tracking.",
    "file": "cs/cv/2512.10935-any4d-unified-feed-forward-metric-4d-reconstructi.md"
  },
  {
    "arxiv_id": "2512.10939",
    "title": "GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting",
    "authors": [
      "Madhav Agarwal",
      "Mingtian Zhang",
      "Laura Sevilla-Lara",
      "Steven McDonagh"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10939",
    "abstract": "Speech-driven talking heads have recently emerged and enable interactive avatars. However, real-world applications are limited, as current methods achieve high visual fidelity but slow or fast yet temporally unstable. Diffusion methods provide realistic image generation, yet struggle with oneshot se",
    "file": "cs/cv/2512.10939-gaussianheadtalk-wobble-free-3d-talking-heads-wit.md"
  },
  {
    "arxiv_id": "2512.10927",
    "title": "FoundationMotion: Auto-Labeling and Reasoning about Spatial Movement in Videos",
    "authors": [
      "Yulu Gan",
      "Ligeng Zhu",
      "Dandan Shan",
      "Baifeng Shi",
      "Hongxu Yin",
      "Boris Ivanovic",
      "Song Han",
      "Trevor Darrell",
      "Jitendra Malik",
      "Marco Pavone",
      "Boyi Li"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10927",
    "abstract": "Motion understanding is fundamental to physical reasoning, enabling models to infer dynamics and predict future states. However, state-of-the-art models still struggle on recent motion benchmarks, primarily due to the scarcity of large-scale, fine-grained motion datasets. Existing motion datasets ar",
    "file": "cs/cv/2512.10927-foundationmotion-auto-labeling-and-reasoning-abou.md"
  },
  {
    "arxiv_id": "2512.10940",
    "title": "OmniView: An All-Seeing Diffusion Model for 3D and 4D View Synthesis",
    "authors": [
      "Xiang Fan",
      "Sharath Girish",
      "Vivek Ramanujan",
      "Chaoyang Wang",
      "Ashkan Mirzaei",
      "Petr Sushko",
      "Aliaksandr Siarohin",
      "Sergey Tulyakov",
      "Ranjay Krishna"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10940",
    "abstract": "Prior approaches injecting camera control into diffusion models have focused on specific subsets of 4D consistency tasks: novel view synthesis, text-to-video with camera control, image-to-video, amongst others. Therefore, these fragmented approaches are trained on disjoint slices of available 3D/4D ",
    "file": "cs/cv/2512.10940-omniview-an-all-seeing-diffusion-model-for-3d-and.md"
  },
  {
    "arxiv_id": "2512.10808",
    "title": "Graph Laplacian Transformer with Progressive Sampling for Prostate Cancer Grading",
    "authors": [
      "Masum Shah Junayed",
      "John Derek Van Vessem",
      "Qian Wan",
      "Gahie Nam",
      "Sheida Nabavi"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10808",
    "abstract": "Prostate cancer grading from whole-slide images (WSIs) remains a challenging task due to the large-scale nature of WSIs, the presence of heterogeneous tissue structures, and difficulty of selecting diagnostically relevant regions. Existing approaches often rely on random or static patch selection, l",
    "file": "cs/cv/2512.10808-graph-laplacian-transformer-with-progressive-sampl.md"
  },
  {
    "arxiv_id": "2512.10932",
    "title": "BabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models",
    "authors": [
      "Shengao Wang",
      "Wenqi Wang",
      "Zecheng Wang",
      "Max Whitton",
      "Michael Wakeham",
      "Arjun Chandra",
      "Joey Huang",
      "Pengyue Zhu",
      "Helen Chen",
      "David Li",
      "Jeffrey Li",
      "Shawn Li",
      "Andrew Zagula",
      "Amy Zhao",
      "Andrew Zhu",
      "Sayaka Nakamura",
      "Yuki Yamamoto",
      "Jerry Jun Yokono",
      "Aaron Mueller",
      "Bryan A. Plummer",
      "Kate Saenko",
      "Venkatesh Saligrama",
      "Boqing Gong"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10932",
    "abstract": "Early children's developmental trajectories set up a natural goal for sample-efficient pretraining of vision foundation models. We introduce BabyVLM-V2, a developmentally grounded framework for infant-inspired vision-language modeling that extensively improves upon BabyVLM-V1 through a longitudinal,",
    "file": "cs/cv/2512.10932-babyvlm-v2-toward-developmentally-grounded-pretra.md"
  },
  {
    "arxiv_id": "2512.10840",
    "title": "PoseGAM: Robust Unseen Object Pose Estimation via Geometry-Aware Multi-View Reasoning",
    "authors": [
      "Jianqi Chen",
      "Biao Zhang",
      "Xiangjun Tang",
      "Peter Wonka"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10840",
    "abstract": "6D object pose estimation, which predicts the transformation of an object relative to the camera, remains challenging for unseen objects. Existing approaches typically rely on explicitly constructing feature correspondences between the query image and either the object model or template images. In t",
    "file": "cs/cv/2512.10840-posegam-robust-unseen-object-pose-estimation-via.md"
  },
  {
    "arxiv_id": "2512.10888",
    "title": "PubTables-v2: A new large-scale dataset for full-page and multi-page table extraction",
    "authors": [
      "Brandon Smock",
      "Valerie Faucon-Morin",
      "Max Sokolov",
      "Libin Liang",
      "Tayyibah Khanam",
      "Maury Courtland"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10888",
    "abstract": "Table extraction (TE) is a key challenge in visual document understanding. Traditional approaches detect tables first, then recognize their structure. Recently, interest has surged in developing methods, such as vision-language models (VLMs), that can extract tables directly in their full page or do",
    "file": "cs/cv/2512.10888-pubtables-v2-a-new-large-scale-dataset-for-full-p.md"
  },
  {
    "arxiv_id": "2512.10934",
    "title": "Curriculum-Based Reinforcement Learning for Autonomous UAV Navigation in Unknown Curved Tubular Conduit",
    "authors": [
      "Zamirddine Mari",
      "J\u00e9r\u00f4me Pasquet",
      "Julien Seinturier"
    ],
    "date": "2025-12-11",
    "field": "other",
    "tags": [
      "cs.RO",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.10934",
    "abstract": "Autonomous drone navigation in confined tubular environments remains a major challenge due to the constraining geometry of the conduits, the proximity of the walls, and the perceptual limitations inherent to such scenarios. We propose a reinforcement learning approach enabling a drone to navigate un",
    "file": "other/2512.10934-curriculum-based-reinforcement-learning-for-autono.md"
  },
  {
    "arxiv_id": "2512.10891",
    "title": "Iterative Compositional Data Generation for Robot Control",
    "authors": [
      "Anh-Quan Pham",
      "Marcel Hussing",
      "Shubhankar P. Patankar",
      "Dani S. Bassett",
      "Jorge Mendez-Mendez",
      "Eric Eaton"
    ],
    "date": "2025-12-11",
    "field": "other",
    "tags": [
      "cs.RO",
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.10891",
    "abstract": "Collecting robotic manipulation data is expensive, making it impractical to acquire demonstrations for the combinatorially large space of tasks that arise in multi-object, multi-robot, and multi-environment settings. While recent generative models can synthesize useful data for individual tasks, the",
    "file": "other/2512.10891-iterative-compositional-data-generation-for-robot.md"
  }
]