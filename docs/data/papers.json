[
  {
    "arxiv_id": "2512.10936",
    "title": "Empirical evaluation of the Frank-Wolfe methods for constructing white-box adversarial attacks",
    "authors": [
      "Kristina Korotkova",
      "Aleksandr Katrutsa"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10936",
    "abstract": "The construction of adversarial attacks for neural networks appears to be a crucial challenge for their deployment in various services. To estimate the adversarial robustness of a neural network, a fast and efficient approach is needed to construct adversarial attacks. Since the formalization of adv",
    "file": "cs/lg/2512.10936-empirical-evaluation-of-the-frank-wolfe-methods-fo.md"
  },
  {
    "arxiv_id": "2512.10953",
    "title": "Bidirectional Normalizing Flow: From Data to Noise and Back",
    "authors": [
      "Yiyang Lu",
      "Qiao Sun",
      "Xianbang Wang",
      "Zhicheng Jiang",
      "Hanhong Zhao",
      "Kaiming He"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10953",
    "abstract": "Normalizing Flows (NFs) have been established as a principled framework for generative modeling. Standard NFs consist of a forward process and a reverse process: the forward process maps data to noise, while the reverse process generates samples by inverting it. Typical NF forward transformations ar",
    "file": "cs/lg/2512.10953-bidirectional-normalizing-flow-from-data-to-noise.md"
  },
  {
    "arxiv_id": "2512.10817",
    "title": "Extrapolation of Periodic Functions Using Binary Encoding of Continuous Numerical Values",
    "authors": [
      "Brian P. Powell",
      "Jordan A. Caraballo-Vega",
      "Mark L. Carroll",
      "Thomas Maxwell",
      "Andrew Ptak",
      "Greg Olmschenk",
      "Jorge Martinez-Palomera"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "url": "https://arxiv.org/abs/2512.10817",
    "abstract": "We report the discovery that binary encoding allows neural networks to extrapolate periodic functions beyond their training bounds. We introduce Normalized Base-2 Encoding (NB2E) as a method for encoding continuous numerical values and demonstrate that, using this input encoding, vanilla multi-layer",
    "file": "cs/lg/2512.10817-extrapolation-of-periodic-functions-using-binary-e.md"
  },
  {
    "arxiv_id": "2512.10858",
    "title": "Scaling Behavior of Discrete Diffusion Language Models",
    "authors": [
      "Dimitri von R\u00fctte",
      "Janis Fluri",
      "Omead Pooladzandi",
      "Bernhard Sch\u00f6lkopf",
      "Thomas Hofmann",
      "Antonio Orvieto"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.10858",
    "abstract": "Modern LLM pre-training consumes vast amounts of compute and training data, making the scaling behavior, or scaling laws, of different models a key distinguishing factor. Discrete diffusion language models (DLMs) have been proposed as an alternative to autoregressive language models (ALMs). However,",
    "file": "cs/lg/2512.10858-scaling-behavior-of-discrete-diffusion-language-mo.md"
  },
  {
    "arxiv_id": "2512.10938",
    "title": "Stronger Normalization-Free Transformers",
    "authors": [
      "Mingzhi Chen",
      "Taiming Lu",
      "Jiachen Zhu",
      "Mingjie Sun",
      "Zhuang Liu"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10938",
    "abstract": "Although normalization layers have long been viewed as indispensable components of deep learning architectures, the recent introduction of Dynamic Tanh (DyT) has demonstrated that alternatives are possible. The point-wise function DyT constrains extreme values for stable convergence and reaches norm",
    "file": "cs/lg/2512.10938-stronger-normalization-free-transformers.md"
  },
  {
    "arxiv_id": "2512.10835",
    "title": "Learning Controllable and Diverse Player Behaviors in Multi-Agent Environments",
    "authors": [
      "Atahan Cilan",
      "Atay \u00d6zg\u00f6vde"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.10835",
    "abstract": "This paper introduces a reinforcement learning framework that enables controllable and diverse player behaviors without relying on human gameplay data. Existing approaches often require large-scale player trajectories, train separate models for different player types, or provide no direct mapping be",
    "file": "cs/lg/2512.10835-learning-controllable-and-diverse-player-behaviors.md"
  },
  {
    "arxiv_id": "2512.10949",
    "title": "Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation",
    "authors": [
      "Yiwen Tang",
      "Zoey Guo",
      "Kaixin Zhu",
      "Ray Zhang",
      "Qizhi Chen",
      "Dongzhi Jiang",
      "Junli Liu",
      "Bohan Zeng",
      "Haoming Song",
      "Delin Qu",
      "Tianyi Bai",
      "Dan Xu",
      "Wentao Zhang",
      "Bin Zhao"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.10949",
    "abstract": "Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which req",
    "file": "cs/cv/2512.10949-are-we-ready-for-rl-in-text-to-3d-generation-a-pr.md"
  },
  {
    "arxiv_id": "2512.10943",
    "title": "AlcheMinT: Fine-grained Temporal Control for Multi-Reference Consistent Video Generation",
    "authors": [
      "Sharath Girish",
      "Viacheslav Ivanov",
      "Tsai-Shien Chen",
      "Hao Chen",
      "Aliaksandr Siarohin",
      "Sergey Tulyakov"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10943",
    "abstract": "Recent advances in subject-driven video generation with large diffusion models have enabled personalized content synthesis conditioned on user-provided subjects. However, existing methods lack fine-grained temporal control over subject appearance and disappearance, which are essential for applicatio",
    "file": "cs/cv/2512.10943-alchemint-fine-grained-temporal-control-for-multi.md"
  },
  {
    "arxiv_id": "2512.10947",
    "title": "Towards Efficient and Effective Multi-Camera Encoding for End-to-End Driving",
    "authors": [
      "Jiawei Yang",
      "Ziyu Chen",
      "Yurong You",
      "Yan Wang",
      "Yiming Li",
      "Yuxiao Chen",
      "Boyi Li",
      "Boris Ivanovic",
      "Marco Pavone",
      "Yue Wang"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10947",
    "abstract": "We present Flex, an efficient and effective scene encoder that addresses the computational bottleneck of processing high-volume multi-camera data in end-to-end autonomous driving. Flex employs a small set of learnable scene tokens to jointly encode information from all image tokens across different ",
    "file": "cs/cv/2512.10947-towards-efficient-and-effective-multi-camera-encod.md"
  },
  {
    "arxiv_id": "2512.10954",
    "title": "Group Diffusion: Enhancing Image Generation by Unlocking Cross-Sample Collaboration",
    "authors": [
      "Sicheng Mo",
      "Thao Nguyen",
      "Richard Zhang",
      "Nick Kolkin",
      "Siddharth Srinivasan Iyer",
      "Eli Shechtman",
      "Krishna Kumar Singh",
      "Yong Jae Lee",
      "Bolei Zhou",
      "Yuheng Li"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10954",
    "abstract": "In this work, we explore an untapped signal in diffusion model inference. While all previous methods generate images independently at inference, we instead ask if samples can be generated collaboratively. We propose Group Diffusion, unlocking the attention mechanism to be shared across images, rathe",
    "file": "cs/cv/2512.10954-group-diffusion-enhancing-image-generation-by-unl.md"
  },
  {
    "arxiv_id": "2512.10860",
    "title": "SWiT-4D: Sliding-Window Transformer for Lossless and Parameter-Free Temporal 4D Generation",
    "authors": [
      "Kehong Gong",
      "Zhengyu Wen",
      "Mingxi Xu",
      "Weixia He",
      "Qi Wang",
      "Ning Zhang",
      "Zhengyu Li",
      "Chenbin Li",
      "Dongze Lian",
      "Wei Zhao",
      "Xiaoyu He",
      "Mingyuan Zhang"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10860",
    "abstract": "Despite significant progress in 4D content generation, the conversion of monocular videos into high-quality animated 3D assets with explicit 4D meshes remains considerably challenging. The scarcity of large-scale, naturally captured 4D mesh datasets further limits the ability to train generalizable ",
    "file": "cs/cv/2512.10860-swit-4d-sliding-window-transformer-for-lossless-a.md"
  },
  {
    "arxiv_id": "2512.10935",
    "title": "Any4D: Unified Feed-Forward Metric 4D Reconstruction",
    "authors": [
      "Jay Karhade",
      "Nikhil Keetha",
      "Yuchen Zhang",
      "Tanisha Gupta",
      "Akash Sharma",
      "Sebastian Scherer",
      "Deva Ramanan"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "url": "https://arxiv.org/abs/2512.10935",
    "abstract": "We present Any4D, a scalable multi-view transformer for metric-scale, dense feed-forward 4D reconstruction. Any4D directly generates per-pixel motion and geometry predictions for N frames, in contrast to prior work that typically focuses on either 2-view dense scene flow or sparse 3D point tracking.",
    "file": "cs/cv/2512.10935-any4d-unified-feed-forward-metric-4d-reconstructi.md"
  },
  {
    "arxiv_id": "2512.10939",
    "title": "GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting",
    "authors": [
      "Madhav Agarwal",
      "Mingtian Zhang",
      "Laura Sevilla-Lara",
      "Steven McDonagh"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10939",
    "abstract": "Speech-driven talking heads have recently emerged and enable interactive avatars. However, real-world applications are limited, as current methods achieve high visual fidelity but slow or fast yet temporally unstable. Diffusion methods provide realistic image generation, yet struggle with oneshot se",
    "file": "cs/cv/2512.10939-gaussianheadtalk-wobble-free-3d-talking-heads-wit.md"
  },
  {
    "arxiv_id": "2512.10940",
    "title": "OmniView: An All-Seeing Diffusion Model for 3D and 4D View Synthesis",
    "authors": [
      "Xiang Fan",
      "Sharath Girish",
      "Vivek Ramanujan",
      "Chaoyang Wang",
      "Ashkan Mirzaei",
      "Petr Sushko",
      "Aliaksandr Siarohin",
      "Sergey Tulyakov",
      "Ranjay Krishna"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10940",
    "abstract": "Prior approaches injecting camera control into diffusion models have focused on specific subsets of 4D consistency tasks: novel view synthesis, text-to-video with camera control, image-to-video, amongst others. Therefore, these fragmented approaches are trained on disjoint slices of available 3D/4D ",
    "file": "cs/cv/2512.10940-omniview-an-all-seeing-diffusion-model-for-3d-and.md"
  },
  {
    "arxiv_id": "2512.10840",
    "title": "PoseGAM: Robust Unseen Object Pose Estimation via Geometry-Aware Multi-View Reasoning",
    "authors": [
      "Jianqi Chen",
      "Biao Zhang",
      "Xiangjun Tang",
      "Peter Wonka"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10840",
    "abstract": "6D object pose estimation, which predicts the transformation of an object relative to the camera, remains challenging for unseen objects. Existing approaches typically rely on explicitly constructing feature correspondences between the query image and either the object model or template images. In t",
    "file": "cs/cv/2512.10840-posegam-robust-unseen-object-pose-estimation-via.md"
  }
]