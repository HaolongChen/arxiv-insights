[
  {
    "arxiv_id": "2512.10953",
    "title": "Bidirectional Normalizing Flow: From Data to Noise and Back",
    "authors": [
      "Yiyang Lu",
      "Qiao Sun",
      "Xianbang Wang",
      "Zhicheng Jiang",
      "Hanhong Zhao",
      "Kaiming He"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10953",
    "abstract": "Normalizing Flows (NFs) have been established as a principled framework for generative modeling. Standard NFs consist of a forward process and a reverse process: the forward process maps data to noise, while the reverse process generates samples by inverting it. Typical NF forward transformations ar",
    "file": "cs/lg/2512.10953-bidirectional-normalizing-flow-from-data-to-noise.md"
  },
  {
    "arxiv_id": "2512.10817",
    "title": "Extrapolation of Periodic Functions Using Binary Encoding of Continuous Numerical Values",
    "authors": [
      "Brian P. Powell",
      "Jordan A. Caraballo-Vega",
      "Mark L. Carroll",
      "Thomas Maxwell",
      "Andrew Ptak",
      "Greg Olmschenk",
      "Jorge Martinez-Palomera"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "url": "https://arxiv.org/abs/2512.10817",
    "abstract": "We report the discovery that binary encoding allows neural networks to extrapolate periodic functions beyond their training bounds. We introduce Normalized Base-2 Encoding (NB2E) as a method for encoding continuous numerical values and demonstrate that, using this input encoding, vanilla multi-layer",
    "file": "cs/lg/2512.10817-extrapolation-of-periodic-functions-using-binary-e.md"
  },
  {
    "arxiv_id": "2512.10858",
    "title": "Scaling Behavior of Discrete Diffusion Language Models",
    "authors": [
      "Dimitri von R\u00fctte",
      "Janis Fluri",
      "Omead Pooladzandi",
      "Bernhard Sch\u00f6lkopf",
      "Thomas Hofmann",
      "Antonio Orvieto"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.10858",
    "abstract": "Modern LLM pre-training consumes vast amounts of compute and training data, making the scaling behavior, or scaling laws, of different models a key distinguishing factor. Discrete diffusion language models (DLMs) have been proposed as an alternative to autoregressive language models (ALMs). However,",
    "file": "cs/lg/2512.10858-scaling-behavior-of-discrete-diffusion-language-mo.md"
  },
  {
    "arxiv_id": "2512.10835",
    "title": "Learning Controllable and Diverse Player Behaviors in Multi-Agent Environments",
    "authors": [
      "Atahan Cilan",
      "Atay \u00d6zg\u00f6vde"
    ],
    "date": "2025-12-11",
    "field": "cs-lg",
    "tags": [
      "cs.LG"
    ],
    "url": "https://arxiv.org/abs/2512.10835",
    "abstract": "This paper introduces a reinforcement learning framework that enables controllable and diverse player behaviors without relying on human gameplay data. Existing approaches often require large-scale player trajectories, train separate models for different player types, or provide no direct mapping be",
    "file": "cs/lg/2512.10835-learning-controllable-and-diverse-player-behaviors.md"
  },
  {
    "arxiv_id": "2512.10949",
    "title": "Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation",
    "authors": [
      "Yiwen Tang",
      "Zoey Guo",
      "Kaixin Zhu",
      "Ray Zhang",
      "Qizhi Chen",
      "Dongzhi Jiang",
      "Junli Liu",
      "Bohan Zeng",
      "Haoming Song",
      "Delin Qu",
      "Tianyi Bai",
      "Dan Xu",
      "Wentao Zhang",
      "Bin Zhao"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "url": "https://arxiv.org/abs/2512.10949",
    "abstract": "Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which req",
    "file": "cs/cv/2512.10949-are-we-ready-for-rl-in-text-to-3d-generation-a-pr.md"
  },
  {
    "arxiv_id": "2512.10943",
    "title": "AlcheMinT: Fine-grained Temporal Control for Multi-Reference Consistent Video Generation",
    "authors": [
      "Sharath Girish",
      "Viacheslav Ivanov",
      "Tsai-Shien Chen",
      "Hao Chen",
      "Aliaksandr Siarohin",
      "Sergey Tulyakov"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "https://arxiv.org/abs/2512.10943",
    "abstract": "Recent advances in subject-driven video generation with large diffusion models have enabled personalized content synthesis conditioned on user-provided subjects. However, existing methods lack fine-grained temporal control over subject appearance and disappearance, which are essential for applicatio",
    "file": "cs/cv/2512.10943-alchemint-fine-grained-temporal-control-for-multi.md"
  },
  {
    "arxiv_id": "2512.10947",
    "title": "Towards Efficient and Effective Multi-Camera Encoding for End-to-End Driving",
    "authors": [
      "Jiawei Yang",
      "Ziyu Chen",
      "Yurong You",
      "Yan Wang",
      "Yiming Li",
      "Yuxiao Chen",
      "Boyi Li",
      "Boris Ivanovic",
      "Marco Pavone",
      "Yue Wang"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10947",
    "abstract": "We present Flex, an efficient and effective scene encoder that addresses the computational bottleneck of processing high-volume multi-camera data in end-to-end autonomous driving. Flex employs a small set of learnable scene tokens to jointly encode information from all image tokens across different ",
    "file": "cs/cv/2512.10947-towards-efficient-and-effective-multi-camera-encod.md"
  },
  {
    "arxiv_id": "2512.10954",
    "title": "Group Diffusion: Enhancing Image Generation by Unlocking Cross-Sample Collaboration",
    "authors": [
      "Sicheng Mo",
      "Thao Nguyen",
      "Richard Zhang",
      "Nick Kolkin",
      "Siddharth Srinivasan Iyer",
      "Eli Shechtman",
      "Krishna Kumar Singh",
      "Yong Jae Lee",
      "Bolei Zhou",
      "Yuheng Li"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10954",
    "abstract": "In this work, we explore an untapped signal in diffusion model inference. While all previous methods generate images independently at inference, we instead ask if samples can be generated collaboratively. We propose Group Diffusion, unlocking the attention mechanism to be shared across images, rathe",
    "file": "cs/cv/2512.10954-group-diffusion-enhancing-image-generation-by-unl.md"
  },
  {
    "arxiv_id": "2512.10860",
    "title": "SWiT-4D: Sliding-Window Transformer for Lossless and Parameter-Free Temporal 4D Generation",
    "authors": [
      "Kehong Gong",
      "Zhengyu Wen",
      "Mingxi Xu",
      "Weixia He",
      "Qi Wang",
      "Ning Zhang",
      "Zhengyu Li",
      "Chenbin Li",
      "Dongze Lian",
      "Wei Zhao",
      "Xiaoyu He",
      "Mingyuan Zhang"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10860",
    "abstract": "Despite significant progress in 4D content generation, the conversion of monocular videos into high-quality animated 3D assets with explicit 4D meshes remains considerably challenging. The scarcity of large-scale, naturally captured 4D mesh datasets further limits the ability to train generalizable ",
    "file": "cs/cv/2512.10860-swit-4d-sliding-window-transformer-for-lossless-a.md"
  },
  {
    "arxiv_id": "2512.10840",
    "title": "PoseGAM: Robust Unseen Object Pose Estimation via Geometry-Aware Multi-View Reasoning",
    "authors": [
      "Jianqi Chen",
      "Biao Zhang",
      "Xiangjun Tang",
      "Peter Wonka"
    ],
    "date": "2025-12-11",
    "field": "cs-cv",
    "tags": [
      "cs.CV"
    ],
    "url": "https://arxiv.org/abs/2512.10840",
    "abstract": "6D object pose estimation, which predicts the transformation of an object relative to the camera, remains challenging for unseen objects. Existing approaches typically rely on explicitly constructing feature correspondences between the query image and either the object model or template images. In t",
    "file": "cs/cv/2512.10840-posegam-robust-unseen-object-pose-estimation-via.md"
  }
]