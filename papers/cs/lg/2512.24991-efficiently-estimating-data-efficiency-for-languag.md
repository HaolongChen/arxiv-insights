---
title: "Efficiently Estimating Data Efficiency for Language Model Fine-tuning"
arxiv_id: "2512.24991"
authors: ["Gyung Hyun Je", "Colin Raffel"]
publication_date: 2025-12-31
field: "cs-lg"
tags: ["cs.LG"]
url: "https://arxiv.org/abs/2512.24991"
pdf: "https://arxiv.org/pdf/2512.24991.pdf"
---

# Efficiently Estimating Data Efficiency for Language Model Fine-tuning

## Metadata

- **arXiv ID**: [2512.24991](https://arxiv.org/abs/2512.24991)
- **Authors**: Gyung Hyun Je, Colin Raffel
- **Published**: 2025-12-31
- **Collected**: 2026-01-02
- **Field**: CS-LG
- **PDF**: [Download](https://arxiv.org/pdf/2512.24991.pdf)

## Abstract

While large language models (LLMs) demonstrate reasonable zero-shot capability across many downstream tasks, fine-tuning is a common practice to improve their performance. However, a task's data efficiency--i.e., the number of fine-tuning examples needed to achieve a desired level of performance--is often unknown, resulting in costly cycles of incremental annotation and retraining. Indeed, we demonstrate across a curated set of 30 specialized tasks that performant LLMs may struggle zero-shot but can attain stronger performance after fine-tuning. This motivates the need for methods to predict a task's data efficiency without requiring incremental annotation. After introducing a concrete metric that quantifies a task's data efficiency, we propose using the gradient cosine similarity of low-confidence examples to predict data efficiency based on a small number of labeled samples. We validate our approach on a diverse set of tasks with varying data efficiencies, attaining 8.6% error in overall data efficiency prediction and typically eliminating hundreds of unnecessary annotations on each task. Our experiment results and implementation code are available on GitHub.

## Key Findings

### 1. Automated extraction - requires manual review


## Methodology

See abstract and full paper for details

**Dataset**: Not specified


## Applications

- Refer to paper for specific applications


## Tags

`cs.LG`

---

*Processed by automation system on 2026-01-02 02:05:38*
