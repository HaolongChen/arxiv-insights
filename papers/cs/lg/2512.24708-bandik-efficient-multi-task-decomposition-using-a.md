---
title: "BandiK: Efficient Multi-Task Decomposition Using a Multi-Bandit Framework"
arxiv_id: "2512.24708"
authors: ["Andr\u00e1s Millinghoffer", "Andr\u00e1s Formanek", "Andr\u00e1s Antos", "P\u00e9ter Antal"]
publication_date: 2025-12-31
field: "cs-lg"
tags: ["cs.LG", "cs.AI"]
url: "https://arxiv.org/abs/2512.24708"
pdf: "https://arxiv.org/pdf/2512.24708.pdf"
---

# BandiK: Efficient Multi-Task Decomposition Using a Multi-Bandit Framework

## Metadata

- **arXiv ID**: [2512.24708](https://arxiv.org/abs/2512.24708)
- **Authors**: András Millinghoffer, András Formanek, András Antos, Péter Antal
- **Published**: 2025-12-31
- **Collected**: 2026-01-01
- **Field**: CS-LG
- **PDF**: [Download](https://arxiv.org/pdf/2512.24708.pdf)

## Abstract

The challenge of effectively transferring knowledge across multiple tasks is of critical importance and is also present in downstream tasks with foundation models. However, the nature of transfer, its transitive-intransitive nature, is still an open problem, and negative transfer remains a significant obstacle. Selection of beneficial auxiliary task sets in multi-task learning is frequently hindered by the high computational cost of their evaluation, the high number of plausible candidate auxiliary sets, and the varying complexity of selection across target tasks.   To address these constraints, we introduce BandiK, a novel three-stage multi-task auxiliary task subset selection method using multi-bandits, where each arm pull evaluates candidate auxiliary sets by training and testing a multiple output neural network on a single random train-test dataset split. Firstly, BandiK estimates the pairwise transfers between tasks, which helps in identifying which tasks are likely to benefit from joint learning. In the second stage, it constructs a linear number of candidate sets of auxiliary tasks (in the number of all tasks) for each target task based on the initial estimations, significantly reducing the exponential number of potential auxiliary task sets. Thirdly, it employs a Multi-Armed Bandit (MAB) framework for each task, where the arms correspond to the performance of candidate auxiliary sets realized as multiple output neural networks over train-test data set splits. To enhance efficiency, BandiK integrates these individual task-specific MABs into a multi-bandit structure. The proposed multi-bandit solution exploits that the same neural network realizes multiple arms of different individual bandits corresponding to a given candidate set. This semi-overlapping arm property defines a novel multi-bandit cost/reward structure utilized in BandiK.

## Key Findings

### 1. Automated extraction - requires manual review


## Methodology

See abstract and full paper for details

**Dataset**: Not specified


## Applications

- Refer to paper for specific applications


## Tags

`cs.LG` `cs.AI`

---

*Processed by automation system on 2026-01-01 02:20:44*
