---
title: "ResponseRank: Data-Efficient Reward Modeling through Preference Strength Learning"
arxiv_id: "2512.25023"
authors: ["Timo Kaufmann", "Yannick Metz", "Daniel Keim", "Eyke H\u00fcllermeier"]
publication_date: 2025-12-31
field: "cs-lg"
tags: ["cs.LG"]
url: "https://arxiv.org/abs/2512.25023"
pdf: "https://arxiv.org/pdf/2512.25023.pdf"
---

# ResponseRank: Data-Efficient Reward Modeling through Preference Strength Learning

## Metadata

- **arXiv ID**: [2512.25023](https://arxiv.org/abs/2512.25023)
- **Authors**: Timo Kaufmann, Yannick Metz, Daniel Keim, Eyke HÃ¼llermeier
- **Published**: 2025-12-31
- **Collected**: 2026-01-01
- **Field**: CS-LG
- **PDF**: [Download](https://arxiv.org/pdf/2512.25023.pdf)

## Abstract

Binary choices, as often used for reinforcement learning from human feedback (RLHF), convey only the direction of a preference. A person may choose apples over oranges and bananas over grapes, but which preference is stronger? Strength is crucial for decision-making under uncertainty and generalization of preference models, but hard to measure reliably. Metadata such as response times and inter-annotator agreement can serve as proxies for strength, but are often noisy and confounded. We propose ResponseRank to address the challenge of learning from noisy strength signals. Our method uses relative differences in proxy signals to rank responses to pairwise comparisons by their inferred preference strength. To control for systemic variation, we compare signals only locally within carefully constructed strata. This enables robust learning of utility differences consistent with strength-derived rankings while making minimal assumptions about the strength signal. Our contributions are threefold: (1) ResponseRank, a novel method that robustly learns preference strength by leveraging locally valid relative strength signals; (2) empirical evidence of improved sample efficiency and robustness across diverse tasks: synthetic preference learning (with simulated response times), language modeling (with annotator agreement), and RL control tasks (with simulated episode returns); and (3) the Pearson Distance Correlation (PDC), a novel metric that isolates cardinal utility learning from ordinal accuracy.

## Key Findings

### 1. Automated extraction - requires manual review


## Methodology

See abstract and full paper for details

**Dataset**: Not specified


## Applications

- Refer to paper for specific applications


## Tags

`cs.LG`

---

*Processed by automation system on 2026-01-01 16:33:25*
