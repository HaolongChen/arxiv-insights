---
title: "Critic-Guided Reinforcement Unlearning in Text-to-Image Diffusion"
arxiv_id: "2601.03213"
authors: ["Mykola Vysotskyi", "Zahar Kohut", "Mariia Shpir", "Taras Rumezhak", "Volodymyr Karpiv"]
publication_date: 2026-01-06
field: "cs-lg"
tags: ["cs.LG"]
url: "https://arxiv.org/abs/2601.03213"
pdf: "https://arxiv.org/pdf/2601.03213.pdf"
---

# Critic-Guided Reinforcement Unlearning in Text-to-Image Diffusion

## Metadata

- **arXiv ID**: [2601.03213](https://arxiv.org/abs/2601.03213)
- **Authors**: Mykola Vysotskyi, Zahar Kohut, Mariia Shpir, Taras Rumezhak, Volodymyr Karpiv
- **Published**: 2026-01-06
- **Collected**: 2026-01-07
- **Field**: CS-LG
- **PDF**: [Download](https://arxiv.org/pdf/2601.03213.pdf)

## Abstract

Machine unlearning in text-to-image diffusion models aims to remove targeted concepts while preserving overall utility. Prior diffusion unlearning methods typically rely on supervised weight edits or global penalties; reinforcement-learning (RL) approaches, while flexible, often optimize sparse end-of-trajectory rewards, yielding high-variance updates and weak credit assignment. We present a general RL framework for diffusion unlearning that treats denoising as a sequential decision process and introduces a timestep-aware critic with noisy-step rewards. Concretely, we train a CLIP-based reward predictor on noisy latents and use its per-step signal to compute advantage estimates for policy-gradient updates of the reverse diffusion kernel. Our algorithm is simple to implement, supports off-policy reuse, and plugs into standard text-to-image backbones. Across multiple concepts, the method achieves better or comparable forgetting to strong baselines while maintaining image quality and benign prompt fidelity; ablations show that (i) per-step critics and (ii) noisy-conditioned rewards are key to stability and effectiveness. We release code and evaluation scripts to facilitate reproducibility and future research on RL-based diffusion unlearning.

## Key Findings

### 1. Automated extraction - requires manual review


## Methodology

See abstract and full paper for details

**Dataset**: Not specified


## Applications

- Refer to paper for specific applications


## Tags

`cs.LG`

---

*Processed by automation system on 2026-01-07 16:37:02*
