---
title: "Delta-LLaVA: Base-then-Specialize Alignment for Token-Efficient Vision-Language Models"
arxiv_id: "2512.18910"
authors: ["Mohamad Zamini", "Diksha Shukla"]
publication_date: 2025-12-21
field: "cs-cv"
tags: ["cs.CV"]
url: "https://arxiv.org/abs/2512.18910"
pdf: "https://arxiv.org/pdf/2512.18910.pdf"
---

# Delta-LLaVA: Base-then-Specialize Alignment for Token-Efficient Vision-Language Models

## Metadata

- **arXiv ID**: [2512.18910](https://arxiv.org/abs/2512.18910)
- **Authors**: Mohamad Zamini, Diksha Shukla
- **Published**: 2025-12-21
- **Collected**: 2025-12-23
- **Field**: CS-CV
- **PDF**: [Download](https://arxiv.org/pdf/2512.18910.pdf)

## Abstract

Multimodal Large Language Models (MLLMs) combine visual and textual representations to enable rich reasoning capabilities. However, the high computational cost of processing dense visual tokens remains a major bottleneck. A critical component in this pipeline is the visual projector, which bridges the vision encoder and the language model. Standard designs often employ a simple multi-layer perceptron for direct token mapping, but this approach scales poorly with high-resolution inputs, introducing significant redundancy. We present Delta-LLaVA, a token-efficient projector that employs a low-rank DeltaProjection to align multi-level vision features into a compact subspace before further interaction. On top of this base alignment, lightweight Transformer blocks act as specialization layers, capturing both global and local structure under constrained token budgets. Extensive experiments and ablations demonstrate that this base-then-specialize design yields consistent gains across multiple benchmarks with only 144 tokens, highlighting the importance of token formation prior to scaling interaction capacity. With Delta-LLaVA, inference throughput improves by up to 55%, while end-to-end training accelerates by nearly 4-5x in pretraining and over 1.5x in finetuning, highlighting the dual benefits of our design in both efficiency and scalability.

## Key Findings

### 1. Automated extraction - requires manual review


## Methodology

See abstract and full paper for details

**Dataset**: Not specified


## Applications

- Refer to paper for specific applications


## Tags

`cs.CV`

---

*Processed by automation system on 2025-12-23 02:02:57*
