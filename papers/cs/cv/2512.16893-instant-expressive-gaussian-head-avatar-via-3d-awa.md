---
title: "Instant Expressive Gaussian Head Avatar via 3D-Aware Expression Distillation"
arxiv_id: "2512.16893"
authors: ["Kaiwen Jiang", "Xueting Li", "Seonwook Park", "Ravi Ramamoorthi", "Shalini De Mello", "Koki Nagano"]
publication_date: 2025-12-18
field: "cs-cv"
tags: ["cs.CV"]
url: "https://arxiv.org/abs/2512.16893"
pdf: "https://arxiv.org/pdf/2512.16893.pdf"
---

# Instant Expressive Gaussian Head Avatar via 3D-Aware Expression Distillation

## Metadata

- **arXiv ID**: [2512.16893](https://arxiv.org/abs/2512.16893)
- **Authors**: Kaiwen Jiang, Xueting Li, Seonwook Park, Ravi Ramamoorthi, Shalini De Mello, Koki Nagano
- **Published**: 2025-12-18
- **Collected**: 2025-12-20
- **Field**: CS-CV
- **PDF**: [Download](https://arxiv.org/pdf/2512.16893.pdf)

## Abstract

Portrait animation has witnessed tremendous quality improvements thanks to recent advances in video diffusion models. However, these 2D methods often compromise 3D consistency and speed, limiting their applicability in real-world scenarios, such as digital twins or telepresence. In contrast, 3D-aware facial animation feedforward methods -- built upon explicit 3D representations, such as neural radiance fields or Gaussian splatting -- ensure 3D consistency and achieve faster inference speed, but come with inferior expression details. In this paper, we aim to combine their strengths by distilling knowledge from a 2D diffusion-based method into a feed-forward encoder, which instantly converts an in-the-wild single image into a 3D-consistent, fast yet expressive animatable representation. Our animation representation is decoupled from the face's 3D representation and learns motion implicitly from data, eliminating the dependency on pre-defined parametric models that often constrain animation capabilities. Unlike previous computationally intensive global fusion mechanisms (e.g., multiple attention layers) for fusing 3D structural and animation information, our design employs an efficient lightweight local fusion strategy to achieve high animation expressivity. As a result, our method runs at 107.31 FPS for animation and pose control while achieving comparable animation quality to the state-of-the-art, surpassing alternative designs that trade speed for quality or vice versa. Project website is https://research.nvidia.com/labs/amri/projects/instant4d

## Key Findings

### 1. Automated extraction - requires manual review


## Methodology

See abstract and full paper for details

**Dataset**: Not specified


## Applications

- Refer to paper for specific applications


## Tags

`cs.CV`

---

*Processed by automation system on 2025-12-20 01:55:16*
