---
title: "From Indoor to Open World: Revealing the Spatial Reasoning Gap in MLLMs"
arxiv_id: "2512.19683"
authors: ["Mingrui Wu", "Zhaozhi Wang", "Fangjinhua Wang", "Jiaolong Yang", "Marc Pollefeys", "Tong Zhang"]
publication_date: 2025-12-22
field: "cs-cv"
tags: ["cs.CV"]
url: "https://arxiv.org/abs/2512.19683"
pdf: "https://arxiv.org/pdf/2512.19683.pdf"
---

# From Indoor to Open World: Revealing the Spatial Reasoning Gap in MLLMs

## Metadata

- **arXiv ID**: [2512.19683](https://arxiv.org/abs/2512.19683)
- **Authors**: Mingrui Wu, Zhaozhi Wang, Fangjinhua Wang, Jiaolong Yang, Marc Pollefeys, Tong Zhang
- **Published**: 2025-12-22
- **Collected**: 2025-12-23
- **Field**: CS-CV
- **PDF**: [Download](https://arxiv.org/pdf/2512.19683.pdf)

## Abstract

While Multimodal Large Language Models (MLLMs) have achieved impressive performance on semantic tasks, their spatial intelligence--crucial for robust and grounded AI systems--remains underdeveloped. Existing benchmarks fall short of diagnosing this limitation: they either focus on overly simplified qualitative reasoning or rely on domain-specific indoor data, constrained by the lack of outdoor datasets with verifiable metric ground truth. To bridge this gap, we introduce a large-scale benchmark built from pedestrian-perspective videos captured with synchronized stereo cameras, LiDAR, and IMU/GPS sensors. This dataset provides metrically precise 3D information, enabling the automatic generation of spatial reasoning questions that span a hierarchical spectrum--from qualitative relational reasoning to quantitative metric and kinematic understanding. Evaluations reveal that the performance gains observed in structured indoor benchmarks vanish in open-world settings. Further analysis using synthetic abnormal scenes and blinding tests confirms that current MLLMs depend heavily on linguistic priors instead of grounded visual reasoning. Our benchmark thus provides a principled platform for diagnosing these limitations and advancing physically grounded spatial intelligence.

## Key Findings

### 1. Automated extraction - requires manual review


## Methodology

See abstract and full paper for details

**Dataset**: Not specified


## Applications

- Refer to paper for specific applications


## Tags

`cs.CV`

---

*Processed by automation system on 2025-12-23 08:36:13*
