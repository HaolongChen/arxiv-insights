---
title: "AgentIAD: Tool-Augmented Single-Agent for Industrial Anomaly Detection"
arxiv_id: "2512.13671"
authors: ["Junwen Miao", "Penghui Du", "Yi Liu", "Yu Wang", "Yan Wang"]
publication_date: 2025-12-15
field: "cs-cv"
tags: ["cs.CV"]
url: "https://arxiv.org/abs/2512.13671"
pdf: "https://arxiv.org/pdf/2512.13671.pdf"
---

# AgentIAD: Tool-Augmented Single-Agent for Industrial Anomaly Detection

## Metadata

- **arXiv ID**: [2512.13671](https://arxiv.org/abs/2512.13671)
- **Authors**: Junwen Miao, Penghui Du, Yi Liu, Yu Wang, Yan Wang
- **Published**: 2025-12-15
- **Collected**: 2025-12-17
- **Field**: CS-CV
- **PDF**: [Download](https://arxiv.org/pdf/2512.13671.pdf)

## Abstract

Industrial anomaly detection (IAD) is difficult due to the scarcity of normal reference samples and the subtle, localized nature of many defects. Single-pass vision-language models (VLMs) often overlook small abnormalities and lack explicit mechanisms to compare against canonical normal patterns. We propose AgentIAD, a tool-driven agentic framework that enables multi-stage visual inspection. The agent is equipped with a Perceptive Zoomer (PZ) for localized fine-grained analysis and a Comparative Retriever (CR) for querying normal exemplars when evidence is ambiguous. To teach these inspection behaviors, we construct structured perceptive and comparative trajectories from the MMAD dataset and train the model in two stages: supervised fine-tuning followed by reinforcement learning. A two-part reward design drives this process: a perception reward that supervises classification accuracy, spatial alignment, and type correctness, and a behavior reward that encourages efficient tool use. Together, these components enable the model to refine its judgment through step-wise observation, zooming, and verification. AgentIAD achieves a new state-of-the-art 97.62% classification accuracy on MMAD, surpassing prior MLLM-based approaches while producing transparent and interpretable inspection traces.

## Key Findings

### 1. Automated extraction - requires manual review


## Methodology

See abstract and full paper for details

**Dataset**: Not specified


## Applications

- Refer to paper for specific applications


## Tags

`cs.CV`

---

*Processed by automation system on 2025-12-17 01:57:41*
