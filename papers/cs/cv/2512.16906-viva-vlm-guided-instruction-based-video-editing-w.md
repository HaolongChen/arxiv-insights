---
title: "VIVA: VLM-Guided Instruction-Based Video Editing with Reward Optimization"
arxiv_id: "2512.16906"
authors: ["Xiaoyan Cong", "Haotian Yang", "Angtian Wang", "Yizhi Wang", "Yiding Yang", "Canyu Zhang", "Chongyang Ma"]
publication_date: 2025-12-18
field: "cs-cv"
tags: ["cs.CV"]
url: "https://arxiv.org/abs/2512.16906"
pdf: "https://arxiv.org/pdf/2512.16906.pdf"
---

# VIVA: VLM-Guided Instruction-Based Video Editing with Reward Optimization

## Metadata

- **arXiv ID**: [2512.16906](https://arxiv.org/abs/2512.16906)
- **Authors**: Xiaoyan Cong, Haotian Yang, Angtian Wang, Yizhi Wang, Yiding Yang, Canyu Zhang, Chongyang Ma
- **Published**: 2025-12-18
- **Collected**: 2025-12-19
- **Field**: CS-CV
- **PDF**: [Download](https://arxiv.org/pdf/2512.16906.pdf)

## Abstract

Instruction-based video editing aims to modify an input video according to a natural-language instruction while preserving content fidelity and temporal coherence. However, existing diffusion-based approaches are often trained on paired data of simple editing operations, which fundamentally limits their ability to generalize to diverse and complex, real-world instructions. To address this generalization gap, we propose VIVA, a scalable framework for instruction-based video editing that leverages VLM-guided encoding and reward optimization. First, we introduce a VLM-based instructor that encodes the textual instruction, the first frame of the source video, and an optional reference image into visually-grounded instruction representations, providing fine-grained spatial and semantic context for the diffusion transformer backbone. Second, we propose a post-training stage, Edit-GRPO, which adapts Group Relative Policy Optimization to the domain of video editing, directly optimizing the model for instruction-faithful, content-preserving, and aesthetically pleasing edits using relative rewards. Furthermore, we propose a data construction pipeline designed to synthetically generate diverse, high-fidelity paired video-instruction data of basic editing operations. Extensive experiments show that VIVA achieves superior instruction following, generalization, and editing quality over state-of-the-art methods. Website: https://viva-paper.github.io

## Key Findings

### 1. Automated extraction - requires manual review


## Methodology

See abstract and full paper for details

**Dataset**: Not specified


## Applications

- Refer to paper for specific applications


## Tags

`cs.CV`

---

*Processed by automation system on 2025-12-19 16:33:35*
