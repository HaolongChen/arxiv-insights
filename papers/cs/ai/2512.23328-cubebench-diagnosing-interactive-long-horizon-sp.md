---
title: "CubeBench: Diagnosing Interactive, Long-Horizon Spatial Reasoning Under Partial Observations"
arxiv_id: "2512.23328"
authors: ["Huan-ang Gao", "Zikang Zhang", "Tianwei Luo", "Kaisen Yang", "Xinzhe Juan", "Jiahao Qiu", "Tianxing Chen", "Bingxiang He", "Hao Zhao", "Hao Zhou", "Shilong Liu", "Mengdi Wang"]
publication_date: 2025-12-29
field: "cs-ai"
tags: ["cs.AI", "cs.CL", "cs.CV"]
url: "https://arxiv.org/abs/2512.23328"
pdf: "https://arxiv.org/pdf/2512.23328.pdf"
---

# CubeBench: Diagnosing Interactive, Long-Horizon Spatial Reasoning Under Partial Observations

## Metadata

- **arXiv ID**: [2512.23328](https://arxiv.org/abs/2512.23328)
- **Authors**: Huan-ang Gao, Zikang Zhang, Tianwei Luo, Kaisen Yang, Xinzhe Juan, Jiahao Qiu, Tianxing Chen, Bingxiang He, Hao Zhao, Hao Zhou, Shilong Liu, Mengdi Wang
- **Published**: 2025-12-29
- **Collected**: 2025-12-30
- **Field**: CS-AI
- **PDF**: [Download](https://arxiv.org/pdf/2512.23328.pdf)

## Abstract

Large Language Model (LLM) agents, while proficient in the digital realm, face a significant gap in physical-world deployment due to the challenge of forming and maintaining a robust spatial mental model. We identify three core cognitive challenges hindering this transition: spatial reasoning, long-horizon state tracking via mental simulation, and active exploration under partial observation. To isolate and evaluate these faculties, we introduce CubeBench, a novel generative benchmark centered on the Rubik's Cube. CubeBench uses a three-tiered diagnostic framework that progressively assesses agent capabilities, from foundational state tracking with full symbolic information to active exploration with only partial visual data. Our experiments on leading LLMs reveal critical limitations, including a uniform 0.00% pass rate on all long-horizon tasks, exposing a fundamental failure in long-term planning. We also propose a diagnostic framework to isolate these cognitive bottlenecks by providing external solver tools. By analyzing the failure modes, we provide key insights to guide the development of more physically-grounded intelligent agents.

## Key Findings

### 1. Automated extraction - requires manual review


## Methodology

See abstract and full paper for details

**Dataset**: Not specified


## Applications

- Refer to paper for specific applications


## Tags

`cs.AI` `cs.CL` `cs.CV`

---

*Processed by automation system on 2025-12-30 02:03:39*
