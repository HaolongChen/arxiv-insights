---
title: "MAGMA: A Multi-Graph based Agentic Memory Architecture for AI Agents"
arxiv_id: "2601.03236"
authors: ["Dongming Jiang", "Yi Li", "Guanpeng Li", "Bingzhe Li"]
publication_date: 2026-01-06
field: "cs-ai"
tags: ["cs.AI"]
url: "https://arxiv.org/abs/2601.03236"
pdf: "https://arxiv.org/pdf/2601.03236.pdf"
---

# MAGMA: A Multi-Graph based Agentic Memory Architecture for AI Agents

## Metadata

- **arXiv ID**: [2601.03236](https://arxiv.org/abs/2601.03236)
- **Authors**: Dongming Jiang, Yi Li, Guanpeng Li, Bingzhe Li
- **Published**: 2026-01-06
- **Collected**: 2026-01-07
- **Field**: CS-AI
- **PDF**: [Download](https://arxiv.org/pdf/2601.03236.pdf)

## Abstract

Memory-Augmented Generation (MAG) extends Large Language Models with external memory to support long-context reasoning, but existing approaches largely rely on semantic similarity over monolithic memory stores, entangling temporal, causal, and entity information. This design limits interpretability and alignment between query intent and retrieved evidence, leading to suboptimal reasoning accuracy. In this paper, we propose MAGMA, a multi-graph agentic memory architecture that represents each memory item across orthogonal semantic, temporal, causal, and entity graphs. MAGMA formulates retrieval as policy-guided traversal over these relational views, enabling query-adaptive selection and structured context construction. By decoupling memory representation from retrieval logic, MAGMA provides transparent reasoning paths and fine-grained control over retrieval. Experiments on LoCoMo and LongMemEval demonstrate that MAGMA consistently outperforms state-of-the-art agentic memory systems in long-horizon reasoning tasks.

## Key Findings

### 1. Automated extraction - requires manual review


## Methodology

See abstract and full paper for details

**Dataset**: Not specified


## Applications

- Refer to paper for specific applications


## Tags

`cs.AI`

---

*Processed by automation system on 2026-01-07 02:05:12*
