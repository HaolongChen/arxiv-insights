---
title: "UltraLogic: Enhancing LLM Reasoning through Large-Scale Data Synthesis and Bipolar Float Reward"
arxiv_id: "2601.03205"
authors: ["Yile Liu", "Yixian Liu", "Zongwei Li", "Yufei Huang", "Xinhua Feng", "Zhichao Hu", "Jinglu Hu", "Jianfeng Yan", "Fengzong Lian", "Yuhong Liu"]
publication_date: 2026-01-06
field: "cs-ai"
tags: ["cs.CL", "cs.AI"]
url: "https://arxiv.org/abs/2601.03205"
pdf: "https://arxiv.org/pdf/2601.03205.pdf"
---

# UltraLogic: Enhancing LLM Reasoning through Large-Scale Data Synthesis and Bipolar Float Reward

## Metadata

- **arXiv ID**: [2601.03205](https://arxiv.org/abs/2601.03205)
- **Authors**: Yile Liu, Yixian Liu, Zongwei Li, Yufei Huang, Xinhua Feng, Zhichao Hu, Jinglu Hu, Jianfeng Yan, Fengzong Lian, Yuhong Liu
- **Published**: 2026-01-06
- **Collected**: 2026-01-07
- **Field**: CS-AI
- **PDF**: [Download](https://arxiv.org/pdf/2601.03205.pdf)

## Abstract

While Large Language Models (LLMs) have demonstrated significant potential in natural language processing , complex general-purpose reasoning requiring multi-step logic, planning, and verification remains a critical bottleneck. Although Reinforcement Learning with Verifiable Rewards (RLVR) has succeeded in specific domains , the field lacks large-scale, high-quality, and difficulty-calibrated data for general reasoning. To address this, we propose UltraLogic, a framework that decouples the logical core of a problem from its natural language expression through a Code-based Solving methodology to automate high-quality data production. The framework comprises hundreds of unique task types and an automated calibration pipeline across ten difficulty levels. Furthermore, to mitigate binary reward sparsity and the Non-negative Reward Trap, we introduce the Bipolar Float Reward (BFR) mechanism, utilizing graded penalties to effectively distinguish perfect responses from those with logical flaws. Our experiments demonstrate that task diversity is the primary driver for reasoning enhancement , and that BFR, combined with a difficulty matching strategy, significantly improves training efficiency, guiding models toward global logical optima.

## Key Findings

### 1. Automated extraction - requires manual review


## Methodology

See abstract and full paper for details

**Dataset**: Not specified


## Applications

- Refer to paper for specific applications


## Tags

`cs.CL` `cs.AI`

---

*Processed by automation system on 2026-01-07 16:37:02*
