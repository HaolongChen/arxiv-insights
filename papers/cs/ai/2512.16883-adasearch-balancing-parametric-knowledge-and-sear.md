---
title: "AdaSearch: Balancing Parametric Knowledge and Search in Large Language Models via Reinforcement Learning"
arxiv_id: "2512.16883"
authors: ["Tzu-Han Lin", "Wei-Lin Chen", "Chen-An Li", "Hung-yi Lee", "Yun-Nung Chen", "Yu Meng"]
publication_date: 2025-12-18
field: "cs-ai"
tags: ["cs.CL"]
url: "https://arxiv.org/abs/2512.16883"
pdf: "https://arxiv.org/pdf/2512.16883.pdf"
---

# AdaSearch: Balancing Parametric Knowledge and Search in Large Language Models via Reinforcement Learning

## Metadata

- **arXiv ID**: [2512.16883](https://arxiv.org/abs/2512.16883)
- **Authors**: Tzu-Han Lin, Wei-Lin Chen, Chen-An Li, Hung-yi Lee, Yun-Nung Chen, Yu Meng
- **Published**: 2025-12-18
- **Collected**: 2025-12-20
- **Field**: CS-AI
- **PDF**: [Download](https://arxiv.org/pdf/2512.16883.pdf)

## Abstract

Equipping large language models (LLMs) with search engines via reinforcement learning (RL) has emerged as an effective approach for building search agents. However, overreliance on search introduces unnecessary cost and risks exposure to noisy or malicious content, while relying solely on parametric knowledge risks hallucination. The central challenge is to develop agents that adaptively balance parametric knowledge with external search, invoking search only when necessary. Prior work mitigates search overuse by shaping rewards around the number of tool calls. However, these penalties require substantial reward engineering, provide ambiguous credit assignment, and can be exploited by agents that superficially reduce calls. Moreover, evaluating performance solely through call counts conflates necessary and unnecessary search, obscuring the measurement of true adaptive behavior. To address these limitations, we first quantify the self-knowledge awareness of existing search agents via an F1-based decision metric, revealing that methods such as Search-R1 often overlook readily available parametric knowledge. Motivated by these findings, we propose AdaSearch, a simple two-stage, outcome-driven RL framework that disentangles problem solving from the decision of whether to invoke search, and makes this decision process explicit and interpretable. This transparency is crucial for high-stakes domains such as finance and medical question answering, yet is largely neglected by prior approaches. Experiments across multiple model families and sizes demonstrate that AdaSearch substantially improves knowledge-boundary awareness, reduces unnecessary search calls, preserves strong task performance, and offers more transparent, interpretable decision behaviors.

## Key Findings

### 1. Automated extraction - requires manual review


## Methodology

See abstract and full paper for details

**Dataset**: Not specified


## Applications

- Refer to paper for specific applications


## Tags

`cs.CL`

---

*Processed by automation system on 2025-12-20 08:31:30*
