---
title: "Eliciting Behaviors in Multi-Turn Conversations"
arxiv_id: "2512.23701"
authors: ["Jing Huang", "Shujian Zhang", "Lun Wang", "Andrew Hard", "Rajiv Mathews", "John Lambert"]
publication_date: 2025-12-29
field: "cs-ai"
tags: ["cs.CL", "cs.LG"]
url: "https://arxiv.org/abs/2512.23701"
pdf: "https://arxiv.org/pdf/2512.23701.pdf"
---

# Eliciting Behaviors in Multi-Turn Conversations

## Metadata

- **arXiv ID**: [2512.23701](https://arxiv.org/abs/2512.23701)
- **Authors**: Jing Huang, Shujian Zhang, Lun Wang, Andrew Hard, Rajiv Mathews, John Lambert
- **Published**: 2025-12-29
- **Collected**: 2025-12-30
- **Field**: CS-AI
- **PDF**: [Download](https://arxiv.org/pdf/2512.23701.pdf)

## Abstract

Identifying specific and often complex behaviors from large language models (LLMs) in conversational settings is crucial for their evaluation. Recent work proposes novel techniques to find natural language prompts that induce specific behaviors from a target model, yet they are mainly studied in single-turn settings. In this work, we study behavior elicitation in the context of multi-turn conversations. We first offer an analytical framework that categorizes existing methods into three families based on their interactions with the target model: those that use only prior knowledge, those that use offline interactions, and those that learn from online interactions. We then introduce a generalized multi-turn formulation of the online method, unifying single-turn and multi-turn elicitation. We evaluate all three families of methods on automatically generating multi-turn test cases. We investigate the efficiency of these approaches by analyzing the trade-off between the query budget, i.e., the number of interactions with the target model, and the success rate, i.e., the discovery rate of behavior-eliciting inputs. We find that online methods can achieve an average success rate of 45/19/77% with just a few thousand queries over three tasks where static methods from existing multi-turn conversation benchmarks find few or even no failure cases. Our work highlights a novel application of behavior elicitation methods in multi-turn conversation evaluation and the need for the community to move towards dynamic benchmarks.

## Key Findings

### 1. Automated extraction - requires manual review


## Methodology

See abstract and full paper for details

**Dataset**: Not specified


## Applications

- Refer to paper for specific applications


## Tags

`cs.CL` `cs.LG`

---

*Processed by automation system on 2025-12-30 08:35:54*
