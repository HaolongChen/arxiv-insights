---
title: "Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents"
arxiv_id: "2601.02314"
authors: ["Sourena Khanzadeh"]
publication_date: 2026-01-05
field: "cs-ai"
tags: ["cs.AI"]
url: "https://arxiv.org/abs/2601.02314"
pdf: "https://arxiv.org/pdf/2601.02314.pdf"
---

# Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents

## Metadata

- **arXiv ID**: [2601.02314](https://arxiv.org/abs/2601.02314)
- **Authors**: Sourena Khanzadeh
- **Published**: 2026-01-05
- **Collected**: 2026-01-06
- **Field**: CS-AI
- **PDF**: [Download](https://arxiv.org/pdf/2601.02314.pdf)

## Abstract

As Large Language Model (LLM) agents are increasingly tasked with high-stakes autonomous decision-making, the transparency of their reasoning processes has become a critical safety concern. While \textit{Chain-of-Thought} (CoT) prompting allows agents to generate human-readable reasoning traces, it remains unclear whether these traces are \textbf{faithful} generative drivers of the model's output or merely \textbf{post-hoc rationalizations}. We introduce \textbf{Project Ariadne}, a novel XAI framework that utilizes Structural Causal Models (SCMs) and counterfactual logic to audit the causal integrity of agentic reasoning. Unlike existing interpretability methods that rely on surface-level textual similarity, Project Ariadne performs \textbf{hard interventions} ($do$-calculus) on intermediate reasoning nodes -- systematically inverting logic, negating premises, and reversing factual claims -- to measure the \textbf{Causal Sensitivity} ($φ$) of the terminal answer. Our empirical evaluation of state-of-the-art models reveals a persistent \textit{Faithfulness Gap}. We define and detect a widespread failure mode termed \textbf{Causal Decoupling}, where agents exhibit a violation density ($ρ$) of up to $0.77$ in factual and scientific domains. In these instances, agents arrive at identical conclusions despite contradictory internal logic, proving that their reasoning traces function as "Reasoning Theater" while decision-making is governed by latent parametric priors. Our findings suggest that current agentic architectures are inherently prone to unfaithful explanation, and we propose the Ariadne Score as a new benchmark for aligning stated logic with model action.

## Key Findings

### 1. Automated extraction - requires manual review


## Methodology

See abstract and full paper for details

**Dataset**: Not specified


## Applications

- Refer to paper for specific applications


## Tags

`cs.AI`

---

*Processed by automation system on 2026-01-06 16:36:19*
