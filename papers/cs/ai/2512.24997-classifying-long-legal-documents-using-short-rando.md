---
title: "Classifying long legal documents using short random chunks"
arxiv_id: "2512.24997"
authors: ["Luis Adri\u00e1n Cabrera-Diego"]
publication_date: 2025-12-31
field: "cs-ai"
tags: ["cs.CL", "cs.AI"]
url: "https://arxiv.org/abs/2512.24997"
pdf: "https://arxiv.org/pdf/2512.24997.pdf"
---

# Classifying long legal documents using short random chunks

## Metadata

- **arXiv ID**: [2512.24997](https://arxiv.org/abs/2512.24997)
- **Authors**: Luis Adri√°n Cabrera-Diego
- **Published**: 2025-12-31
- **Collected**: 2026-01-02
- **Field**: CS-AI
- **PDF**: [Download](https://arxiv.org/pdf/2512.24997.pdf)

## Abstract

Classifying legal documents is a challenge, besides their specialized vocabulary, sometimes they can be very long. This means that feeding full documents to a Transformers-based models for classification might be impossible, expensive or slow. Thus, we present a legal document classifier based on DeBERTa V3 and a LSTM, that uses as input a collection of 48 randomly-selected short chunks (max 128 tokens). Besides, we present its deployment pipeline using Temporal, a durable execution solution, which allow us to have a reliable and robust processing workflow. The best model had a weighted F-score of 0.898, while the pipeline running on CPU had a processing median time of 498 seconds per 100 files.

## Key Findings

### 1. Automated extraction - requires manual review


## Methodology

See abstract and full paper for details

**Dataset**: Not specified


## Applications

- Refer to paper for specific applications


## Tags

`cs.CL` `cs.AI`

---

*Processed by automation system on 2026-01-02 02:05:38*
