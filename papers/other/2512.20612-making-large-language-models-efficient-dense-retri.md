---
title: "Making Large Language Models Efficient Dense Retrievers"
arxiv_id: "2512.20612"
authors: ["Yibin Lei", "Shwai He", "Ang Li", "Andrew Yates"]
publication_date: 2025-12-23
field: "other"
tags: ["cs.IR", "cs.CL"]
url: "https://arxiv.org/abs/2512.20612"
pdf: "https://arxiv.org/pdf/2512.20612.pdf"
---

# Making Large Language Models Efficient Dense Retrievers

## Metadata

- **arXiv ID**: [2512.20612](https://arxiv.org/abs/2512.20612)
- **Authors**: Yibin Lei, Shwai He, Ang Li, Andrew Yates
- **Published**: 2025-12-23
- **Collected**: 2025-12-24
- **Field**: OTHER
- **PDF**: [Download](https://arxiv.org/pdf/2512.20612.pdf)

## Abstract

Recent work has shown that directly fine-tuning large language models (LLMs) for dense retrieval yields strong performance, but their substantial parameter counts make them computationally inefficient. While prior studies have revealed significant layer redundancy in LLMs for generative tasks, it remains unclear whether similar redundancy exists when these models are adapted for retrieval tasks, which require encoding entire sequences into fixed representations rather than generating tokens iteratively. To this end, we conduct a comprehensive analysis of layer redundancy in LLM-based dense retrievers. We find that, in contrast to generative settings, MLP layers are substantially more prunable, while attention layers remain critical for semantic aggregation. Building on this insight, we propose EffiR, a framework for developing efficient retrievers that performs large-scale MLP compression through a coarse-to-fine strategy (coarse-grained depth reduction followed by fine-grained width reduction), combined with retrieval-specific fine-tuning. Across diverse BEIR datasets and LLM backbones, EffiR achieves substantial reductions in model size and inference cost while preserving the performance of full-size models.

## Key Findings

### 1. Automated extraction - requires manual review


## Methodology

See abstract and full paper for details

**Dataset**: Not specified


## Applications

- Refer to paper for specific applications


## Tags

`cs.IR` `cs.CL`

---

*Processed by automation system on 2025-12-24 02:00:45*
