---
title: "MuseCPBench: an Empirical Study of Music Editing Methods through Music Context Preservation"
arxiv_id: "2512.14629"
authors: ["Yash Vishe", "Eric Xue", "Xunyi Jiang", "Zachary Novack", "Junda Wu", "Julian McAuley", "Xin Xu"]
publication_date: 2025-12-16
field: "other"
tags: ["cs.SD", "cs.AI"]
url: "https://arxiv.org/abs/2512.14629"
pdf: "https://arxiv.org/pdf/2512.14629.pdf"
---

# MuseCPBench: an Empirical Study of Music Editing Methods through Music Context Preservation

## Metadata

- **arXiv ID**: [2512.14629](https://arxiv.org/abs/2512.14629)
- **Authors**: Yash Vishe, Eric Xue, Xunyi Jiang, Zachary Novack, Junda Wu, Julian McAuley, Xin Xu
- **Published**: 2025-12-16
- **Collected**: 2025-12-18
- **Field**: OTHER
- **PDF**: [Download](https://arxiv.org/pdf/2512.14629.pdf)

## Abstract

Music editing plays a vital role in modern music production, with applications in film, broadcasting, and game development. Recent advances in music generation models have enabled diverse editing tasks such as timbre transfer, instrument substitution, and genre transformation. However, many existing works overlook the evaluation of their ability to preserve musical facets that should remain unchanged during editing a property we define as Music Context Preservation (MCP). While some studies do consider MCP, they adopt inconsistent evaluation protocols and metrics, leading to unreliable and unfair comparisons. To address this gap, we introduce the first MCP evaluation benchmark, MuseCPBench, which covers four categories of musical facets and enables comprehensive comparisons across five representative music editing baselines. Through systematic analysis along musical facets, methods, and models, we identify consistent preservation gaps in current music editing methods and provide insightful explanations. We hope our findings offer practical guidance for developing more effective and reliable music editing strategies with strong MCP capability

## Key Findings

### 1. Automated extraction - requires manual review


## Methodology

See abstract and full paper for details

**Dataset**: Not specified


## Applications

- Refer to paper for specific applications


## Tags

`cs.SD` `cs.AI`

---

*Processed by automation system on 2025-12-18 01:58:27*
