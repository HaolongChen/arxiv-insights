# Data Directory

This directory contains sample data and processed outputs for the arXiv insights workflow.

## Directory Structure

```
data/
├── sample-paper.json       # Sample paper data for testing
├── .poke-sync-status.json  # Sync status tracking (generated)
└── README.md              # This file
```

## Sample Paper Data

The `sample-paper.json` file provides an example of the paper data structure expected by the Poke API integration workflows. It includes:

- **Basic metadata**: arXiv ID, title, authors, abstract
- **Publication details**: Categories, dates, URLs
- **Insights**: Key contributions, methodology, datasets, applications
- **Poke API status**: Synchronization tracking

## Usage

### For Testing

You can use the sample data to test the paper processing workflow:

```bash
python scripts/process_paper_with_poke.py data/sample-paper.json --dry-run
```

### For Workflow Triggers

The GitHub Actions workflow `process-papers-with-poke.yml` can be manually triggered with:

```yaml
paper_file: data/sample-paper.json
```

## Poke API Integration

When papers are processed and sent to the Poke API, the sync status is tracked in `.poke-sync-status.json`. This file is automatically generated and updated by the integration scripts.

### Status File Format

```json
{
  "last_sync": "2024-01-25T10:00:00Z",
  "sync_history": [
    {
      "timestamp": "2024-01-25T10:00:00Z",
      "paper_id": "2401.12345",
      "status": "success",
      "response_code": 200
    }
  ],
  "pending_papers": [],
  "failed_papers": []
}
```

## Environment Variables

Make sure to set these environment variables for Poke API integration:

- `POKE_API_KEY`: Your Poke API authentication key (required)
- `POKE_API_BASE_URL`: Base URL for Poke API (optional, defaults to pokeapi.co)
- `POKE_API_ENABLED`: Enable/disable Poke API integration (optional, defaults to true)

## Adding New Data

To add new paper data for processing:

1. Create a JSON file following the sample structure
2. Place it in the `papers/` directory or this `data/` directory
3. Run the processing script or trigger the workflow
4. Check the logs and artifacts for results

## Notes

- The `data/` directory is used for sample/test data
- The `papers/` directory is used for actual paper data from arXiv
- Processed outputs are uploaded as GitHub Actions artifacts
- Sync status files are automatically maintained by the integration scripts
